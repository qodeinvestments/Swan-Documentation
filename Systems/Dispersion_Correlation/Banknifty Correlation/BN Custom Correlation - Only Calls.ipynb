{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "274d2ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AXISBANK', 'BANKBARODA', 'BANKINDIA', 'CANBK', 'FEDERALBNK', 'HDFCBANK', 'ICICIBANK', 'INDUSINDBK', 'KOTAKBANK', 'PNB', 'SBIN', 'YESBANK', 'IDFCFIRSTB', 'RBLBANK', 'BANDHANBNK', 'AUBANK']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime as dt\n",
    "from datetime import datetime, date, time,timedelta\n",
    "import pandas as pd\n",
    "from csv import DictWriter\n",
    "import urllib\n",
    "import re,datetime\n",
    "import os\n",
    "import time\n",
    "from os import walk\n",
    "import re\n",
    "import gc\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 100)\n",
    "\n",
    "\n",
    "#############\n",
    "#INPUTS\n",
    "#############\n",
    "\n",
    "delta = 15\n",
    "\n",
    "backtest_start_date = '27-5-2016'\n",
    "backtest_end_date = '31-1-2023'\n",
    "\n",
    "index = \"BANKNIFTY\"\n",
    "index_file_path = \"D:\\Correlation Backtest Data 2016-23\\Correlation 6-16 to 1-23 data\\Input Files\\Index\\BANKNIFTY.csv\"\n",
    "\n",
    "stfolder = \"D:/Correlation Backtest Data 2016-23/Correlation 6-16 to 1-23 data/Input Files/Stocks\"\n",
    "    \n",
    "wgt_lot_path = \"D:\\Correlation Backtest Data 2016-23\\Correlation 6-16 to 1-23 data\\Input Files\\Others\\BN Mcap & includeok - Copy - Copy.csv\"\n",
    "\n",
    "direc = r\"D:/Correlation Backtest Data 2016-23/Correlation 6-16 to 1-23 data/Working Files - Only Calls\"\n",
    "\n",
    "output_path = r\"D:/Correlation Backtest Data 2016-23/Correlation 6-16 to 1-23 data/Output Files - Only Calls\"\n",
    "\n",
    "index_lotsize = 1\n",
    "\n",
    "initial_equity = 100000\n",
    "\n",
    "\n",
    "#########################\n",
    "#Creating Stock List\n",
    "#########################\n",
    "\n",
    "# filename = next(walk(stfolder), (None, None, []))[2]  # [] if no file\n",
    "# stock_list_path = []\n",
    "# for i in filename:\n",
    "#     temp = stfolder +\"/\"+ i\n",
    "#     stock_list_path.append(temp)\n",
    "\n",
    "    \n",
    "# stock_list = []\n",
    "# for i in stock_list_path:\n",
    "#     stock_list.append(i.replace(\".csv\",\"\").replace(stfolder + \"/\",\"\"))\n",
    "# print(stock_list)\n",
    "\n",
    "stock_list_df = pd.read_csv(wgt_lot_path, parse_dates = ['date'], dayfirst = True)\n",
    "stock_list_df = stock_list_df[(stock_list_df['date'] >= pd.to_datetime(backtest_start_date, format = '%d-%m-%Y', dayfirst = True)) & (stock_list_df['includeok'] == 1)]\n",
    "stock_list = stock_list_df['Security Symbol'].unique().tolist()\n",
    "print(stock_list)\n",
    "\n",
    "######################################    \n",
    "#Creating weight and lot dictionary\n",
    "######################################\n",
    "\n",
    "\"\"\"wgtlot_df = pd.read_csv(wgt_lot_path)\n",
    "wgtlot_dict = wgtlot_df.set_index('Symbol').T.to_dict('list')\n",
    "print(wgtlot_dict)\n",
    "symbols = list(wgtlot_dict.keys())\"\"\"\n",
    "\n",
    "### Now adding Columns for weights below\n",
    "\n",
    "######################################\n",
    "\n",
    "lookback_period = 15\n",
    "std_dev = 2\n",
    "\n",
    "####################\n",
    "#EXPIRY DATES\n",
    "####################\n",
    "symbols = stock_list.copy()\n",
    "symbols.append(index)\n",
    "\n",
    "exp_file_path = \"D:\\Correlation Backtest Data 2016-23\\Correlation 6-16 to 1-23 data\\Input Files\\Others\\MonthlyExpiry.csv\"\n",
    "\n",
    "exp_df = pd.read_csv(exp_file_path,parse_dates = [\"curr_exp_date\",\"Date\"],dayfirst =True,usecols = [\"curr_exp_date\",\"Date\",\"Weeks_to_Expiry\", \"Week of month\"])\n",
    "exp_df = exp_df[exp_df['Date'] >= pd.to_datetime(backtest_start_date, format = '%d-%m-%Y', dayfirst = True)]\n",
    "#exp_df.rename({'curr_date': 'Date'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc12231e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297904\n",
      "297904\n",
      "93128\n",
      "93128\n",
      "75301\n",
      "75301\n",
      "24287\n",
      "24287\n",
      "64479\n",
      "64479\n",
      "72496\n",
      "72496\n",
      "96261\n",
      "96261\n",
      "116159\n",
      "116159\n",
      "81317\n",
      "81317\n",
      "76688\n",
      "76688\n",
      "72314\n",
      "72314\n",
      "132229\n",
      "132229\n",
      "55360\n",
      "55360\n",
      "49361\n",
      "49361\n",
      "53662\n",
      "53662\n",
      "37132\n",
      "37132\n",
      "18506\n",
      "18506\n",
      "D:/Correlation Backtest Data 2016-23/Correlation 6-16 to 1-23 data/Working Files - Only Calls/BANKNIFTY.csv\n"
     ]
    }
   ],
   "source": [
    "idx = pd.read_csv(index_file_path,parse_dates = [\"Date\"],dayfirst = True)\n",
    "idx = idx[idx['Date'] >= pd.to_datetime(backtest_start_date, format = '%d-%m-%Y', dayfirst = True)]\n",
    "\n",
    "\n",
    "df1 = idx[idx['Ticker'].str.endswith('-I')]\n",
    "df2 = idx[idx['Ticker'].str.endswith('-II')]\n",
    "df3 = idx[idx['Ticker'].str.endswith('-III')]\n",
    "\n",
    "index_file_path = direc + \"/BANKNIFTY.csv\"\n",
    "\n",
    "df1.to_csv(index_file_path)\n",
    "df2.to_csv(index_file_path.replace(\"BANKNIFTY\",\"BANKNIFTY-II\"))\n",
    "df3.to_csv(index_file_path.replace(\"BANKNIFTY\",\"BANKNIFTY-III\"))\n",
    "\n",
    "print(idx.shape[0])\n",
    "print(df1.shape[0]+df2.shape[0]+df3.shape[0])\n",
    "    \n",
    "for i in stock_list:\n",
    "    df = pd.read_csv(stfolder + '/' + i + \".csv\",parse_dates = [\"Date\"],dayfirst = True)\n",
    "    df = df[df['Date'] >= pd.to_datetime(backtest_start_date, format = '%d-%m-%Y', dayfirst = True)]\n",
    "\n",
    "    df1 = df[df['Ticker'].str.endswith('-I')]\n",
    "    df2 = df[df['Ticker'].str.endswith('-II')]\n",
    "    df3 = df[df['Ticker'].str.endswith('-III')]\n",
    "    \n",
    "    path = direc + '/' + i + \".csv\"\n",
    "    \n",
    "    df1.to_csv(path)\n",
    "    df2.to_csv(path.replace(i,i+\"-II\"))\n",
    "    df3.to_csv(path.replace(i,i+\"-III\"))\n",
    "    \n",
    "    print(df.shape[0])\n",
    "    print(df1.shape[0]+df2.shape[0]+df3.shape[0])\n",
    "\n",
    "stfolder = direc\n",
    "print(index_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d6c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee14ae2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7cd17bd552f4953a02e80c1ccf1a41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32fbd0afdbb44379dbaf0f4ec1c20ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14020\\4275916856.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwgt_lot_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparse_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdayfirst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0musecols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Security Symbol\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Equal_Weightage\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Lotsize\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%d-%m-%Y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdayfirst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%d-%m-%Y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdayfirst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m#display(weight)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1251\u001b[0m             \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1253\u001b[1;33m                 \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1254\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_tups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m             \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_date_conversions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m             \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malldata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_do_date_conversions\u001b[1;34m(self, names, data)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_dates\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 820\u001b[1;33m             data, names = _process_date_conversion(\n\u001b[0m\u001b[0;32m    821\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_date_conv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_process_date_conversion\u001b[1;34m(data_dict, converter, parse_spec, index_col, index_names, columns, keep_date_col)\u001b[0m\n\u001b[0;32m   1187\u001b[0m                 \u001b[1;31m# Pyarrow engine returns Series which we need to convert to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m                 \u001b[1;31m# numpy array before converter, its a no-op for other parsers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1189\u001b[1;33m                 \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolspec\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolspec\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m                 new_name, col, old_names = _try_convert_dates(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36mconverter\u001b[1;34m(*date_cols)\u001b[0m\n\u001b[0;32m   1068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1070\u001b[1;33m                 return tools.to_datetime(\n\u001b[0m\u001b[0;32m   1071\u001b[0m                     \u001b[0mensure_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m                     \u001b[0mutc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m             \u001b[0mcache_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOutOfBoundsDatetime\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m             \u001b[1;31m# caching attempts to create a DatetimeIndex, which may raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0munique_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m             \u001b[0mcache_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m             \u001b[0mcache_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[1;31m# GH#39882 and GH#35888 in case of None and NaT we get duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[0mutc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtz\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"utc\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m     result, tz_parsed = objects_to_datetime64ns(\n\u001b[0m\u001b[0;32m    403\u001b[0m         \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[0mdayfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2222\u001b[0m     \u001b[0morder\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"F\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"C\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"F\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"C\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2223\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2224\u001b[1;33m         result, tz_parsed = tslib.array_to_datetime(\n\u001b[0m\u001b[0;32m   2225\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.parsing._parse_dateabbr_string\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\_strptime.py\u001b[0m in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    566\u001b[0m     \"\"\"Return a class cls instance based on the input string and the\n\u001b[0;32m    567\u001b[0m     format string.\"\"\"\n\u001b[1;32m--> 568\u001b[1;33m     \u001b[0mtt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfraction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgmtoff_fraction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_strptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m     \u001b[0mtzname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgmtoff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfraction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\_strptime.py\u001b[0m in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    345\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"stray %% in format '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0m_regex_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_regex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m     \u001b[0mfound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_regex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m         raise ValueError(\"time data %r does not match format %r\" %\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initial_equity = 1000000\n",
    "target_percent = [1,1.5,2,2.5,3]\n",
    "super_final = pd.DataFrame()\n",
    "super_final_delta = pd.DataFrame()\n",
    "initial_equity = 100000\n",
    "leverage = 5\n",
    "\n",
    "for t in tqdm(target_percent):\n",
    "    target = (initial_equity*t)/100\n",
    "    grp = exp_df.groupby(\"curr_exp_date\")\n",
    "    for name, group in tqdm(grp):\n",
    "        #print(name)\n",
    "\n",
    "        exx = grp.get_group(name)\n",
    "        final1 = exx[['Date']].copy()\n",
    "        final1['difference'] = 10000000\n",
    "        final1['delta'] = 100\n",
    "\n",
    "        date_min = exx['Date'].min()\n",
    "        date_max = exx['Date'].max()\n",
    "        delta_range = [15,20,25,30,35,40,45,50]\n",
    "        count = 0\n",
    "\n",
    "        weight = pd.read_csv(wgt_lot_path,parse_dates = [\"date\"],dayfirst = True,usecols = [\"Security Symbol\",\"Equal_Weightage\",\"date\",\"Lotsize\"])\n",
    "        weight = (weight[(weight['date'] >= pd.to_datetime(date_min, format = '%d-%m-%Y', dayfirst = True)) & (weight['date'] <= pd.to_datetime(date_max, format = '%d-%m-%Y', dayfirst = True))])\n",
    "        #display(weight)\n",
    "        wh_grp = weight.groupby(\"Security Symbol\")\n",
    "        exx[index + \"_OG_Weight\"] = 100\n",
    "        exx[index + \"_Lotsize\"] = index_lotsize\n",
    "\n",
    "        for i in stock_list:\n",
    "            try:\n",
    "                d1 = wh_grp.get_group(i)\n",
    "            except:\n",
    "                d1[i + \"_OG_Weight\"] = 0\n",
    "                d1[i + \"_Lotsize\"] = d1[\"Lotsize\"]\n",
    "                d1['Date'] = d1[\"date\"]\n",
    "                exx = pd.merge(exx,d1[[\"Date\",i + \"_OG_Weight\",i+ \"_Lotsize\"]],on= \"Date\", how='left')\n",
    "\n",
    "                continue\n",
    "            d1[i + \"_OG_Weight\"] = d1[\"Equal_Weightage\"]\n",
    "            d1[i + \"_Lotsize\"] = d1[\"Lotsize\"]\n",
    "            d1['Date'] = d1[\"date\"]\n",
    "            exx = pd.merge(exx,d1[[\"Date\",i + \"_OG_Weight\",i+ \"_Lotsize\"]],on= \"Date\", how='left')\n",
    "            exx['BANKNIFTY_Date_CE'] = exx['Date']\n",
    "        \n",
    "        exx.to_csv(output_path + '//' + 'exx_.csv')\n",
    "\n",
    "\n",
    "\n",
    "        for delta in delta_range:\n",
    "\n",
    "            #print(delta)\n",
    "\n",
    "            idx = pd.read_csv(index_file_path,usecols = [\"Date\",\"Ticker\",\"Option_Type\",\"Strike\",\n",
    "                                                                                \"OPT_Close\",\"EQ_Close\", \"IV\", 'Delta', f'Delta_{delta}_Strike'],parse_dates = [\"Date\"])\n",
    "\n",
    "            idx = (idx[(idx['Date'] >= pd.to_datetime(date_min, format = '%d-%m-%Y', dayfirst = True)) & (idx['Date'] <= pd.to_datetime(date_max, format = '%d-%m-%Y', dayfirst = True))])\n",
    "            idx = pd.merge(idx, exx, on = 'Date', how = 'left')\n",
    "            #display(idx)\n",
    "\n",
    "            idx_ce = idx[(idx[\"Strike\"] == idx[f\"Delta_{delta}_Strike\"]) & (idx[\"Option_Type\"] == \"CE\")].add_suffix(\"_CE\")\n",
    "            idx_pe = idx[(idx[\"Strike\"] == idx[f\"Delta_{delta}_Strike\"]) & (idx[\"Option_Type\"] == \"PE\")].add_suffix(\"_PE\")\n",
    "\n",
    "            final = idx_ce.merge(idx_pe, left_on='Date_CE', right_on='Date_PE').drop(columns = [\"Option_Type_PE\",\"Option_Type_CE\"])\n",
    "            #final = final.T.drop_duplicates().T  #Drop Duplicates Columns\n",
    "            final = final.add_prefix(index +\"_\")\n",
    "            final = final.sort_values(by=index +\"_\"+'Date_CE')\n",
    "            #final.to_csv(output_path+\"/check-1data.csv\")\n",
    "\n",
    "            for i in stock_list:\n",
    "                #print(i)\n",
    "                df1 = pd.read_csv(stfolder+ '/' + i + \".csv\",parse_dates = [\"Date\"],usecols = [\"Date\",\"Ticker\",\"Option_Type\",\"Strike\",\n",
    "                                                                                \"OPT_Close\",\"EQ_Close\",\"IV\", 'Delta', f\"Delta_{delta}_Strike\"])\n",
    "\n",
    "                df1 = (df1[(df1['Date'] >= pd.to_datetime(date_min, format = '%d-%m-%Y', dayfirst = True)) & (df1['Date'] <= pd.to_datetime(date_max, format = '%d-%m-%Y', dayfirst = True))])\n",
    "                #df1 = pd.merge(df1, exx, on = 'Date', how = 'left')\n",
    "\n",
    "\n",
    "                df_ce = df1[(df1[\"Strike\"] == df1[f\"Delta_{delta}_Strike\"]) & (df1[\"Option_Type\"] == \"CE\")].add_suffix(\"_CE\")\n",
    "                df_pe = df1[(df1[\"Strike\"] == df1[f\"Delta_{delta}_Strike\"]) & (df1[\"Option_Type\"] == \"PE\")].add_suffix(\"_PE\")\n",
    "                #print(df1.shape[0], df_ce.shape[0], df_pe.shape[0])\n",
    "                temp = df_ce.merge(df_pe, left_on='Date_CE', right_on='Date_PE').drop(columns = [\"Option_Type_PE\",\"Option_Type_CE\"])\n",
    "                #temp = temp.T.drop_duplicates().T\n",
    "                temp = temp.add_prefix(i +\"_\")\n",
    "                final = final.merge(temp,how='left',left_on=index + '_Date_CE', right_on= i + '_Date_CE')\n",
    "\n",
    "            #final = final.T.drop_duplicates().T\n",
    "            #final = final.drop_duplicates()\n",
    "            #display(final)\n",
    "\n",
    "            #exx.rename(columns = {'Date':'BANKNIFTY_Date_CE'}, inplace = True)\n",
    "\n",
    "            final = pd.merge(final, exx, on = 'BANKNIFTY_Date_CE', how = 'left')\n",
    "            final.to_csv(output_path + '//' + 'exx1.csv')\n",
    "\n",
    "\n",
    "\n",
    "            final['total_exposure'] = initial_equity*leverage*2\n",
    "\n",
    "            final[index + '_exposure'] = final['total_exposure']/2\n",
    "            final['stock_exposure'] = final['total_exposure']/2\n",
    "\n",
    "            final[index + '_qty'] = (final[index + '_exposure'])/final[index+'_EQ_Close_CE']\n",
    "            for i in stock_list:\n",
    "                final[i+'_qty'] = (final['stock_exposure']*final[i+'_OG_Weight']/100)/final[i+'_EQ_Close_CE']\n",
    "                \n",
    "            \n",
    "            filter_col = [col for col in final if (col.endswith('_qty') or col.endswith('_EQ_Close_CE'))]\n",
    "            final[filter_col] = final[filter_col].replace(np.nan,0)\n",
    "            \n",
    "            for i in stock_list:\n",
    "                if (final[i+'_qty'] == 0).all():\n",
    "                    final[i+'_OPT_Close_CE'] = 0\n",
    "            #final.to_csv(output_path + '//' + 'exx2.csv')\n",
    "\n",
    "            final['stock_premium'] = 0\n",
    "            \n",
    "            for i in stock_list:\n",
    "                final['stock_premium'] += final[i+'_OPT_Close_CE']*final[i+'_qty']\n",
    "\n",
    "            final['index_premium'] = final['BANKNIFTY_OPT_Close_CE']*final[index + '_qty']\n",
    "\n",
    "            final['total_premium'] = final['stock_premium'] - final['index_premium']\n",
    "\n",
    "            #display(final)\n",
    "\n",
    "\n",
    "            #final.to_csv(output_path + '//' + 'exx2.csv')\n",
    "\n",
    "            final['target_premium'] = target \n",
    "\n",
    "            final['difference-check'] = final['target_premium'] - final['total_premium']\n",
    "            final['Date'] = final['BANKNIFTY_Date_CE']\n",
    "\n",
    "            if count > 0:\n",
    "                final1 = final1.drop(['difference-check'], axis = 1)\n",
    "\n",
    "            final1 = pd.merge(final1, final[['Date', 'difference-check']], on='Date',how='left' )\n",
    "\n",
    "            final1['delta'] = np.where(abs(final1['difference-check']) < abs(final1['difference']), delta, final1['delta'])\n",
    "\n",
    "            final1['difference'] = np.where(abs(final1['difference-check']) < abs(final1['difference']), final1['difference-check'], final1['difference'])\n",
    "\n",
    "\n",
    "            count+=1\n",
    "\n",
    "\n",
    "\n",
    "            #display(final)\n",
    "            #final.to_csv(output_path + \"/expcheck.csv\")\n",
    "\n",
    "        if os.path.exists(output_path + \"/target_\" + str(t) + \"/super_final.csv\"):\n",
    "            final.to_csv(output_path + \"/target_\" + str(t) + \"/super_final.csv\", mode = 'a', header = False)\n",
    "        else:\n",
    "            final.to_csv(output_path + \"/target_\" + str(t) + \"/super_final.csv\")\n",
    "\n",
    "        if os.path.exists(output_path + \"/target_\" + str(t) + \"/super_final_delta.csv\"):\n",
    "            final1.to_csv(output_path + \"/target_\" + str(t) + \"/super_final_delta.csv\", mode = 'a', header = False)\n",
    "        else:\n",
    "            final1.to_csv(output_path + \"/target_\" + str(t) + \"/super_final_delta.csv\")\n",
    "\n",
    "    #    super_final = super_final.append(final) \n",
    "    #    super_final_delta = super_final_delta.append(final1) \n",
    "    #    display(super_final)\n",
    "    #    display(super_final_delta)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9ea94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "super_final.to_csv(output_path + '//' + 'super_final.csv')\n",
    "super_final1.to_csv(output_path + '//' + 'super_final1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea466244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce560b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"D:\\Correlation Backtest Data 2016-23\\Correlation 6-16 to 1-23 data\\Output Files - Only Calls\\exx1.csv\", parse_dates = ['BANKNIFTY_Date_CE'], dayfirst= True)\n",
    "leverage =5\n",
    "data['total_exposure'] = data['BANKNIFTY_EQ_Close_CE']*leverage*2\n",
    "\n",
    "data['index_exposure'] = data['total_exposure']/2\n",
    "\n",
    "for i in stock_list:\n",
    "    data[i+'_exposure'] = (data['total_exposure']/2)*(data[i+'_OG_Weight']/100)\n",
    "    if (data[i+'_OG_Weight'] == 0).all():\n",
    "        data[i+'_quantity'] = 0\n",
    "    else:\n",
    "        data[i+'_quantity'] = data[i+'_exposure']/data[i+'_EQ_Close_CE']\n",
    "    \n",
    "display(data)\n",
    "xxx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#ADDING QTYS\n",
    "result = data.copy()\n",
    "min_exp = []\n",
    "for idi, row in result.iterrows():\n",
    "    min_share_stock = row['Min_Share_Name'].replace(\"_Final_Weight\",\"\")\n",
    "    #print(min_share_stock)\n",
    "    value  = row[min_share_stock + \"_EQ_Close_CE\"]*row[min_share_stock + \"_Lotsize\"]\n",
    "    min_exp.append(value)\n",
    "    \n",
    "result[\"MinExp\"] = min_exp\n",
    "result[index + \"_exp\"] = (result[\"MinExp\"]/result[\"Min_Share_Value\"])\n",
    "#result[index + \"_lot\"] = (result[index + \"_exp\"]/(result[index + \"_Lotsize\"]*result[index + \"_EQ_Close_CE\"])).astype(int)\n",
    "result[index + \"_lot\"] = (result[index + \"_exp\"]/(result[index + \"_Lotsize\"]*result[index + \"_EQ_Close_CE\"]))\n",
    "result[index + \"_qty\"] = result[index + \"_lot\"]*result[index + \"_Lotsize\"]\n",
    "\n",
    "result.to_csv(output_path + '//' + 'resultt.csv')\n",
    "\n",
    "#for stocks with includeok=0, making '_Lotsize' & '_EQ_Close_CE' non-zero\n",
    "\n",
    "filter_col_Lotsize = [col for col in result if col.endswith('_Lotsize')]\n",
    "filter_col_Lotsize.remove(index + \"_Lotsize\")\n",
    "result[filter_col_Lotsize] = result[filter_col_Lotsize].replace(0,1)\n",
    "\n",
    "\n",
    "filter_col_EQ_Close = [col for col in result if col.endswith('_EQ_Close_CE')]\n",
    "filter_col_EQ_Close.remove(index + \"_EQ_Close_CE\")\n",
    "result[filter_col_EQ_Close] = result[filter_col_EQ_Close].replace(0,1)\n",
    "\n",
    "result['index_exp'] = result[index + \"_exp\"]\n",
    "\n",
    "result.to_csv(output_path + '//' + 'resulttcheckcheck.csv')\n",
    "\n",
    "result['stock_exp'] = 0\n",
    "\n",
    "for i in stock_list:\n",
    "    print(i)\n",
    "    if(i==min_share_stock):\n",
    "        result[index + \"_exp\"]\n",
    "        result[i + \"_Final_Weight\"]\n",
    "        result[i + \"_exp\"] = result[\"MinExp\"]\n",
    "        result[i  + \"_lot\"] = 1\n",
    "        result[i + \"_qty\"] = result[i + \"_lot\"]*result[i + \"_Lotsize\"]\n",
    "        \n",
    "        result['stock_exp'] += result[i + \"_exp\"]\n",
    "        \n",
    "    else:\n",
    "        result[index + \"_exp\"]\n",
    "        result[i + \"_Final_Weight\"]\n",
    "        result[i + \"_exp\"] = (result[index + \"_exp\"]*result[i + \"_Final_Weight\"])\n",
    "#         result[i  + \"_lot\"] = (result[i + \"_exp\"]/(result[i + \"_Lotsize\"]*result[i+ \"_EQ_Close_CE\"])).astype(int)\n",
    "        result[i  + \"_lot\"] = (result[i + \"_exp\"]/(result[i + \"_Lotsize\"]*result[i+ \"_EQ_Close_CE\"]))\n",
    "        result[i + \"_qty\"] = result[i + \"_lot\"]*result[i + \"_Lotsize\"]\n",
    "        \n",
    "        result['stock_exp'] += result[i + \"_exp\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef4f57c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dc378c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bd1b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
