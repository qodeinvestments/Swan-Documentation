{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b3225e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm.notebook import tqdm, trange \n",
    "import os\n",
    "import glob\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# to display maximum rows and columns\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc616722",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_path = r\"C:\\Sourav\\BANKNIFTY\\Monthly\\Greeks\\\\\"\n",
    "for file in tqdm(next(os.walk(chunks_path))[2]):\n",
    "    df = pd.read_csv(chunks_path + file)\n",
    "    df.to_csv(r\"C:\\Sourav\\BANKNIFTY\\Monthly\\GreeksCombined\\\\BANKNIFTY-I.csv\", mode='a',\n",
    "              header=not os.path.exists(r\"C:\\Sourav\\BANKNIFTY\\Monthly\\GreeksCombined\\\\BANKNIFTY-I.csv\",),\n",
    "              index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca798009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Sourav\\BANKNIFTY\\Monthly\\GreeksCombined\\BANKNIFTY-I.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "df['Time'] = pd.to_datetime(df['Time']).dt.time\n",
    "df = df.sort_values(by=['Date', 'Time', 'Option_Type', 'Final_strike']).reset_index(drop=True)\n",
    "df.to_csv(r\"C:\\Sourav\\BANKNIFTY\\Monthly\\GreeksCombined\\BANKNIFTYFinal-I.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74bbe68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# file paths\n",
    "output_path = r\"D:\\Greeks\\WeeklyI\\5-min\\AtTheMoney\\\\\"\n",
    "#underlying_path = r\"E:\\sourav\\strikeSelector\\strikeSelector\\input\\5Years\\EQTill04Jul2022\\AllSymbols\\\\\"\n",
    "dispersion_path = r\"D:\\Greeks\\WeeklyI\\5-min\\Greeks\\\\\"\n",
    "#equity_path = r\"E:\\sourav\\strikeSelector\\strikeSelector\\input\\5Years\\EQTill04Jul2022\\AllSymbols\\\\\"\n",
    "#misc_path = \"D:\\Sourav\\1-Min\\Misc\\\\\"\n",
    "\n",
    "# select delta values\n",
    "# delta_list = [0.05, 0.10, 0.15, 0.20, 0.25,\n",
    "#               0.30, 0.35, 0.40, 0.45, 0.50, \n",
    "#               0.55, 0.60, 0.65, 0.70, 0.75,\n",
    "#               0.80, 0.85, 0.90, 0.95]\n",
    "delta_list = [0.50]\n",
    "\n",
    "all_files = sorted(next(os.walk(dispersion_path))[2])\n",
    "#all_underlying_files = os.listdir(underlying_path)\n",
    "print(len(all_files))\n",
    "#print(len(all_underlying_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa1a7187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BankNifty_WeeklyI-2016.csv',\n",
       " 'BankNifty_WeeklyI-2017.csv',\n",
       " 'BankNifty_WeeklyI-2018.csv',\n",
       " 'BankNifty_WeeklyI-2019.csv',\n",
       " 'BankNifty_WeeklyI-2020.csv',\n",
       " 'BankNifty_WeeklyI-2021.csv',\n",
       " 'BankNifty_WeeklyI-2022.csv',\n",
       " 'BankNifty_WeeklyI-2023.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# files to be ignored\n",
    "#ignore_files = ['AUBANK-I.csv', 'AUBANK-II.csv', 'AUBANK-III.csv']\n",
    "\n",
    "#all_files = sorted(list(set(all_files) - set(ignore_files)))\n",
    "\n",
    "#print(len(all_underlying_files))\n",
    "all_files = all_files\n",
    "all_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aed7b28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# select particular files\n",
    "#all_files = ['IDFCFIRSTB-I.csv', 'IDFCFIRSTB-II.csv', 'IDFCFIRSTB-III.csv']\n",
    "\n",
    "print(len(all_files))\n",
    "#all_underlying_files = ['ACC.EQ-NSE.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e7c4b01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d03b55d8244f318d250fbe79425928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time :  2023-05-03 12:34:49.795608\n",
      "filename : BankNifty_WeeklyI-2016.csv\n",
      "float64\n",
      "symbolFilename : BankNifty_WeeklyI-2016\n",
      "symbol : BankNifty_WeeklyI-2016\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c729fc599cf1413cb451e57ee63f2679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End time :  2023-05-03 12:48:31.267758\n",
      "Start time :  2023-05-03 12:48:31.267758\n",
      "filename : BankNifty_WeeklyI-2017.csv\n",
      "float64\n",
      "symbolFilename : BankNifty_WeeklyI-2017\n",
      "symbol : BankNifty_WeeklyI-2017\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a637152b82444c1a612d73502a7c688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End time :  2023-05-03 13:14:35.780850\n",
      "Start time :  2023-05-03 13:14:35.780850\n",
      "filename : BankNifty_WeeklyI-2018.csv\n",
      "float64\n",
      "symbolFilename : BankNifty_WeeklyI-2018\n",
      "symbol : BankNifty_WeeklyI-2018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7179ef11eb144dfe91d464b1b239217f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End time :  2023-05-03 13:39:38.198073\n",
      "Start time :  2023-05-03 13:39:38.198073\n",
      "filename : BankNifty_WeeklyI-2019.csv\n",
      "float64\n",
      "symbolFilename : BankNifty_WeeklyI-2019\n",
      "symbol : BankNifty_WeeklyI-2019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd529db3dee14854b26c21ce67692401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End time :  2023-05-03 14:02:55.863032\n",
      "Start time :  2023-05-03 14:02:55.863032\n",
      "filename : BankNifty_WeeklyI-2020.csv\n",
      "float64\n",
      "symbolFilename : BankNifty_WeeklyI-2020\n",
      "symbol : BankNifty_WeeklyI-2020\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06445554120144ecb2e2bfaa5193b04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End time :  2023-05-03 14:23:44.063010\n",
      "Start time :  2023-05-03 14:23:44.063010\n",
      "filename : BankNifty_WeeklyI-2021.csv\n",
      "float64\n",
      "symbolFilename : BankNifty_WeeklyI-2021\n",
      "symbol : BankNifty_WeeklyI-2021\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4e1c4a0c1c4262b91e2aa236873608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36960 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End time :  2023-05-03 14:44:15.087357\n",
      "Start time :  2023-05-03 14:44:15.087357\n",
      "filename : BankNifty_WeeklyI-2022.csv\n",
      "float64\n",
      "symbolFilename : BankNifty_WeeklyI-2022\n",
      "symbol : BankNifty_WeeklyI-2022\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d52709dde4140d1af42b1dc24a042c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37050 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End time :  2023-05-03 15:07:49.300799\n",
      "Start time :  2023-05-03 15:07:49.300799\n",
      "filename : BankNifty_WeeklyI-2023.csv\n",
      "float64\n",
      "symbolFilename : BankNifty_WeeklyI-2023\n",
      "symbol : BankNifty_WeeklyI-2023\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20f6f2ab16d4420bc779ebd83152d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End time :  2023-05-03 15:13:10.899407\n",
      "Files processed : 8\n",
      "Files not processed : 0\n",
      "Not processed files : []\n"
     ]
    }
   ],
   "source": [
    "filesProcessed = 0\n",
    "filesNotProcessed = 0\n",
    "notProcessedFiles = []\n",
    "\n",
    "# load main csv\n",
    "for filename in tqdm(all_files):\n",
    "    print('Start time : ', datetime.now())\n",
    "    df = pd.read_csv(dispersion_path + filename)\n",
    "\n",
    "    df = df.rename(columns={'tickername' : 'Ticker'})\n",
    "#     df.drop(columns=df.columns[0], axis=1, inplace=True)\n",
    "    \n",
    "    # change date column to datetime format\n",
    "    df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "    \n",
    "    # remove 'Unnamed' columns in a csv\n",
    "    remove_cols = [col for col in df.columns if 'Unnamed' in col]\n",
    "    df.drop(remove_cols, axis='columns', inplace=True)   \n",
    "\n",
    "    #print(df.iloc[0:500])\n",
    "    print('filename :', filename)\n",
    "    \n",
    "    # change date column to datetime format\n",
    "    df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "\n",
    "    # replace $ character in a ticker with empty string ('')\n",
    "    df['Ticker'].replace({'$': None},inplace =True)\n",
    "    \n",
    "    \n",
    "    df['Old_Delta'] = df['Delta'].copy()\n",
    "    print(df['Delta'].dtype)\n",
    "    if df['Delta'].dtype == object:\n",
    "        print('Delta column is in string format.')\n",
    "        df['Delta'] = df['Delta'].str.replace('\\(|\\)', '')\n",
    "        df['Delta'] = df['Delta'].str.replace('\\+0j', '')\n",
    "        df['Delta'] = df['Delta'].str.replace('0j', '0')\n",
    "        #df.to_csv(output_path + 'IDFCFIRSTB.csv', index=False)\n",
    "        df['Delta'] = df['Delta'].astype(float)\n",
    "    \n",
    "    \n",
    "    #df = df.drop(['Strike'], axis=1)\n",
    "    \n",
    "    df.rename(columns={\n",
    "                       'Adj_Open' : 'OPT_Open',\n",
    "                       'Adj_High' : 'OPT_High',\n",
    "                       'Adj_Low' : 'OPT_Low',\n",
    "                       'Adj_Close' : 'OPT_Close',\n",
    "                       'Adj_Volume' : 'OPT_Contracts',\n",
    "                       'New_OI' : 'OPT_OI',\n",
    "                       'Final_strike' : 'Strike'\n",
    "                                            }, inplace=True)\n",
    "    df2 = df.copy()\n",
    "    \n",
    "\n",
    "    # extract Strike and Option Type from the Ticker if it's not there in the input file already.\n",
    "    \n",
    "#     df['Strike'] = df['Ticker'].str.extract('([0-9]+[./]*[0-9]*)').astype(float)\n",
    "    \n",
    "#     df['Option_Type'] = df[\"Ticker\"].str.split('-').str[0].str[-2:]\n",
    "\n",
    "#     df['Option_Type'] = np.where((df['Option_Type'] == 'CE') | (df['Option_Type'] == 'PE'),\n",
    "#                                  df['Option_Type'], 'XX')\n",
    "\n",
    "    \n",
    "    # get the symbol from filename\n",
    "    symbolFilename = filename.split('.')[0]\n",
    "    print('symbolFilename :', symbolFilename)\n",
    "    \n",
    "    # remove '-I'/'-II'/'-III' from filename\n",
    "    symbol = symbolFilename.replace('-III', '')\n",
    "    symbol = symbol.replace('-II', '')\n",
    "    symbol = symbol.replace('-I', '')\n",
    "    print('symbol :', symbol)\n",
    "    \n",
    "    # substitute any special characters ('-', '&', '_') in Dispersion file names with empty string ('_')\n",
    "    charactersDroppedSymbol = re.sub('\\ |\\_|\\.|\\-|\\&|\\;|\\:', '', symbol)\n",
    "\n",
    "    df2 = df.copy()\n",
    "    \n",
    "    ''' \n",
    "    for eqFilename in all_underlying_files:\n",
    "    \n",
    "        # replace any special characters ('-', '&', '_') in EQ file names with empty string ('')\n",
    "        charactersDroppedEQFilename = re.sub('\\_|\\-|\\&', '', eqFilename.split('.')[0]).replace('$', '')\n",
    "        \n",
    "#         print('charactersDroppedEQFilename :', charactersDroppedEQFilename)\n",
    "#         print('charactersDroppedSymbol :', charactersDroppedSymbol)\n",
    "        \n",
    "        # check if symbol and EQ filenames are same after special characters being dropped \n",
    "        if (charactersDroppedEQFilename == charactersDroppedSymbol):\n",
    "            \n",
    "            print('eqFilename :', eqFilename)\n",
    "            \n",
    "            df_underlying = pd.read_csv(equity_path + eqFilename)\n",
    "            \n",
    "            df_underlying.rename(columns={'Open' : 'EQ_Open',\n",
    "                                          'High' : 'EQ_High',\n",
    "                                          'Low' : 'EQ_Low',\n",
    "                                          'Close' : 'EQ_Close',\n",
    "                                          'Volume' : 'EQ_Volume'}, inplace=True)\n",
    "            df_underlying['Date'] = pd.to_datetime(df_underlying['Date'], dayfirst=True)\n",
    "    \n",
    "    # merge main csv and underlying csv\n",
    "    try:\n",
    "        df2 = df.merge(df_underlying[['Date', 'EQ_Open', 'EQ_High', 'EQ_Low', 'EQ_Close']], on=['Date'], how='left')\n",
    "        df_dates = df['Date'].unique()\n",
    "        df_underlying_dates = df_underlying['Date'].unique()\n",
    "        diff_dates = np.setdiff1d(df_dates, df_underlying_dates)\n",
    "        print('Dates missing in EQ file : ', diff_dates)\n",
    "        df_underlying = pd.DataFrame()\n",
    "        \n",
    "    except Exception as e1:\n",
    "        \n",
    "        #print('e :', e1)\n",
    "        print('Symbol not found in EQ folder : ', filename)\n",
    "        notProcessedFiles.append(filename)\n",
    "        filesNotProcessed += 1\n",
    "        continue    \n",
    "    '''\n",
    "\n",
    "    # get the hyphen type (-I, -II, -III) for grouping based on current\n",
    "    #df2['Ticker_Type'] = df2['Ticker'].str.split('-').str[1]\n",
    "    \n",
    "    # calculate difference between 'EQ_Close' and 'Strike' and get the minimum difference for a group\n",
    "    df2['Time'] = pd.to_datetime(df2['Time']).dt.time\n",
    "    \n",
    "    \n",
    "    exp_df = pd.read_csv(r\"E:\\sourav\\Database\\Codes\\CsvFiles\\WeeklyExpiry.csv\")\n",
    "    exp_df = exp_df.rename(columns={'date' : 'Date',\n",
    "                                    'Weekly_Expiry_Date' : 'Expiry_Date'})\n",
    "    exp_df['Date'] = pd.to_datetime(exp_df['Date'], dayfirst=True)\n",
    "    \n",
    "    df2 = df2.merge(exp_df[['Date', 'Expiry_Date']], on=['Date'], how='left') \n",
    "\n",
    "    df2['Difference'] = abs(df2['EQ_Close'] - df2['Strike'].astype(float))\n",
    "    dfg = df2.groupby(['Date', 'Time', 'Option_Type'])['Difference']\n",
    "    df2['Min'] = dfg.transform('min')\n",
    "    \n",
    "    # delete output file if it already exists\n",
    "    try:\n",
    "        os.remove(output_path + symbolFilename + '.csv')\n",
    "    except Exception as e:\n",
    "        #print('e1 : ', e)\n",
    "        pass\n",
    "    \n",
    "    # get 'At The Money' for each group\n",
    "    dfg = df2.groupby(['Date', 'Time', 'Option_Type'])\n",
    "    for name, group in tqdm(dfg):\n",
    "        \n",
    "        # get 'At The Money' for each group\n",
    "        try:\n",
    "            atTheMoney = max(group[(group['Difference'] == group['Min'])]['Strike'])\n",
    "            group['At_The_Money'] = atTheMoney\n",
    "        \n",
    "        except Exception as e:\n",
    "            #print('e3 : ', e)\n",
    "            group['At_The_Money'] = np.nan\n",
    "        \n",
    "        if symbol != 'BANKNIFTY':\n",
    "            group = group[['Date', 'Time', 'Ticker', 'OPT_Open', 'OPT_High', 'OPT_Low', 'OPT_Close', 'OPT_Contracts', 'First_OI', 'Last_OI',\n",
    "                       'Strike', 'Option_Type', 'Expiry_Date', 'IV', 'Delta', 'Theta', 'Gamma', 'Vega', 'EQ_Open', \n",
    "                       'EQ_High', 'EQ_Low', 'EQ_Close', 'At_The_Money']]\n",
    "            \n",
    "        else:\n",
    "            group = group[['Date', 'Time', 'Ticker', 'OPT_Open', 'OPT_High', 'OPT_Low', 'OPT_Close', 'OPT_Contracts', 'OPT_OI',\n",
    "                       'Strike', 'Option_Type', 'Expiry_Date', 'IV', 'Delta', 'Theta', 'Gamma', 'Vega', 'EQ_Open', \n",
    "                       'EQ_High', 'EQ_Low', 'EQ_Close', 'At_The_Money']]\n",
    "        \n",
    "        \n",
    "        # loop through different delta values\n",
    "        for delta in delta_list:\n",
    "            \n",
    "            # convert delta into string\n",
    "            # delta = str(int(delta * 100))\n",
    "            \n",
    "            if delta == 0.50:\n",
    "                group.rename(columns={'Min' : f'Delta_{delta*100:.0f}_Diff_Min',\n",
    "                                      'Difference' : f'Delta_{delta*100:.0f}_Diff'}, \n",
    "                             inplace=True)\n",
    "                group[f'Delta_{delta*100:.0f}_Strike'] = group['At_The_Money']\n",
    "            else:\n",
    "                try:\n",
    "                    if group['Option_Type'].iloc[0] == 'CE':\n",
    "                        group[f'Delta_{delta*100:.0f}_Diff'] = abs(group['Delta'] - delta)\n",
    "                    elif group['Option_Type'].iloc[0] == 'PE':\n",
    "                        group[f'Delta_{delta*100:.0f}_Diff'] = abs(group['Delta'] - (-delta))\n",
    "                    elif group['Option_Type'].iloc[0] == 'XX':\n",
    "                        group[f'Delta_{delta*100:.0f}_Diff'] = np.nan\n",
    "\n",
    "                    group[f'Delta_{delta*100:.0f}_Diff_Min'] = group[f'Delta_{delta*100:.0f}_Diff'].min()        \n",
    "\n",
    "                    try:\n",
    "                        deltaStrike = max(group[group[f'Delta_{delta*100:.0f}_Diff'] == group[f'Delta_{delta*100:.0f}_Diff_Min']]['Strike'])\n",
    "                        group[f'Delta_{delta*100:.0f}_Strike'] = deltaStrike\n",
    "                    except Exception as e:\n",
    "                        #print('e2 : ', e)\n",
    "                        group[f'Delta_{delta*100:.0f}_Strike'] = np.nan\n",
    "\n",
    "                    # dropping unnecessary columns\n",
    "                    group = group.drop([f'Delta_{delta*100:.0f}_Diff_Min', f'Delta_{delta*100:.0f}_Diff'], axis=1)\n",
    "                    \n",
    "                except Exception as e1:\n",
    "                    print('e1 : ', e1)\n",
    "                \n",
    "#         select required columns in the output csv   \n",
    "#         if symbol != 'BANKNIFTY':\n",
    "#             group = group[['Date', 'Ticker', 'OPT_Open', 'OPT_High', 'OPT_Low', 'OPT_Close', 'OPT_Contracts', 'OPT_OI',\n",
    "#                        'Strike', 'Option_Type', 'IV', 'Delta', 'Theta', 'Gamma', 'Vega', 'EQ_Open', \n",
    "#                        'EQ_High', 'EQ_Low', 'EQ_Close', 'EQ_Volume', 'At The Money', f'Delta_{delta*100:.0f}_Diff', f'Delta_{delta*100:.0f}_Diff_Min',\n",
    "#                        f'Delta_{delta*100:.0f}_Strike', 'Ticker_Type']]\n",
    "#         else:\n",
    "#             group = group[['Date', 'Ticker', 'OPT_Open', 'OPT_High', 'OPT_Low', 'OPT_Close', 'OPT_Contracts', 'OPT_OI',\n",
    "#                        'Strike', 'Option_Type', 'IV', 'Delta', 'Theta', 'Gamma', 'Vega', 'EQ_Open', \n",
    "#                        'EQ_High', 'EQ_Low', 'EQ_Close', 'At The Money', f'Delta_{delta*100:.0f}_Diff', f'Delta_{delta*100:.0f}_Diff_Min',\n",
    "#                        f'Delta_{delta*100:.0f}_Strike', 'Ticker_Type']]\n",
    "\n",
    "        # write output to csv\n",
    "        group.to_csv(output_path + symbolFilename + '.csv', mode='a', header=not os.path.exists(output_path + symbolFilename + '.csv'), index=False)\n",
    "    filesProcessed += 1\n",
    "    print('End time : ', datetime.now())\n",
    "\n",
    "print('Files processed :', filesProcessed)\n",
    "print('Files not processed :', filesNotProcessed)  \n",
    "print('Not processed files :', notProcessedFiles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9116a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "x1 = pd.read_csv(r\"E:\\sourav\\Database\\1-Min\\Greeks\\SBIN-I.csv\")\n",
    "print(x1.shape[0])\n",
    "x1['Date'] = pd.to_datetime(x1['Date'], dayfirst=True)\n",
    "date1 = datetime.strptime('30-01-2020', '%d-%m-%Y')\n",
    "date2 = datetime.strptime('31-01-2020', '%d-%m-%Y')\n",
    "\n",
    "x2 = x1[(x1['Date']==date2)]\n",
    "display(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f8b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2['Expiry_Date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f396c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = pd.read_csv(r\"D:\\Sourav\\1-Min\\Greeks\\HDFCBANK-I.csv\")\n",
    "x1['imag'] = np.imag(x1.Delta)\n",
    "x1['real'] = np.real(x1.Delta)\n",
    "display(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299ebd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1['Delta'].str.replace('\\(|\\)|\\+0j', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676996cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = pd.DataFrame({'Num' : [10+13j, 15+0j, 15]})\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e3c996",
   "metadata": {},
   "source": [
    "## Append -I, -II and -III files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85e4310",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = r\"D:\\Sourav\\EOD\\05-50DeltaStrikesAddedWithNewClose\\\\\"\n",
    "output_path = r\"D:\\Sourav\\BankNiftyConstituents2011-2015-Merged\\\\\"\n",
    "symbols = next(os.walk(input_path))[2]\n",
    "\n",
    "for i in tqdm(range(len(symbols))):\n",
    "    symbols[i] = symbols[i].replace('-III.csv', '').replace('-II.csv', '').replace('-I.csv', '')\n",
    "    \n",
    "symbols = sorted(set(symbols))\n",
    "symbols = ['ICICIBANK']\n",
    "symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dae6a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyphens = ['-I', '-II', '-III']\n",
    "\n",
    "for symbol in tqdm(symbols):\n",
    "    df = pd.DataFrame()\n",
    "    sum1 = 0\n",
    "    for i in hyphens:\n",
    "        file_path = input_path + symbol + i + '.csv'\n",
    "        if os.path.isfile(file_path):\n",
    "            df1 = pd.read_csv(file_path)\n",
    "            df = df.append(df1)\n",
    "        df.to_csv(output_path + symbol + '.csv', index=False)\n",
    "        sum1 += df1.shape[0]\n",
    "    print(sum1)\n",
    "    print(symbol + ' : ' + str(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f6f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyphens = ['-I', '-II', '-III']\n",
    "\n",
    "for symbol in tqdm(symbols):\n",
    "    df = pd.DataFrame()\n",
    "    sum1 = 0\n",
    "    for i in hyphens:\n",
    "        file_path = input_path + symbol + i + '.csv'\n",
    "        if os.path.isfile(file_path):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3460db",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = r\"D:\\Sourav\\BN\\05-50DeltaStrikesAdded\\\\\"\n",
    "new_close_path = r\"D:\\purvang\\BN\\New Close\\\\\"\n",
    "output_path = r\"D:\\Sourav\\BN\\05-50DeltaStrikesAddedFutMonthly\\\\\"\n",
    "\n",
    "symbols = next(os.walk(input_path))[2]\n",
    "#symbols = ['AUBANK-I.csv', 'AUBANK-II.csv', 'AUBANK-III.csv']\n",
    "\n",
    "for i in tqdm(range(len(symbols))):\n",
    "    symbols[i] = symbols[i].replace('-III.csv', '').replace('-II.csv', '').replace('-I.csv', '')\n",
    "    \n",
    "symbols = sorted(set(symbols))\n",
    "symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0436ff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyphens = ['-I', '-II', '-III']\n",
    "\n",
    "for symbol in tqdm(symbols):\n",
    "    df = pd.DataFrame()\n",
    "    sum1 = 0\n",
    "    print(symbol)\n",
    "    for i in tqdm(hyphens):\n",
    "        print(i)\n",
    "        file_path = input_path + symbol + i + '.csv'\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "        df['Ticker'] = np.where(df['Option_Type']=='XX', symbol + 'Fut_Monthly' + ' - ' + i[1:],\n",
    "                                df['Ticker'])\n",
    "        file_path = new_close_path + '_' + symbol + i + '_adj.csv.csv'\n",
    "        if os.path.isfile(file_path):\n",
    "            new_close_df = pd.read_csv(file_path)\n",
    "            \n",
    "            new_close_df['Date'] = pd.to_datetime(new_close_df['Date'], dayfirst=True)\n",
    "            \n",
    "            new_close_df['Remainder'] = new_close_df['Adj_strike'] % new_close_df['Adj_strike'].astype(int)\n",
    "            \n",
    "            new_close_df['Ticker'] = np.where(new_close_df['Remainder']==0, \n",
    "                            symbol + new_close_df['Adj_strike'].astype(int).astype(str) + new_close_df['OPTION_TYP'] + ' - ' + i[1:],\n",
    "                            symbol + new_close_df['Adj_strike'].astype(float).astype(str) + new_close_df['OPTION_TYP'] + ' - ' + i[1:])            \n",
    "            \n",
    "            new_close_df['Ticker'] = np.where(new_close_df['OPTION_TYP']=='XX', symbol + 'Fut_Monthly' + ' - ' + i[1:], \n",
    "                                              new_close_df['Ticker'])\n",
    "            \n",
    "            df = df.drop(['OPT_Close'], axis=1)\n",
    "            new_close_df = new_close_df.drop(['Remainder'], axis=1)\n",
    "            df = df.merge(new_close_df[['Date', 'Ticker', 'new_close']], on=['Date', 'Ticker'], how='left')\n",
    "            \n",
    "            \n",
    "            df = df.rename(columns={'new_close' : 'OPT_Close'})\n",
    "            df = df[['Date', 'Ticker', 'OPT_Open', 'OPT_High', 'OPT_Low', 'OPT_Close', 'OPT_Contracts', 'OPT_OI', \n",
    "                     'Strike', 'Option_Type', 'EXPIRY_DT', 'IV', 'Delta', 'Theta', 'Gamma', 'Vega',  \n",
    "                     'EQ_Open',  'EQ_High',   'EQ_Low',  'EQ_Close',  'At_The_Money',  'Delta_5_Strike',  \n",
    "                     'Delta_10_Strike', 'Delta_15_Strike',  'Delta_20_Strike',  'Delta_25_Strike',  \n",
    "                     'Delta_30_Strike', 'Delta_35_Strike', 'Delta_40_Strike',  'Delta_45_Strike', 'Delta_50_Strike']]\n",
    "            df.to_csv(output_path + symbol + i + '.csv' ,index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af073927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
