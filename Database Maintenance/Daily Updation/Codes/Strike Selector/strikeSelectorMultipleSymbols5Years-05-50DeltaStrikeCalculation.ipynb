{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b3225e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm.notebook import tqdm, trange \n",
    "import os\n",
    "import glob\n",
    "import traceback\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# to display maximum rows and columns\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74bbe68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "1047\n"
     ]
    }
   ],
   "source": [
    "# file paths\n",
    "output_path = r\"D:\\Sourav\\Stock-EOD-05-95DeltaStrikesDividendStocks\\\\\"\n",
    "underlying_path = r\"E:\\sourav\\strikeSelector\\strikeSelector\\input\\5Years\\EQTill04Jul2022\\AllSymbols\\\\\"\n",
    "dispersion_path = r\"D:\\Sourav\\Stocks-EOD-GreeksDividendStocks\\\\\"\n",
    "equity_path = r\"E:\\sourav\\strikeSelector\\strikeSelector\\input\\5Years\\EQTill04Jul2022\\AllSymbols\\\\\"\n",
    "\n",
    "# select delta values\n",
    "delta_list = [0.05, 0.10, 0.15, 0.20, 0.25,\n",
    "              0.30, 0.35, 0.40, 0.45, 0.50, \n",
    "              0.55, 0.60, 0.65, 0.70, 0.75, \n",
    "              0.80, 0.85, 0.90, 0.95]\n",
    "\n",
    "all_files = sorted(next(os.walk(dispersion_path))[2])\n",
    "all_underlying_files = os.listdir(underlying_path)\n",
    "print(len(all_files))\n",
    "print(len(all_underlying_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa1a7187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "['IOC-I.csv', 'IOC-II.csv', 'IOC-III.csv']\n"
     ]
    }
   ],
   "source": [
    "# files to be ignored\n",
    "#ignore_files = ['AUBANK-I.csv', 'AUBANK-II.csv', 'AUBANK-III.csv']\n",
    "#all_files = sorted(list(set(all_files) - set(ignore_files)))\n",
    "\n",
    "symbol = 'IOC'\n",
    "all_files = [f'{symbol}-I.csv', f'{symbol}-II.csv', f'{symbol}-III.csv']\n",
    "print(len(all_files))\n",
    "\n",
    "# symbols = next(os.walk(output_path))[2]\n",
    "# print(len(symbols))\n",
    "# all_files = np.setdiff1d(all_files, symbols)\n",
    "print((all_files))\n",
    "#print(len(all_underlying_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e7c4b01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-15 12:39:14.064035\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db973c71768e4c80a2c45b607eeeb518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time :  2023-06-15 12:39:14.071503\n",
      "D:\\Sourav\\Stocks-EOD-GreeksDividendStocks\\\\IOC-I.csv\n",
      "69998\n",
      "filename : IOC-I.csv\n",
      "symbolFilename : IOC-I\n",
      "symbol : IOC\n",
      "69998\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793099c20618416d827087491e6997d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End time :  2023-06-15 12:43:19.132180\n",
      "Start time :  2023-06-15 12:43:19.147772\n",
      "D:\\Sourav\\Stocks-EOD-GreeksDividendStocks\\\\IOC-II.csv\n",
      "19767\n",
      "filename : IOC-II.csv\n",
      "symbolFilename : IOC-II\n",
      "symbol : IOC\n",
      "19767\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f342fce2031e493095db0d925e8abe52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End time :  2023-06-15 12:45:47.579191\n",
      "Start time :  2023-06-15 12:45:47.579191\n",
      "D:\\Sourav\\Stocks-EOD-GreeksDividendStocks\\\\IOC-III.csv\n",
      "430\n",
      "filename : IOC-III.csv\n",
      "symbolFilename : IOC-III\n",
      "symbol : IOC\n",
      "430\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27800ff046d14cab95989a71e8d82f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/321 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End time :  2023-06-15 12:46:01.196044\n",
      "Files processed : 3\n",
      "Files not processed : 0\n",
      "Not processed files : []\n",
      "2023-06-15 12:46:01.196044\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "filesProcessed = 0\n",
    "filesNotProcessed = 0\n",
    "notProcessedFiles = []\n",
    "\n",
    "# load main csv\n",
    "for filename in tqdm(all_files):\n",
    "    print('Start time : ', datetime.datetime.now())\n",
    "    print(dispersion_path + filename)\n",
    "    df = pd.read_csv(dispersion_path + filename)\n",
    "    print(df.shape[0])\n",
    "    df = df.rename(columns={'tickername' : 'Ticker'})\n",
    "#     df.drop(columns=df.columns[0], axis=1, inplace=True)\n",
    "      \n",
    "    \n",
    "    # remove 'Unnamed' columns in a csv\n",
    "    remove_cols = [col for col in df.columns if 'Unnamed' in col]\n",
    "    df.drop(remove_cols, axis='columns', inplace=True)   \n",
    "\n",
    "    #print(df.iloc[0:500])\n",
    "    print('filename :', filename)\n",
    "    \n",
    "    # change date column to datetime format\n",
    "    df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "\n",
    "    # replace $ character in a ticker with empty string ('')\n",
    "    df['Ticker'].replace({'$': None},inplace =True)\n",
    "    \n",
    "    \n",
    "    #df = df.drop(['Strike'], axis=1)\n",
    "    \n",
    "    df.rename(columns={\n",
    "                       'Adj_Open' : 'OPT_Open',\n",
    "                       'Adj_High' : 'OPT_High',\n",
    "                       'Adj_Low' : 'OPT_Low',\n",
    "                       'Adj_Close' : 'OPT_Close',\n",
    "                       'Adj_Volume' : 'OPT_Contracts',\n",
    "                       'Volume' : 'OPT_Contracts',\n",
    "                        #'New_OI' : 'OPT_OI',\n",
    "                       'Last_OI' : 'OPT_OI',\n",
    "                       'OpenInterest' : 'OPT_OI',\n",
    "                       'Final_strike' : 'Strike',\n",
    "                       'CONTRACTS' : 'OPT_Contracts',\n",
    "                       'OPEN_INT' : 'OPT_OI'}, inplace=True)\n",
    "    df2 = df.copy()\n",
    "    \n",
    "\n",
    "    # extract Strike and Option Type from the Ticker if it's not there in the input file already.\n",
    "    \n",
    "#     df['Strike'] = df['Ticker'].str.extract('([0-9]+[./]*[0-9]*)').astype(float)\n",
    "    \n",
    "#     df['Option_Type'] = df[\"Ticker\"].str.split('-').str[0].str[-2:]\n",
    "\n",
    "#     df['Option_Type'] = np.where((df['Option_Type'] == 'CE') | (df['Option_Type'] == 'PE'),\n",
    "#                                  df['Option_Type'], 'XX')\n",
    "\n",
    "    \n",
    "    # get the symbol from filename\n",
    "    symbolFilename = filename.split('.')[0]\n",
    "    print('symbolFilename :', symbolFilename)\n",
    "    \n",
    "    # remove '-I'/'-II'/'-III' from filename\n",
    "    symbol = symbolFilename.replace('-III', '')\n",
    "    symbol = symbol.replace('-VIII', '')\n",
    "    symbol = symbol.replace('-VII', '')\n",
    "    symbol = symbol.replace('-VI', '')\n",
    "    symbol = symbol.replace('-V', '')\n",
    "    symbol = symbol.replace('-IV', '')\n",
    "    symbol = symbol.replace('-II', '')\n",
    "    symbol = symbol.replace('-I', '')\n",
    "    print('symbol :', symbol)\n",
    "    \n",
    "    # substitute any special characters ('-', '&', '_') in Dispersion file names with empty string ('_')\n",
    "    charactersDroppedSymbol = re.sub('\\ |\\_|\\.|\\-|\\&|\\;|\\:', '', symbol)\n",
    "\n",
    "    df2 = df.copy()\n",
    "    \n",
    "    ''' \n",
    "    for eqFilename in all_underlying_files:\n",
    "    \n",
    "        # replace any special characters ('-', '&', '_') in EQ file names with empty string ('')\n",
    "        charactersDroppedEQFilename = re.sub('\\_|\\-|\\&', '', eqFilename.split('.')[0]).replace('$', '')\n",
    "        \n",
    "#         print('charactersDroppedEQFilename :', charactersDroppedEQFilename)\n",
    "#         print('charactersDroppedSymbol :', charactersDroppedSymbol)\n",
    "        \n",
    "        # check if symbol and EQ filenames are same after special characters being dropped \n",
    "        if (charactersDroppedEQFilename == charactersDroppedSymbol):\n",
    "            \n",
    "            print('eqFilename :', eqFilename)\n",
    "            \n",
    "            df_underlying = pd.read_csv(equity_path + eqFilename)\n",
    "            \n",
    "            df_underlying.rename(columns={'Open' : 'EQ_Open',\n",
    "                                          'High' : 'EQ_High',\n",
    "                                          'Low' : 'EQ_Low',\n",
    "                                          'Close' : 'EQ_Close',\n",
    "                                          'Volume' : 'EQ_Volume'}, inplace=True)\n",
    "            df_underlying['Date'] = pd.to_datetime(df_underlying['Date'], dayfirst=True)\n",
    "    \n",
    "    # merge main csv and underlying csv\n",
    "    try:\n",
    "        df2 = df.merge(df_underlying[['Date', 'EQ_Open', 'EQ_High', 'EQ_Low', 'EQ_Close']], on=['Date'], how='left')\n",
    "        df_dates = df['Date'].unique()\n",
    "        df_underlying_dates = df_underlying['Date'].unique()\n",
    "        diff_dates = np.setdiff1d(df_dates, df_underlying_dates)\n",
    "        print('Dates missing in EQ file : ', diff_dates)\n",
    "        df_underlying = pd.DataFrame()\n",
    "        \n",
    "    except Exception as e1:\n",
    "        \n",
    "        #print('e :', e1)\n",
    "        print('Symbol not found in EQ folder : ', filename)\n",
    "        notProcessedFiles.append(filename)\n",
    "        filesNotProcessed += 1\n",
    "        continue    \n",
    "    '''\n",
    "\n",
    "    # get the hyphen type (-I, -II, -III) for grouping based on current\n",
    "    #df2['Ticker_Type'] = df2['Ticker'].str.split('-').str[1]\n",
    "    \n",
    "    \n",
    "    #df2 = df2[df2['OPT_Contracts']>=1000]\n",
    "    \n",
    "    # calculate difference between 'EQ_Close' and 'Strike' and get the minimum difference for a group\n",
    "    df2['Difference'] = abs(df2['EQ_Close'] - df2['Strike'].astype(float))\n",
    "    dfg = df2.groupby(['Date', 'Option_Type'])['Difference']\n",
    "    df2['Min'] = dfg.transform('min')\n",
    "    \n",
    "    # delete output file if it already exists\n",
    "    try:\n",
    "        os.remove(output_path + symbolFilename + '.csv')\n",
    "    except Exception as e:\n",
    "        #print('e1 : ', e)\n",
    "        pass\n",
    "    \n",
    "    print(df2.shape[0])\n",
    "    #print(df2.columns)\n",
    "    \n",
    "    # get 'At The Money' for each group\n",
    "    dfg = df2.groupby(['Date', 'Option_Type'])\n",
    "    for name, group in tqdm(dfg):\n",
    "        \n",
    "        # get 'At The Money' for each group\n",
    "        try:\n",
    "            atTheMoney = max(group[(group['Difference'] == group['Min'])]['Strike'])\n",
    "            group['At_The_Money'] = atTheMoney\n",
    "        \n",
    "        except Exception as e:\n",
    "            #print('e3 : ', e)\n",
    "            group['At_The_Money'] = np.nan\n",
    "    \n",
    "        if symbol != 'BANKNIFTY':\n",
    "            group = group[['Date', 'Ticker', 'OPT_Open', 'OPT_High', 'OPT_Low', 'OPT_Close', 'OPT_Contracts', 'OPT_OI',\n",
    "                       'Strike', 'Option_Type', 'Expiry_Date', 'IV', 'Delta', 'Theta', 'Gamma', 'Vega', 'EQ_Open', \n",
    "                       'EQ_High', 'EQ_Low', 'EQ_Close', 'At_The_Money']]\n",
    "        else:\n",
    "            group = group[['Date', 'Ticker', 'OPT_Open', 'OPT_High', 'OPT_Low', 'OPT_Close', 'OPT_Contracts', 'OPT_OI',\n",
    "                       'Strike', 'Option_Type', 'Expiry_Date', 'IV', 'Delta', 'Theta', 'Gamma', 'Vega', 'EQ_Open', \n",
    "                       'EQ_High', 'EQ_Low', 'EQ_Close', 'At_The_Money']]\n",
    "        \n",
    "        # loop through different delta values\n",
    "        for delta in delta_list:\n",
    "            \n",
    "            # convert delta into string\n",
    "            # delta = str(int(delta * 100))\n",
    "            \n",
    "            if delta == 0.50:\n",
    "                group.rename(columns={'Min' : f'Delta_{delta*100:.0f}_Diff_Min',\n",
    "                                      'Difference' : f'Delta_{delta*100:.0f}_Diff'}, \n",
    "                             inplace=True)\n",
    "                group[f'Delta_{delta*100:.0f}_Strike'] = group['At_The_Money']\n",
    "            else:\n",
    "                if group['Option_Type'].iloc[0] == 'CE':\n",
    "                    group[f'Delta_{delta*100:.0f}_Diff'] = abs(group['Delta'] - delta)\n",
    "                elif group['Option_Type'].iloc[0] == 'PE':\n",
    "                    group[f'Delta_{delta*100:.0f}_Diff'] = abs(group['Delta'] - (-delta))\n",
    "                elif group['Option_Type'].iloc[0] == 'XX':\n",
    "                    group[f'Delta_{delta*100:.0f}_Diff'] = np.nan\n",
    "\n",
    "                group[f'Delta_{delta*100:.0f}_Diff_Min'] = group[f'Delta_{delta*100:.0f}_Diff'].min()        \n",
    "\n",
    "                try:\n",
    "                    deltaStrike = max(group[group[f'Delta_{delta*100:.0f}_Diff'] == group[f'Delta_{delta*100:.0f}_Diff_Min']]['Strike'])\n",
    "                    group[f'Delta_{delta*100:.0f}_Strike'] = deltaStrike\n",
    "                except Exception as e:\n",
    "                    #print('e2 : ', e)\n",
    "                    group[f'Delta_{delta*100:.0f}_Strike'] = np.nan\n",
    "\n",
    "                # dropping unnecessary columns\n",
    "                group = group.drop([f'Delta_{delta*100:.0f}_Diff_Min', f'Delta_{delta*100:.0f}_Diff'], axis=1)\n",
    "                \n",
    "#         select required columns in the output csv   \n",
    "#         if symbol != 'BANKNIFTY':\n",
    "#             group = group[['Date', 'Ticker', 'OPT_Open', 'OPT_High', 'OPT_Low', 'OPT_Close', 'OPT_Contracts', 'OPT_OI',\n",
    "#                        'Strike', 'Option_Type', 'IV', 'Delta', 'Theta', 'Gamma', 'Vega', 'EQ_Open', \n",
    "#                        'EQ_High', 'EQ_Low', 'EQ_Close', 'EQ_Volume', 'At The Money', f'Delta_{delta*100:.0f}_Diff', f'Delta_{delta*100:.0f}_Diff_Min',\n",
    "#                        f'Delta_{delta*100:.0f}_Strike', 'Ticker_Type']]\n",
    "#         else:\n",
    "#             group = group[['Date', 'Ticker', 'OPT_Open', 'OPT_High', 'OPT_Low', 'OPT_Close', 'OPT_Contracts', 'OPT_OI',\n",
    "#                        'Strike', 'Option_Type', 'IV', 'Delta', 'Theta', 'Gamma', 'Vega', 'EQ_Open', \n",
    "#                        'EQ_High', 'EQ_Low', 'EQ_Close', 'At The Money', f'Delta_{delta*100:.0f}_Diff', f'Delta_{delta*100:.0f}_Diff_Min',\n",
    "#                        f'Delta_{delta*100:.0f}_Strike', 'Ticker_Type']]\n",
    "\n",
    "        # write output to csv\n",
    "        group.to_csv(output_path + symbolFilename + '.csv', mode='a', header=not os.path.exists(output_path + symbolFilename + '.csv'), index=False)\n",
    "    filesProcessed += 1\n",
    "    print('End time : ', datetime.datetime.now())\n",
    "\n",
    "print('Files processed :', filesProcessed)\n",
    "print('Files not processed :', filesNotProcessed)  \n",
    "print('Not processed files :', notProcessedFiles)\n",
    "print(datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82876329",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"E:\\sourav\\BANKNIFTYConstituents\\BANKNIFTYMonthly\\05-95DeltaStrikes\\BANKNIFTY-I.csv\")\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e3c996",
   "metadata": {},
   "source": [
    "## Append -I, -II and -III files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85e4310",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = r\"C:\\Sourav\\BANKNIFTYConstituents27-01-2023to15-03-2023\\05-95DeltaStrikes\\\\\"\n",
    "output_path = r\"C:\\Sourav\\BANKNIFTYConstituents27-01-2023to15-03-2023\\Combined\\\\\"\n",
    "symbols = next(os.walk(input_path))[2]\n",
    "\n",
    "for i in tqdm(range(len(symbols))):\n",
    "    symbols[i] = symbols[i].replace('-III.csv', '').replace('-II.csv', '').replace('-I.csv', '')\n",
    "    \n",
    "symbols = sorted(set(symbols))\n",
    "#symbols = ['ICICIBANK']\n",
    "symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dae6a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyphens = ['-I', '-II', '-III']\n",
    "\n",
    "for symbol in tqdm(symbols):\n",
    "    print(symbol)\n",
    "    sum1 = 0\n",
    "    for i in hyphens:\n",
    "        print(i)\n",
    "        file_path = input_path + symbol + i + '.csv'\n",
    "        if os.path.isfile(file_path):\n",
    "            df1 = pd.read_csv(file_path)\n",
    "            #df = df.append(df1)\n",
    "            df1.to_csv(output_path + symbol + '.csv', mode='a', header=not os.path.exists(output_path + symbol + '.csv'),\n",
    "                       index=False)\n",
    "        sum1 += df1.shape[0]\n",
    "    print(sum1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f6f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyphens = ['-I', '-II', '-III']\n",
    "\n",
    "for symbol in tqdm(symbols):\n",
    "    df = pd.DataFrame()\n",
    "    sum1 = 0\n",
    "    for i in hyphens:\n",
    "        file_path = input_path + symbol + i + '.csv'\n",
    "        if os.path.isfile(file_path):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3460db",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = r\"D:\\Sourav\\BN\\05-50DeltaStrikesAdded\\\\\"\n",
    "new_close_path = r\"D:\\purvang\\BN\\New Close\\\\\"\n",
    "output_path = r\"D:\\Sourav\\BN\\05-50DeltaStrikesAddedFutMonthly\\\\\"\n",
    "\n",
    "symbols = next(os.walk(input_path))[2]\n",
    "#symbols = ['AUBANK-I.csv', 'AUBANK-II.csv', 'AUBANK-III.csv']\n",
    "\n",
    "for i in tqdm(range(len(symbols))):\n",
    "    symbols[i] = symbols[i].replace('-III.csv', '').replace('-II.csv', '').replace('-I.csv', '')\n",
    "    \n",
    "symbols = sorted(set(symbols))\n",
    "symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0436ff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyphens = ['-I', '-II', '-III']\n",
    "\n",
    "for symbol in tqdm(symbols):\n",
    "    df = pd.DataFrame()\n",
    "    sum1 = 0\n",
    "    print(symbol)\n",
    "    for i in tqdm(hyphens):\n",
    "        print(i)\n",
    "        file_path = input_path + symbol + i + '.csv'\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "        df['Ticker'] = np.where(df['Option_Type']=='XX', symbol + 'Fut_Monthly' + ' - ' + i[1:],\n",
    "                                df['Ticker'])\n",
    "        file_path = new_close_path + '_' + symbol + i + '_adj.csv.csv'\n",
    "        if os.path.isfile(file_path):\n",
    "            new_close_df = pd.read_csv(file_path)\n",
    "            \n",
    "            new_close_df['Date'] = pd.to_datetime(new_close_df['Date'], dayfirst=True)\n",
    "            \n",
    "            new_close_df['Remainder'] = new_close_df['Adj_strike'] % new_close_df['Adj_strike'].astype(int)\n",
    "            \n",
    "            new_close_df['Ticker'] = np.where(new_close_df['Remainder']==0, \n",
    "                            symbol + new_close_df['Adj_strike'].astype(int).astype(str) + new_close_df['OPTION_TYP'] + ' - ' + i[1:],\n",
    "                            symbol + new_close_df['Adj_strike'].astype(float).astype(str) + new_close_df['OPTION_TYP'] + ' - ' + i[1:])            \n",
    "            \n",
    "            new_close_df['Ticker'] = np.where(new_close_df['OPTION_TYP']=='XX', symbol + 'Fut_Monthly' + ' - ' + i[1:], \n",
    "                                              new_close_df['Ticker'])\n",
    "            \n",
    "            df = df.drop(['OPT_Close'], axis=1)\n",
    "            new_close_df = new_close_df.drop(['Remainder'], axis=1)\n",
    "            df = df.merge(new_close_df[['Date', 'Ticker', 'new_close']], on=['Date', 'Ticker'], how='left')\n",
    "            \n",
    "            \n",
    "            df = df.rename(columns={'new_close' : 'OPT_Close'})\n",
    "            df = df[['Date', 'Ticker', 'OPT_Open', 'OPT_High', 'OPT_Low', 'OPT_Close', 'OPT_Contracts', 'OPT_OI', \n",
    "                     'Strike', 'Option_Type', 'EXPIRY_DT', 'IV', 'Delta', 'Theta', 'Gamma', 'Vega',  \n",
    "                     'EQ_Open',  'EQ_High',   'EQ_Low',  'EQ_Close',  'At_The_Money',  'Delta_5_Strike',  \n",
    "                     'Delta_10_Strike', 'Delta_15_Strike',  'Delta_20_Strike',  'Delta_25_Strike',  \n",
    "                     'Delta_30_Strike', 'Delta_35_Strike', 'Delta_40_Strike',  'Delta_45_Strike', 'Delta_50_Strike']]\n",
    "            df.to_csv(output_path + symbol + i + '.csv' ,index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af073927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
