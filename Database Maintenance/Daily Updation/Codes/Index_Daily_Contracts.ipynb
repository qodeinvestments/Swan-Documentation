{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18889974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a date in YYYY-MM-DD format 2023-05-10\n",
      "r10052023\n",
      "BANKNIFTY CONTRACTS BEING CREATED\n",
      "Sanity Check Success\n",
      "BANKNIFTY MONTHLY CONTRACTS CREATED\n",
      "[0.0, 1.0, 2.0, 3.0, 4.0, 7.0, 11.0, 10000.0]\n",
      "BANKNIFTY WEEKLY CONTRACTS CREATED\n",
      "BANKNIFTY QUARTERLY CONTRACTS CREATED\n",
      "BANKNIFTY HALF-YEARLY-I CREATED\n",
      "BANKNIFTY-QUARTERLY-III not found\n",
      "BANKNIFTY-QUARTERLY-IV not found\n",
      "BANKNIFTY HALFYEARLY CONTRACTS CREATED\n",
      "0 I\n",
      "1 II\n",
      "2 III\n",
      "BANKNIFTY QUARTERLY-III does not exist\n",
      "3 III\n",
      "BANKNIFTY QUARTERLY-III does not exist\n",
      "Dataframe is empty!!!\n",
      "BANKNIFTY YEARLY CONTRACTS CREATED\n",
      "\n",
      "BANKNIFTY CONTRACTS CREATED\n",
      "\n",
      "\n",
      "NIFTY CONTRACTS BEING CREATED\n",
      "Sanity Check Success\n",
      "NIFTY MONTHLY CONTRACTS CREATED\n",
      "[0.0, 1.0, 2.0, 3.0, 4.0, 7.0, 11.0, 10000.0]\n",
      "NIFTY WEEKLY CONTRACTS CREATED\n",
      "NIFTY QUARTERLY CONTRACTS CREATED\n",
      "Success\n",
      "NIFTY HALF YEARLY CONTRACTS CREATED\n",
      "0 YEARLY I HALFYEARLY I II\n",
      "1 YEARLY II HALFYEARLY III IV\n",
      "2 YEARLY III HALFYEARLY V VI\n",
      "3 YEARLY IV HALFYEARLY VII VIII\n",
      "No contracts for Half yearly IX X\n",
      "YEARLY CONTRACTS GENERATED\n",
      "\n",
      "NIFTY CONTRACTS CREATED\n",
      "\n",
      "\n",
      "FINNIFTY CONTRACTS BEING CREATED\n",
      "-I 209\n",
      "-I 209\n",
      "FINNIFTY MONTHLY CONTRACTS GENERATED\n",
      "[0, 1, 2]\n",
      "-I\n",
      "28175\n",
      "28175\n",
      "-II\n",
      "833\n",
      "833\n",
      "-III\n",
      "209\n",
      "209\n",
      "-IV not exists\n",
      "-V not exists\n",
      "-VI not exists\n",
      "-VII not exists\n",
      "-VIII not exists\n",
      "-IX not exists\n",
      "-X not exists\n",
      "-XI not exists\n",
      "-XII not exists\n",
      "FINNIFTY WEEKLY CONTRACTS CREATED\n",
      "\n",
      "FINNIFTY CONTRACTS CREATED\n",
      "ELAPSED TIME 101.52038049697876\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import walk\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import array_contains\n",
    "from pyspark.sql.functions import *\n",
    "import time\n",
    "from pyspark.sql.functions import date_format\n",
    "from datetime import date\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "date1 = input('Enter a date in YYYY-MM-DD format ')                                     ## TO BE CHANGED DAILY AS PER UPDATION DATE\n",
    "year , month , day = map(int,date1.split('-'))\n",
    "day , month = f\"{day:02d}\",f\"{month:02d}\"\n",
    "tablename=\"r\"+str(day)+str(month)+str(year)\n",
    "print(tablename)\n",
    "\n",
    "st=time.time()\n",
    "\n",
    "def banknifty_data():\n",
    "    spark = SparkSession.builder.config(\"spark.jars\", \"C:\\\\Users\\\\admin\\\\Downloads\\\\postgresql-42.5.0.jar\") \\\n",
    "    .master(\"local\").appName(\"PySpark_Postgres_test\").getOrCreate()\n",
    "    \n",
    "    df = spark.read.format(\"jdbc\").option(\"url\", \"jdbc:postgresql://swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com/RawDataBase\").option(\"user\",\"postgres\").option(\"password\",\"swancap123\")\\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\").option(\"dbtable\", tablename)\\\n",
    "        .option(\"user\", \"postgres\").option(\"password\", \"swancap123\").load()\n",
    "\n",
    "    ## GETTING ONLY TIME IN TIME COLUMN\n",
    "    q = df.withColumn('time',date_format('time', 'HH:mm:ss'))\n",
    "    bndata = q.filter(q.ticker.contains('BANKNIFTY') & ((q.ticker.endswith('E.NFO'))| (q.ticker.endswith('E'))))\n",
    "    ## REPLACING .NFO IN ticker\n",
    "    bndata = bndata.withColumn('ticker',regexp_replace('ticker','.NFO',''))\n",
    "\n",
    "    ## CONVERTING PYSPARK DATAFRAME TO PANDAS DATAFRAME\n",
    "    bndata = bndata.toPandas()\n",
    "    return bndata\n",
    "\n",
    "def banknifty_monthly():\n",
    "    \n",
    "    ## CHECKING IF PATH DOES NOT EXIST, THEN CREATE PATH\n",
    "    if not os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\Monthly_data\\\\\"):\n",
    "        os.makedirs(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\Monthly_data\\\\\")\n",
    "        \n",
    "    if not os.path.exists(r\"C:\\users\\admin\\desktop\\Pyspark\\BankNifty\\Monthly\\\\\"):\n",
    "        os.makedirs(r\"C:\\users\\admin\\desktop\\Pyspark\\BankNifty\\Monthly\\\\\")\n",
    "    \n",
    "    folpath = r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\Monthly_data\\\\\"\n",
    "    sym = 'BANKNIFTY'\n",
    "    start_time = datetime.strptime('09:15:00', '%H:%M:%S').time()\n",
    "    end_time = datetime.strptime('15:30:00', '%H:%M:%S').time()\n",
    "    \n",
    "    def add(stri):\n",
    "        obj = datetime.strptime(stri, \"%b\")\n",
    "        month_number = obj.month\n",
    "        return month_number\n",
    "\n",
    "    ## READING THE EXPIRY SHEET\n",
    "    exp_file_path = r\"C:\\Users\\admin\\Downloads\\MonthlyExpiry.csv\"\n",
    "    exp_df = pd.read_csv(exp_file_path,parse_dates=[\"curr_exp_date\",\"curr_date\"],dayfirst=True).dropna()\n",
    "    ## CONVERTING TO PANDAS DATAFRAME\n",
    "    exp_df.rename({'curr_date': 'New_date'}, axis=1, inplace=True)\n",
    "    exp_df['New_date'] = pd.to_datetime(exp_df['New_date'],dayfirst=True)\n",
    "    exp_date = pd.read_excel(r'C:\\users\\admin\\desktop\\Expiry_DT.xlsx')\n",
    "    \n",
    "    ## CALLING FUNCTION BANKNIFTY_DATA TO GENERATE ONLY BANKNIFTY TICKERS\n",
    "    ddf = banknifty_data()\n",
    "    ddf = ddf.loc[:, ~ddf.columns.str.contains('^Unnamed')]\n",
    "    ddf['date'] = pd.to_datetime(ddf['date'],dayfirst=True)\n",
    "    ddf['Optiontype'] = ddf['ticker'].str[-2:]\n",
    "    ddf['Temp'] = ddf['ticker'].str.replace('BANKNIFTY','')\n",
    "    ddf['Temp'] = ddf['Temp'].str[:-2]\n",
    "    ddf['Length_of_temp'] = np.where(ddf['Temp'].str.len()==12,12,ddf['Temp'].str.len())\n",
    "    ddf['Strike'] = np.where((ddf['Temp'].str.len()==12)|(ddf['Temp'].str.len()==10),ddf['Temp'].str[-5:],\n",
    "                             ddf['Temp'].str[-4:])\n",
    "    ddf['Exp_year'] = np.where(ddf['Temp'].str.len()==12,ddf['Temp'].str[5:7],ddf['Temp'].str[:2])\n",
    "    ddf['Exp_month'] = ddf['Temp'].str[2:5]\n",
    "    ddf['Exp_year'] = ddf['Exp_year'].astype('str')\n",
    "    ddf['MonthYear'] = ddf['Exp_month'] + ddf['Exp_year']\n",
    "    merged_df = pd.merge(ddf,exp_date,on='MonthYear')\n",
    "    merged_df = merged_df.drop(['MonthYear','Month','Year'],axis=1)\n",
    "    merged_df['Length_of_temp'] = merged_df['Length_of_temp'].astype('int64')\n",
    "    df_10 = merged_df[(merged_df['Length_of_temp']==10) | (merged_df['Length_of_temp']==9)]\n",
    "    df_12 = merged_df[merged_df['Length_of_temp']==12]\n",
    "    df_12['DateDate'] = df_12['Temp'].str[:2]\n",
    "    df_12['DateDate'] = df_12['DateDate'].astype('int64')\n",
    "    df_12['Exp_DT'] = pd.to_datetime(merged_df['Exp_DT'],dayfirst=True)\n",
    "    df_12['Exp_Day'] = df_12['Exp_DT'].dt.day\n",
    "    df_12 = df_12[df_12['Exp_Day']==df_12['DateDate']]\n",
    "    df_12 = df_12.drop(['DateDate','Exp_Day'],axis=1)\n",
    "\n",
    "    ddf = df_10.append(df_12,ignore_index=True)\n",
    "    ddf['time'] = ddf['time'].str.replace(' 15:00:59','15:00:59')\n",
    "    ddf['time'] = ddf['time'].str.replace(' 9:','09:',regex=True)\n",
    "    ddf['time'] = pd.to_datetime(ddf['time'], format='%H:%M:%S').dt.time\n",
    "    ddf = ddf[(ddf['time']>=start_time) & (ddf['time']<=end_time)]\n",
    "    ddf['exp_month_number'] = ddf.apply(lambda row : add(row[\"Exp_month\"]), axis = 1)\n",
    "    ddf['New_date'] = ddf['date']\n",
    "    ddf[\"New_date\"] = pd.to_datetime(ddf[\"New_date\"],dayfirst=True)\n",
    "    ddf[\"current_month_number\"] = ddf['New_date'].dt.month\n",
    "    ddf[\"difference\"] = ddf['exp_month_number'].astype(int) - ddf[\"current_month_number\"].astype(int)\n",
    "    df1 = pd.merge(ddf, \n",
    "                     exp_df, \n",
    "                     on ='New_date', \n",
    "                     how ='left')\n",
    "    df1.drop(df1.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "    df1[\"current_exp_month_number\"] = df1['curr_exp_date'].dt.month\n",
    "    df1[\"Diff_months\"] = df1[\"current_exp_month_number\"] - df1[\"current_month_number\"]\n",
    "    df1[\"Diff_months\"] = df1[\"Diff_months\"].astype(int) \n",
    "    bdf = df1[df1[\"Diff_months\"] == 0]\n",
    "    adf = df1[(df1[\"Diff_months\"] == 1) | (df1[\"Diff_months\"] == -11)]\n",
    "    if bdf.shape[0] + adf.shape[0] == df1.shape[0]:\n",
    "        print(\"Sanity Check Success\")\n",
    "    else:\n",
    "        print(\"Error1\")\n",
    "    agb = adf.groupby([\"difference\"])\n",
    "    unique_val_list_a = list(adf[\"difference\"].unique())\n",
    "    bgb = bdf.groupby([\"difference\"])\n",
    "    unique_val_list_b = list(bdf[\"difference\"].unique())\n",
    "    \n",
    "    ## REMOVING YESTERDAY'S CREATED FILE\n",
    "    if os.path.exists(folpath+sym+'-I.csv'):\n",
    "        os.remove(folpath+sym+'-I.csv')\n",
    "    if os.path.exists(folpath+sym+'-II.csv'):\n",
    "        os.remove(folpath+sym+'-II.csv')\n",
    "    if os.path.exists(folpath+sym+'-III.csv'):\n",
    "        os.remove(folpath+sym+'-III.csv')\n",
    "    if os.path.exists(folpath+sym+'misc.csv'):\n",
    "        os.remove(folpath+sym+'misc.csv')\n",
    "        \n",
    "    for i in unique_val_list_b:\n",
    "        temp_df_new = bgb.get_group(i)\n",
    "        temp_df_new = temp_df_new.drop(temp_df_new.columns[9:],axis=1)\n",
    "        if i == 0:\n",
    "            temp_df_new.to_csv(folpath + sym + '-I.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "        if i == 1 or i == -11:\n",
    "            temp_df_new.to_csv(folpath + sym + '-II.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "        if i == 2 or i == -10:\n",
    "            temp_df_new.to_csv(folpath + sym + '-III.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "        \n",
    "    for i in unique_val_list_a:\n",
    "        temp_df_new = agb.get_group(i)\n",
    "        temp_df_new = temp_df_new.drop(temp_df_new.columns[9:],axis=1)\n",
    "        if i == 1 or i == -11:\n",
    "            temp_df_new.to_csv(folpath + sym + '-I.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "        if i == 2 or i == -10:\n",
    "            temp_df_new.to_csv(folpath + sym + '-II.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "        if i == 3 or i == -9:\n",
    "            temp_df_new.to_csv(folpath + sym + '-III.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "    \n",
    "    ##########################CREATING LABEL IN STANDARD FORM#####################\n",
    "    for i in range(3):\n",
    "        if i == 0:\n",
    "            file='I'\n",
    "        elif i == 1:\n",
    "            file='II'\n",
    "        elif i == 2:\n",
    "            file='III'\n",
    "        \n",
    "        if os.path.exists(r'C:\\users\\admin\\desktop\\Pyspark\\BankNifty\\Monthly\\Banknifty-'+file+\".csv\"):\n",
    "            os.remove(r'C:\\users\\admin\\desktop\\Pyspark\\BankNifty\\Monthly\\Banknifty-'+file+\".csv\")\n",
    "    \n",
    "        if os.path.exists(r'C:\\users\\admin\\desktop\\Pyspark_Contracts\\BankNifty\\Monthly_Data\\BANKNIFTY-'+file+'.csv'):\n",
    "            ddf = pd.read_csv(r'C:\\users\\admin\\desktop\\Pyspark_Contracts\\BankNifty\\Monthly_Data\\BANKNIFTY-'+file+'.csv')\n",
    "            ddf['Option_Type'] = ddf['ticker'].str[-2:]\n",
    "            ddf['Strike'] = np.where((ddf['ticker'].str.len()==20) | (ddf['ticker'].str.len()==22) , ddf['ticker'].str[-6:-2] , ddf['ticker'].str[-7:-2])\n",
    "            ddf['Symbol'] = 'BANKNIFTY' + 'MONTHLY-' + file + ddf['Strike'].astype(int).astype(str) + ddf['Option_Type']\n",
    "            ddf['ticker'] = ddf['Symbol']\n",
    "            ddf = ddf.drop(ddf.columns[9:],axis=1)\n",
    "            ddf = ddf.rename(columns = {\"ticker\":\"Ticker\"})\n",
    "            ddf.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\Monthly\\\\Banknifty-\"+file+\".csv\",index=False)\n",
    "    print(\"BANKNIFTY MONTHLY CONTRACTS CREATED\")\n",
    "\n",
    "def banknifty_weekly():\n",
    "    ## CHECKING IF PATH DOES NOT EXIST, THEN CREATE PATH\n",
    "    if not os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\Weekly_data\\\\\"):\n",
    "        os.makedirs(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\Weekly_data\\\\\")\n",
    "        \n",
    "    if not os.path.exists(r\"C:\\users\\admin\\desktop\\Pyspark\\BankNifty\\Weekly\\\\\"):\n",
    "        os.makedirs(r\"C:\\users\\admin\\desktop\\Pyspark\\BankNifty\\Weekly\\\\\")\n",
    "        \n",
    "    folpath = r\"C:\\users\\admin\\desktop\\\\Pyspark_Contracts\\\\BankNifty\\\\Weekly_Data\\\\\"\n",
    "    sym = 'BANKNIFTY'\n",
    "    s = 'BANKNIFTY'\n",
    "    expiry_time = datetime.strptime('15:29:59', '%H:%M:%S').time()\n",
    "    \n",
    "    ## CALLING FUNCTION NIFTY_DATA TO GENERATE ONLY NIFTY TICKERS\n",
    "    df=banknifty_data()\n",
    "    \n",
    "    ## READING WEEKLY EXPIRY FILES\n",
    "    exp_df = pd.read_csv(r\"C:\\Users\\admin\\Downloads\\WeeklyExpiry.csv\",parse_dates = [\"date\"],dayfirst =True,usecols= ['date', 'Week_number'])\n",
    "    exp_date = pd.read_excel(r'C:\\users\\admin\\desktop\\Expiry_DT.xlsx',parse_dates = ['Exp_DT'],usecols = ['MonthYear','Exp_DT'])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['time'] = df['time'].str.replace(' 15:00:59','15:00:59')\n",
    "    df['time'] = df['time'].str.replace(' 9:','09:',regex=True)\n",
    "    df['time'] = pd.to_datetime(df['time']).dt.time\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    df = df[df['time'] <= expiry_time]\n",
    "    df['EXPIRY_DT'] = df['ticker'].str[9:16]\n",
    "    df['EXPIRY_DT'] = pd.to_datetime(df['EXPIRY_DT'],dayfirst=True)\n",
    "    df['OPTION_TYP'] = df['ticker'].str[-2:]\n",
    "    df['STRIKE_PR'] = np.where(df['ticker'].str.len()==23,df['ticker'].str[-7:-2],df['ticker'].str[-7:-2])\n",
    "    df['Month'] = df['ticker'].str[11:14]\n",
    "    df['Year'] = np.where(df['ticker'].str.len()==23,df['ticker'].str[14:16],df['ticker'].str[9:11])\n",
    "    df['MonthYear'] = df['Month'] + df['Year']\n",
    "    df = df.rename(columns={'EXPIRY_DT' : 'expiry_date'})\n",
    "\n",
    "    ## MERGING WITH EXPIRY SHEET TO GET EXPIRY DATE\n",
    "    df1 = pd.merge(df,exp_df,on='date',how='left')\n",
    "    df1 = df1.drop_duplicates()\n",
    "    df1 = pd.merge(df1,exp_date,on='MonthYear',how='left')\n",
    "    df1 = df1.drop(['Month','Year','MonthYear'],axis=1)\n",
    "\n",
    "    ## GETTING THE EXPIRY DATES FOR MONTHLY CONTRACTS\n",
    "    df1['expiry_date'] = np.where(df1['ticker'].str.len()>21,df1['expiry_date'],df1['Exp_DT'])\n",
    "    df1 = df1.drop(['Exp_DT'],axis=1)\n",
    "    exp_df = pd.read_csv(r\"C:\\Users\\admin\\Downloads\\WeeklyExpiry.csv\",parse_dates = [\"Weekly_Expiry_Date\"],dayfirst =True,usecols= ['Weekly_Expiry_Date', 'Expiry_Week_number'])\n",
    "    exp_df = exp_df.dropna()\n",
    "    exp_df = exp_df.rename(columns = {'Weekly_Expiry_Date': 'expiry_date'})\n",
    "    df2 = pd.merge(df1, exp_df, on ='expiry_date', how ='left')\n",
    "    df2 = df2.drop_duplicates()\n",
    "    df2['week_diff'] = df2['Expiry_Week_number'] - df2['Week_number']\n",
    "\n",
    "    final_df = df2[(df2[\"OPTION_TYP\"] == \"CE\") | (df2[\"OPTION_TYP\"] == \"PE\") ]\n",
    "    final_df[\"week_diff\"] = final_df['week_diff'].replace(np.nan,10000)\n",
    "\n",
    "    agb = final_df.groupby([\"week_diff\"])\n",
    "    unique_val_list_a = list(final_df[\"week_diff\"].unique())\n",
    "    unique_val_list_a = sorted([a for a in unique_val_list_a if a>=0])[0:12]\n",
    "    print(unique_val_list_a)\n",
    "\n",
    "    ## CREATING -I,-II AND SO ON BASED ON THE WEEK DIFFERENCES\n",
    "\n",
    "    if os.path.exists(folpath+sym+'-I.csv'):\n",
    "        os.remove(folpath+sym+'-I.csv')\n",
    "    if os.path.exists(folpath+sym+'-II.csv'):\n",
    "        os.remove(folpath+sym+'-II.csv')\n",
    "    if os.path.exists(folpath+sym+'-III.csv'):\n",
    "        os.remove(folpath+sym+'-III.csv')\n",
    "    if os.path.exists(folpath+sym+'-IV.csv'):\n",
    "        os.remove(folpath+sym+'-IV.csv')\n",
    "    if os.path.exists(folpath+sym+'-V.csv'):\n",
    "        os.remove(folpath+sym+'-V.csv')\n",
    "    if os.path.exists(folpath+sym+'-VI.csv'):\n",
    "        os.remove(folpath+sym+'-VI.csv')\n",
    "    if os.path.exists(folpath+sym+'-VII.csv'):\n",
    "        os.remove(folpath+sym+'-VII.csv')\n",
    "    if os.path.exists(folpath+sym+'-VIII.csv'):\n",
    "        os.remove(folpath+sym+'-VIII.csv')\n",
    "    if os.path.exists(folpath+sym+'-IX.csv'):\n",
    "        os.remove(folpath+sym+'-IX.csv')\n",
    "    if os.path.exists(folpath+sym+'-X.csv'):\n",
    "        os.remove(folpath+sym+'-X.csv')\n",
    "    if os.path.exists(folpath+sym+'-XI.csv'):\n",
    "        os.remove(folpath+sym+'-XI.csv')\n",
    "    if os.path.exists(folpath+sym+'-XII.csv'):\n",
    "        os.remove(folpath+sym+'-XII.csv')  \n",
    "    if os.path.exists(folpath+sym+'-XIII.csv'):\n",
    "        os.remove(folpath+sym+'-XIII.csv')  \n",
    "    if os.path.exists(folpath+sym+'-XIV.csv'):\n",
    "        os.remove(folpath+sym+'-XIV.csv')  \n",
    "        \n",
    "    for i in sorted(unique_val_list_a):\n",
    "        temp_df = agb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        temp_df = temp_df.drop_duplicates()\n",
    "        if i == 0:\n",
    "            temp_df.to_csv(folpath + s + '-I.csv', mode = 'a', header = not os.path.exists(folpath + s + '-I.csv'), index=False)\n",
    "        if i == 1:\n",
    "            temp_df.to_csv(folpath + s + '-II.csv', mode = 'a', header = not os.path.exists(folpath + s + '-II.csv'), index=False)\n",
    "        if i == 2:\n",
    "            temp_df.to_csv(folpath + s + '-III.csv', mode = 'a', header = not os.path.exists(folpath + s + '-III.csv'), index=False)\n",
    "        if i == 3:\n",
    "            temp_df.to_csv(folpath + s + '-IV.csv', mode = 'a', header = not os.path.exists(folpath + s + '-IV.csv'), index=False)\n",
    "        if i == 4:\n",
    "            temp_df.to_csv(folpath + s + '-V.csv', mode = 'a', header = not os.path.exists(folpath + s + '-V.csv'), index=False)\n",
    "        if i == 5:\n",
    "            temp_df.to_csv(folpath + s + '-VI.csv', mode = 'a', header = not os.path.exists(folpath + s + '-VI.csv'), index=False)\n",
    "        if i == 6:\n",
    "            temp_df.to_csv(folpath + s + '-VII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-VII.csv'), index=False)\n",
    "        if i == 7:\n",
    "            temp_df.to_csv(folpath + s + '-VIII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-VIII.csv'), index=False)\n",
    "        if i == 8:\n",
    "            temp_df.to_csv(folpath + s + '-IX.csv', mode = 'a', header = not os.path.exists(folpath + s + '-IX.csv'), index=False)\n",
    "        if i == 9:\n",
    "            temp_df.to_csv(folpath + s + '-X.csv', mode = 'a', header = not os.path.exists(folpath + s + '-X.csv'), index=False)\n",
    "        if i == 10:\n",
    "            temp_df.to_csv(folpath + s + '-XI.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XI.csv'), index=False)\n",
    "        if i == 11:\n",
    "            temp_df.to_csv(folpath + s + '-XII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XII.csv'), index=False)\n",
    "        if i == 12:\n",
    "            temp_df.to_csv(folpath + s + '-XIII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XIII.csv'), index=False)\n",
    "        if i == 13:\n",
    "            temp_df.to_csv(folpath + s + '-XIV.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XIV.csv'), index=False)\n",
    "    \n",
    "    #################LABELLING FILES IN STANDARD FORM######################\n",
    "    for i in range(15):\n",
    "        if i==0:\n",
    "            file='I'\n",
    "        elif i==1:\n",
    "            file='II'\n",
    "        elif i==2:\n",
    "            file='III'\n",
    "        elif i==3:\n",
    "            file='IV'\n",
    "        elif i==4:\n",
    "            file='V'\n",
    "        elif i==5:\n",
    "            file='VI'\n",
    "        elif i==6:\n",
    "            file='VII'\n",
    "        elif i==7:\n",
    "            file='VIII'\n",
    "        elif i==8:\n",
    "            file='IX'\n",
    "        elif i==9:\n",
    "            file='X'\n",
    "        elif i==10:\n",
    "            file='XI'\n",
    "        elif i==11:\n",
    "            file='XII'\n",
    "        elif i==12:\n",
    "            file='XIII'\n",
    "        elif i==13:\n",
    "            file='XIV'\n",
    "        if os.path.exists(r'C:\\users\\admin\\desktop\\Pyspark\\BankNifty\\Weekly\\BANKNIFTY-'+file+'.csv'):\n",
    "            os.remove(r'C:\\users\\admin\\desktop\\Pyspark\\BankNifty\\Weekly\\BANKNIFTY-'+file+'.csv')\n",
    "        if os.path.exists(r'C:\\users\\admin\\desktop\\Pyspark_Contracts\\BankNifty\\Weekly_Data\\BANKNIFTY-'+file+'.csv'):\n",
    "            ddf = pd.read_csv(r'C:\\users\\admin\\desktop\\Pyspark_Contracts\\BankNifty\\Weekly_Data\\BANKNIFTY-'+file+'.csv')\n",
    "            ddf['Option_Type'] = ddf['ticker'].str[-2:]\n",
    "            ddf['Strike'] = np.where((ddf['ticker'].str.len()==20) | (ddf['ticker'].str.len()==22) , ddf['ticker'].str[-6:-2] , ddf['ticker'].str[-7:-2])\n",
    "            ddf['Symbol'] = 'BANKNIFTY' + 'WEEKLY-' + file + + ddf['Strike'].astype(int).astype(str) + ddf['Option_Type']\n",
    "            ddf['ticker'] = ddf['Symbol']\n",
    "            ddf = ddf.drop(ddf.columns[9:],axis=1)\n",
    "            ddf = ddf.rename(columns = {'date':'Date','ticker':'Ticker'})\n",
    "            ddf = ddf.drop_duplicates()\n",
    "            ddf.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\Weekly\\BANKNIFTY-\"+file+\".csv\",index=False)\n",
    "    print(\"BANKNIFTY WEEKLY CONTRACTS CREATED\")\n",
    "    \n",
    "def banknifty_quarterly():\n",
    "    ## CHECKING IF PATH DOES NOT EXIST, THEN CREATE PATH\n",
    "    if not os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\Quarterly_data\\\\\"):\n",
    "        os.makedirs(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\Quarterly_data\\\\\")\n",
    "        \n",
    "    if not os.path.exists(r\"C:\\users\\admin\\desktop\\Pyspark\\BankNifty\\Quarterly\\\\\"):\n",
    "        os.makedirs(r\"C:\\users\\admin\\desktop\\Pyspark\\BankNifty\\Quarterly\\\\\")\n",
    "        \n",
    "    folpath = r\"C:\\users\\admin\\desktop\\\\Pyspark_Contracts\\\\BankNifty\\\\Quarterly_Data\\\\\"\n",
    "    sym = 'BANKNIFTY'\n",
    "    start_time = datetime.strptime('09:15:00', '%H:%M:%S').time()\n",
    "    end_time = datetime.strptime('15:30:00', '%H:%M:%S').time()\n",
    "\n",
    "    ## CALLING FUNCTION BANKNIFTY_DATA TO GENERATE ONLY BANKNIFTY TICKERS\n",
    "    temp = banknifty_data()\n",
    "    \n",
    "    def add(stri):\n",
    "        obj = datetime.strptime(stri, \"%b\")\n",
    "        month_number = obj.month\n",
    "        return month_number\n",
    "\n",
    "    exp_date = pd.read_excel(r'C:\\users\\admin\\desktop\\Expiry_DT.xlsx')    ## reading the expiry sheet file\n",
    "    exp_file_path = r\"C:\\Users\\admin\\Downloads\\MonthlyExpiry.csv\"\n",
    "    exp_df = pd.read_csv(exp_file_path,parse_dates = [\"curr_exp_date\",\"curr_date\"],dayfirst =True,usecols = [\"curr_exp_date\",\"curr_date\"]).dropna()\n",
    "    exp_df.rename({'curr_date': 'New_date'}, axis=1, inplace=True)\n",
    "    temp['time'] = temp['time'].astype(str).str.replace(' 15:00:59','15:00:59')\n",
    "    temp['time'] = temp['time'].str.replace(' 9:','09:',regex=True)\n",
    "    temp['ticker'] = temp['ticker'].str.replace('30MAR23','29MAR23',regex=True)\n",
    "    temp['time'] = pd.to_datetime(temp['time']).dt.time\n",
    "    temp['date'] = pd.to_datetime(temp['date'])\n",
    "    temp = temp[(temp['time']>=start_time) & (temp['time']<=end_time)]\n",
    "    temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "    temp['Option_type'] = temp['ticker'].str[-2:]\n",
    "    temp[\"Temp\"] = temp[\"ticker\"].str.replace('BANKNIFTY',\"\")\n",
    "    temp[\"Temp\"] = temp[\"Temp\"].str[:-2]\n",
    "    temp[\"Strike\"] = np.where((temp['Temp'].str.len()==12) | (temp['Temp'].str.len()==10),\n",
    "                                temp['Temp'].str[-5:],\n",
    "                                temp['Temp'].str[-4:])\n",
    "    temp['Current_Year'] = temp['date'].dt.year\n",
    "    temp['Current_Year'] = temp['Current_Year'].astype(str).str[-2:]\n",
    "    temp[\"Exp_year\"] = np.where(temp['Temp'].str.len()==12,temp[\"Temp\"].str[5:7],temp['Temp'].str[:2])\n",
    "    temp[\"Exp_month\"] = temp[\"Temp\"].str[2:5]\n",
    "    temp['Length_of_Temp'] = np.where(temp['Temp'].str.len()==12,12,temp['Temp'].str.len())\n",
    "    temp['Exp_year'] = temp['Exp_year'].astype('str')\n",
    "    temp['MonthYear'] = temp['Exp_month']+temp['Exp_year']\n",
    "    temp = pd.merge(temp,exp_date,on='MonthYear')\n",
    "    temp = temp.drop(['MonthYear','Month','Year'],axis=1)\n",
    "\n",
    "    temp['Length_of_Temp'] = temp['Length_of_Temp'].astype('int64')\n",
    "    temp_10 = temp[(temp['Length_of_Temp']==10) | (temp['Length_of_Temp']==9)]\n",
    "    temp_12 = temp[temp['Length_of_Temp']==12]\n",
    "    temp_12['datedate'] = temp_12['Temp'].str[:2]\n",
    "    temp_12['datedate'] = temp_12['datedate'].astype('int64')\n",
    "    temp_12['Exp_DT'] = pd.to_datetime(temp['Exp_DT'],dayfirst=True)\n",
    "    temp_12['Exp_Day'] = temp_12['Exp_DT'].dt.day\n",
    "    temp_12 = temp_12[temp_12['Exp_Day']==temp_12['datedate']]\n",
    "\n",
    "    temp_12 = temp_12.drop(['datedate','Exp_Day'],axis=1)\n",
    "    temp = temp_10.append(temp_12,ignore_index=True)\n",
    "\n",
    "    temp['exp_month_number'] = temp.apply(lambda row : add(row[\"Exp_month\"]), axis = 1)\n",
    "    temp['New_date'] = temp['date']\n",
    "    temp[\"New_date\"] = pd.to_datetime(temp[\"New_date\"])\n",
    "    temp[\"current_month_number\"] = temp['New_date'].dt.month\n",
    "    temp[\"difference\"] = temp['exp_month_number'].astype(int) - temp[\"current_month_number\"].astype(int)\n",
    "    temp['Year_difference'] = temp['Exp_year'].astype(int) - temp['Current_Year'].astype(int)\n",
    "    temp = temp[(temp['exp_month_number']==3) | (temp['exp_month_number']==6) | (temp['exp_month_number']==9) | (temp['exp_month_number']==12)]\n",
    "\n",
    "    temp1 = pd.merge(temp, \n",
    "                         exp_df, \n",
    "                         on ='New_date', \n",
    "                         how ='left')\n",
    "\n",
    "    temp1.drop(temp1.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "    temp1[\"current_exp_month_number\"] = temp1['curr_exp_date'].dt.month\n",
    "    temp1[\"Diff_months\"] = temp1[\"current_exp_month_number\"] - temp1[\"current_month_number\"]\n",
    "    temp1[\"Diff_months\"] = temp1[\"Diff_months\"].astype(int) \n",
    "\n",
    "    temp1 = temp1[temp1['Exp_DT']>=temp1['curr_exp_date']]                 ## to filter out dates which have wrong ticker\n",
    "\n",
    "    ## creating groups for generating contracts\n",
    "    atemp = temp1[(temp1['Diff_months']==0) & (temp1['Year_difference']==0)]\n",
    "    agb = atemp.groupby(['difference'])\n",
    "    unique_a = list(atemp['difference'].unique())\n",
    "\n",
    "    if os.path.exists(folpath+sym+'-I.csv'):\n",
    "        os.remove(folpath+sym+'-I.csv')\n",
    "    if os.path.exists(folpath+sym+'-II.csv'):\n",
    "        os.remove(folpath+sym+'-II.csv')\n",
    "    if os.path.exists(folpath+sym+'-III.csv'):\n",
    "        os.remove(folpath+sym+'-III.csv')\n",
    "    if os.path.exists(folpath+sym+'-IV.csv'):\n",
    "        os.remove(folpath+sym+'-IV.csv')\n",
    "    if os.path.exists(folpath+sym+'-V.csv'):\n",
    "        os.remove(folpath+sym+'-V.csv')\n",
    "    if os.path.exists(folpath+sym+'-VI.csv'):\n",
    "        os.remove(folpath+sym+'-VI.csv')\n",
    "    if os.path.exists(folpath+sym+'-VII.csv'):\n",
    "        os.remove(folpath+sym+'-VII.csv')\n",
    "    if os.path.exists(folpath+sym+'-VIII.csv'):\n",
    "        os.remove(folpath+sym+'-VIII.csv')    \n",
    "\n",
    "    for i in unique_a:\n",
    "        temp_df = agb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==0 or i==1 or i==2:\n",
    "            temp_df.to_csv(folpath + sym + '-I.csv', mode='a', header=not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "        if i==3 or i==4 or i==5:\n",
    "            temp_df.to_csv(folpath + sym + '-II.csv', mode='a', header=not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "        if i==6 or i==7 or i==8:\n",
    "            temp_df.to_csv(folpath + sym + '-III.csv', mode='a', header=not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "        if i==9 or i==10 or i==11:\n",
    "            temp_df.to_csv(folpath + sym + '-IV.csv', mode='a', header=not os.path.exists(folpath + sym + '-IV.csv'), index=False)\n",
    "\n",
    "    btemp = temp1[(temp1['Diff_months']==0) & (temp1['Year_difference']==1)]\n",
    "    bgb = btemp.groupby(['difference'])\n",
    "    unique_b = list(btemp['difference'].unique())        \n",
    "\n",
    "    for i in unique_b:\n",
    "        temp_df = bgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-7 or i==-8 or i==-9:\n",
    "            temp_df.to_csv(folpath + sym + '-II.csv', mode='a', header=not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "        if i==-4 or i==-5 or i==-6:\n",
    "            temp_df.to_csv(folpath + sym + '-III.csv', mode='a', header=not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "        if i==-1 or i==-2 or i==-3:\n",
    "            temp_df.to_csv(folpath + sym + '-IV.csv', mode='a', header=not os.path.exists(folpath + sym + '-IV.csv'), index=False)\n",
    "        if i==0 or i==1 or i==2:\n",
    "            temp_df.to_csv(folpath + sym + '-V.csv', mode='a', header=not os.path.exists(folpath + sym + '-V.csv'), index=False)\n",
    "        if i==3 or i==4 or i==5:\n",
    "            temp_df.to_csv(folpath + sym + '-VI.csv', mode='a', header=not os.path.exists(folpath + sym + '-VI.csv'), index=False)\n",
    "        if i==6 or i==7 or i==8:\n",
    "            temp_df.to_csv(folpath + sym + '-VII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VII.csv'), index=False)\n",
    "        if i==9 or i==10 or i==11:\n",
    "            temp_df.to_csv(folpath + sym + '-VIII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VIII.csv'), index=False)\n",
    "\n",
    "    ctemp = temp1[(temp1['Diff_months']==0) & (temp1['Year_difference']==2)]\n",
    "    cgb = ctemp.groupby(['difference'])\n",
    "    unique_c = list(ctemp['difference'].unique())        \n",
    "\n",
    "    for i in unique_c:\n",
    "        temp_df = cgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-7 or i==-8 or i==-9:\n",
    "            temp_df.to_csv(folpath + sym + '-VI.csv', mode='a', header=not os.path.exists(folpath + sym + '-VI.csv'), index=False)\n",
    "        if i==-4 or i==-5 or i==-6:\n",
    "            temp_df.to_csv(folpath + sym + '-VII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VII.csv'), index=False)\n",
    "        if i==-1 or i==-2 or i==-3:\n",
    "            temp_df.to_csv(folpath + sym + '-VIII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VIII.csv'), index=False)\n",
    "\n",
    "    dtemp = temp1[((temp1['Diff_months']==1) | (temp1['Diff_months']==-11)) & (temp1['Year_difference']==0)]\n",
    "    dgb = dtemp.groupby(['difference'])\n",
    "    unique_d = list(dtemp['difference'].unique())\n",
    "\n",
    "    for i in unique_d:\n",
    "        temp_df = dgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==1 or i==2 or i==3:\n",
    "            temp_df.to_csv(folpath + sym + '-I.csv', mode='a', header=not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "        if i==4 or i==5 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-II.csv', mode='a', header=not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "        if i==7 or i==8 or i==9:\n",
    "            temp_df.to_csv(folpath + sym + '-III.csv', mode='a', header=not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "        if i==10 or i==11:\n",
    "            temp_df.to_csv(folpath + sym + '-IV.csv', mode='a', header=not os.path.exists(folpath + sym + '-IV.csv'), index=False)\n",
    "\n",
    "    etemp = temp1[((temp1['Diff_months']==1) | (temp1['Diff_months']==-11)) & (temp1['Year_difference']==1)]\n",
    "    egb = etemp.groupby(['difference'])\n",
    "    unique_e = list(etemp['difference'].unique())\n",
    "\n",
    "    for i in unique_e:\n",
    "        temp_df = egb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-9:\n",
    "            temp_df.to_csv(folpath + sym + '-I.csv', mode='a', header=not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "        if i==-6 or i==-7:\n",
    "            temp_df.to_csv(folpath + sym + '-II.csv', mode='a', header=not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "        if i==-3 or i==-4:\n",
    "            temp_df.to_csv(folpath + sym + '-III.csv', mode='a', header=not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "        if i==0 or i==-1 or i==-2:\n",
    "            temp_df.to_csv(folpath + sym + '-IV.csv', mode='a', header=not os.path.exists(folpath + sym + '-IV.csv'), index=False)\n",
    "        if i==1 or i==2 or i==3:\n",
    "            temp_df.to_csv(folpath + sym + '-V.csv', mode='a', header=not os.path.exists(folpath + sym + '-V.csv'), index=False)\n",
    "        if i==4 or i==5 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-VI.csv', mode='a', header=not os.path.exists(folpath + sym + '-VI.csv'), index=False)\n",
    "        if i==7 or i==8 or i==9:\n",
    "            temp_df.to_csv(folpath + sym + '-VII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VII.csv'), index=False)\n",
    "        if i==10 or i==11:\n",
    "            temp_df.to_csv(folpath + sym + '-VIII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VIII.csv'), index=False)\n",
    "\n",
    "    ftemp = temp1[((temp1['Diff_months']==1) | (temp1['Diff_months']==-11)) & (temp1['Year_difference']==2)]\n",
    "    fgb = ftemp.groupby(['difference'])\n",
    "    unique_f = list(ftemp['difference'].unique())\n",
    "\n",
    "    for i in unique_f:\n",
    "        temp_df = fgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-9:\n",
    "            temp_df.to_csv(folpath + sym + '-V.csv', mode='a', header=not os.path.exists(folpath + sym + '-V.csv'), index=False)\n",
    "        if i==-6 or i==-7:\n",
    "            temp_df.to_csv(folpath + sym + '-VI.csv', mode='a', header=not os.path.exists(folpath + sym + '-VI.csv'), index=False)\n",
    "        if i==-3 or i==-4:\n",
    "            temp_df.to_csv(folpath + sym + '-VII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VII.csv'), index=False)\n",
    "        if i==0 or i==-1 or i==-2:\n",
    "            temp_df.to_csv(folpath + sym + '-VIII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VIII.csv'), index=False)\n",
    "    \n",
    "    ## CREATING THE TICKER AND REMOVING ADDITIONAL COLUMNS\n",
    "    for i in range(4):\n",
    "        if i==0:\n",
    "            file='I'\n",
    "        elif i==1:\n",
    "            file='II'\n",
    "        elif i==2:\n",
    "            file='III'\n",
    "        elif i==3:\n",
    "            file='IV'\n",
    "        if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\Quarterly\\Banknifty-\"+file+\".csv\"):\n",
    "            os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\Quarterly\\Banknifty-\"+file+\".csv\")\n",
    "        if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\Quarterly_data\\BANKNIFTY-\"+file+\".csv\"):\n",
    "            ddf = pd.read_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\Quarterly_data\\BANKNIFTY-\"+file+\".csv\")\n",
    "            ddf['Option_Type'] = ddf['ticker'].str[-2:]\n",
    "            ddf['Strike'] = np.where((ddf['ticker'].str.len()==20) | (ddf['ticker'].str.len()==22) , ddf['ticker'].str[-6:-2] , ddf['ticker'].str[-7:-2])\n",
    "            ddf['Symbol'] = 'BANKNIFTY' + 'QUARTERLY-' + file + + ddf['Strike'].astype(int).astype(str) + ddf['Option_Type']\n",
    "            ddf['ticker'] = ddf['Symbol']\n",
    "            ddf = ddf.drop(ddf.columns[9:],axis=1)\n",
    "            ddf = ddf.rename(columns = {'date':'Date','ticker':'Ticker'})\n",
    "            ddf = ddf.drop_duplicates()\n",
    "            ddf.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\Quarterly\\Banknifty-\"+file+\".csv\",index=False)\n",
    "    print(\"BANKNIFTY QUARTERLY CONTRACTS CREATED\")\n",
    "    \n",
    "def banknifty_halfyearly():\n",
    "    ## CHECKING IF PATH DOES NOT EXIST, THEN CREATE PATH\n",
    "    if not os.path.exists(r\"C:\\users\\admin\\desktop\\Pyspark\\BankNifty\\Half_Yearly\\\\\"):\n",
    "        os.makedirs(r\"C:\\users\\admin\\desktop\\Pyspark\\BankNifty\\Half_Yearly\\\\\")\n",
    "    \n",
    "    if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\\\Half_Yearly\\\\Banknifty-I.csv\"):\n",
    "        os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\\\Half_Yearly\\\\Banknifty-I.csv\")\n",
    "\n",
    "    if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\\\Half_Yearly\\\\Banknifty-II.csv\"):\n",
    "        os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\\\Half_Yearly\\\\Banknifty-II.csv\")\n",
    "        \n",
    "    final_df = pd.DataFrame()\n",
    "    file = 'I'\n",
    "    for i in range(2):\n",
    "        df = pd.read_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\\\Quarterly_Data\\BANKNIFTY-\"+str(file)+\".csv\")\n",
    "        temp = df.copy()\n",
    "        temp = temp.rename(columns = {'ticker':'Ticker','date':'Date','time':'Time','open':'Open','low':'Low','high':'High','close':'Close','volume':'Volume'})\n",
    "        temp['Time'] = pd.to_datetime(temp['Time']).dt.time\n",
    "        temp['Date'] = pd.to_datetime(temp['Date'])\n",
    "        temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "        temp['Option_type'] = temp['Ticker'].str[-2:]\n",
    "        temp[\"Temp\"] = temp[\"Ticker\"].str.replace('BANKNIFTY',\"\")\n",
    "        temp[\"Temp\"] = temp[\"Temp\"].str[:-2]\n",
    "        temp[\"Strike\"] = np.where((temp['Temp'].str.len()==12) | (temp['Temp'].str.len()==10),\n",
    "                                    temp['Temp'].str[-5:],\n",
    "                                    temp['Temp'].str[-4:])\n",
    "        temp['Current_Year'] = temp['Date'].dt.year\n",
    "        temp['Current_Year'] = temp['Current_Year'].astype(str).str[-2:]\n",
    "        temp[\"Exp_year\"] = np.where(temp['Temp'].str.len()==12,temp[\"Temp\"].str[5:7],temp['Temp'].str[:2])\n",
    "        temp[\"Exp_month\"] = temp[\"Temp\"].str[2:5]\n",
    "        temp['Length_of_Temp'] = np.where(temp['Temp'].str.len()==12,12,temp['Temp'].str.len())\n",
    "        temp = temp[(temp['Exp_month']=='JUN') | (temp['Exp_month']=='DEC')]\n",
    "        temp = temp.reset_index(drop=True)\n",
    "        final_df = final_df.append(temp)\n",
    "        final_df = final_df.reset_index(drop=True)\n",
    "        final_df = final_df.drop(final_df.columns[9:],axis=1)\n",
    "        file+=file\n",
    "\n",
    "    if final_df.empty==False:    \n",
    "        test = final_df.copy()\n",
    "        test['Option_Type'] = test['Ticker'].str[-2:]\n",
    "        test['Last'] = test['Ticker'].str[-7:]\n",
    "        test['Strike'] = test['Last'].astype('str').str.extractall('(\\d+)').unstack().fillna('').sum(axis=1).astype(int)\n",
    "        test['Symbol'] = test['Ticker'].str[:9] + '-I' + test['Strike'].astype(str) + test['Option_Type'].astype(str)\n",
    "        test['Ticker'] = test['Symbol']\n",
    "        test = test.drop(test.columns[9:13],axis=1)\n",
    "        print(\"BANKNIFTY HALF-YEARLY-I CREATED\")\n",
    "        test.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\\\Half_Yearly\\\\Banknifty-I.csv\",index=False)\n",
    "\n",
    "\n",
    "    final_df = pd.DataFrame()\n",
    "    file = 'III'\n",
    "    for i in range(2):\n",
    "        if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\\\Quarterly_Data\\BANKNIFTY-\"+str(file)+\".csv\"):\n",
    "            df = pd.read_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\\\Quarterly_Data\\BANKNIFTY-\"+str(file)+\".csv\")\n",
    "            temp = df.copy()\n",
    "            temp = temp.rename(columns = {'ticker':'Ticker','date':'Date','time':'Time','open':'Open','low':'Low','high':'High','close':'Close','volume':'Volume'})\n",
    "            temp['Time'] = pd.to_datetime(temp['Time']).dt.time\n",
    "            temp['Date'] = pd.to_datetime(temp['Date'])\n",
    "            temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "            temp['Option_type'] = temp['Ticker'].str[-2:]\n",
    "            temp[\"Temp\"] = temp[\"Ticker\"].str.replace('BANKNIFTY',\"\")\n",
    "            temp[\"Temp\"] = temp[\"Temp\"].str[:-2]\n",
    "            temp[\"Strike\"] = np.where((temp['Temp'].str.len()==12) | (temp['Temp'].str.len()==10),\n",
    "                                        temp['Temp'].str[-5:],\n",
    "                                        temp['Temp'].str[-4:])\n",
    "            temp['Current_Year'] = temp['Date'].dt.year\n",
    "            temp['Current_Year'] = temp['Current_Year'].astype(str).str[-2:]\n",
    "            temp[\"Exp_year\"] = np.where(temp['Temp'].str.len()==12,temp[\"Temp\"].str[5:7],temp['Temp'].str[:2])\n",
    "            temp[\"Exp_month\"] = temp[\"Temp\"].str[2:5]\n",
    "            temp['Length_of_Temp'] = np.where(temp['Temp'].str.len()==12,12,temp['Temp'].str.len())\n",
    "            temp = temp[(temp['Exp_month']=='JUN') | (temp['Exp_month']=='DEC')]\n",
    "            temp = temp.reset_index(drop=True)\n",
    "            final_df = final_df.append(temp)\n",
    "            final_df = final_df.reset_index(drop=True)\n",
    "            final_df = final_df.drop(final_df.columns[9:],axis=1)\n",
    "            file='IV'\n",
    "        else:\n",
    "            print(\"BANKNIFTY-QUARTERLY-\"+str(file)+' not found')\n",
    "            file='IV'\n",
    "\n",
    "    if final_df.empty==False:\n",
    "        test = final_df.copy()\n",
    "        test['Option_Type'] = test['Ticker'].str[-2:]\n",
    "        test['Last'] = test['Ticker'].str[-7:]\n",
    "        test['Strike'] = test['Last'].astype('str').str.extractall('(\\d+)').unstack().fillna('').sum(axis=1).astype(int)\n",
    "        test['Symbol'] = test['Ticker'].str[:9] + '-II' + test['Strike'].astype(str) + test['Option_Type'].astype(str)\n",
    "        test['Ticker'] = test['Symbol']\n",
    "        test = test.drop(test.columns[9:13],axis=1)\n",
    "        print(\"BANKNIFTY HALF-YEARLY-II CREATED\")\n",
    "        test.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\\\Half_Yearly\\\\Banknifty-II.csv\",index=False)\n",
    "    print(\"BANKNIFTY HALFYEARLY CONTRACTS CREATED\")\n",
    "\n",
    "def banknifty_yearly():\n",
    "    ## CHECKING IF PATH DOES NOT EXIST, THEN CREATE PATH\n",
    "    if not os.path.exists(r\"C:\\users\\admin\\desktop\\Pyspark\\BankNifty\\Yearly\\\\\"):\n",
    "        os.makedirs(r\"C:\\users\\admin\\desktop\\Pyspark\\BankNifty\\Yearly\\\\\")\n",
    "        \n",
    "    if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\\\Yearly\\\\Banknifty-I.csv\"):\n",
    "        os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\\\Yearly\\\\Banknifty-I.csv\")\n",
    "\n",
    "    final_df = pd.DataFrame()\n",
    "    file = 'I'\n",
    "    add_file = 'I'\n",
    "    for i in range(4):\n",
    "        print(i,file)\n",
    "        if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\\\Quarterly_Data\\BANKNIFTY-\"+str(file)+\".csv\"):  \n",
    "            df = pd.read_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\\\Quarterly_Data\\BANKNIFTY-\"+str(file)+\".csv\")\n",
    "            temp = df.copy()\n",
    "            temp = temp.rename(columns = {'ticker':'Ticker','date':'Date','time':'Time','open':'Open','low':'Low','high':'High','close':'Close','volume':'Volume'})\n",
    "            temp['Time'] = pd.to_datetime(temp['Time']).dt.time\n",
    "            temp['Date'] = pd.to_datetime(temp['Date'])\n",
    "            temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "            temp['Option_type'] = temp['Ticker'].str[-2:]\n",
    "            temp[\"Temp\"] = temp[\"Ticker\"].str.replace('BANKNIFTY',\"\")\n",
    "            temp[\"Temp\"] = temp[\"Temp\"].str[:-2]\n",
    "            temp[\"Strike\"] = np.where((temp['Temp'].str.len()==12) | (temp['Temp'].str.len()==10),\n",
    "                                        temp['Temp'].str[-5:],\n",
    "                                        temp['Temp'].str[-4:])\n",
    "            temp['Current_Year'] = temp['Date'].dt.year\n",
    "            temp['Current_Year'] = temp['Current_Year'].astype(str).str[-2:]\n",
    "            temp[\"Exp_year\"] = np.where(temp['Temp'].str.len()==12,temp[\"Temp\"].str[5:7],temp['Temp'].str[:2])\n",
    "            temp[\"Exp_month\"] = temp[\"Temp\"].str[2:5]\n",
    "            temp['Length_of_Temp'] = np.where(temp['Temp'].str.len()==12,12,temp['Temp'].str.len())\n",
    "            temp = temp[(temp['Exp_month']=='DEC')]\n",
    "            temp = temp.reset_index(drop=True)\n",
    "            final_df = final_df.append(temp)\n",
    "            final_df = final_df.reset_index(drop=True)\n",
    "            final_df = final_df.drop(final_df.columns[9:],axis=1)\n",
    "            if i==2:\n",
    "                file='IV'\n",
    "            else:\n",
    "                file+=add_file\n",
    "\n",
    "        else:\n",
    "            print(\"BANKNIFTY QUARTERLY-\"+str(file)+\" does not exist\")\n",
    "\n",
    "    if final_df.empty==False:\n",
    "        test = final_df.copy()\n",
    "        test['Option_Type'] = test['Ticker'].str[-2:]\n",
    "        test['Last'] = test['Ticker'].str[-7:]\n",
    "        test['Strike'] = test['Last'].astype('str').str.extractall('(\\d+)').unstack().fillna('').sum(axis=1).astype(int)\n",
    "        test['Symbol'] = test['Ticker'].str[:9] + '-I' + test['Strike'].astype(str) + test['Option_Type'].astype(str)\n",
    "        test['Ticker'] = test['Symbol']\n",
    "        test = test.drop(test.columns[9:13],axis=1)\n",
    "        print(\"BANKNIFTY YEARLY-I CREATED\")\n",
    "        test.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\\\Yearly\\\\Banknifty-I.csv\",index=False)\n",
    "\n",
    "    else:\n",
    "        print(\"Dataframe is empty!!!\")\n",
    "    print(\"BANKNIFTY YEARLY CONTRACTS CREATED\")\n",
    "\n",
    "def nifty_data():\n",
    "    spark = SparkSession.builder.config(\"spark.jars\", \"C:\\\\Users\\\\admin\\\\Downloads\\\\postgresql-42.5.0.jar\") \\\n",
    "    .master(\"local\").appName(\"PySpark_Postgres_test\").getOrCreate()\n",
    "    \n",
    "    df = spark.read.format(\"jdbc\").option(\"url\", \"jdbc:postgresql://swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com/RawDataBase\").option(\"user\",\"postgres\").option(\"password\",\"swancap123\")\\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\").option(\"dbtable\", tablename)\\\n",
    "        .option(\"user\", \"postgres\").option(\"password\", \"swancap123\").load()\n",
    "\n",
    "    ## GETTING ONLY TIME IN TIME COLUMN\n",
    "    q = df.withColumn('time',date_format('time', 'HH:mm:ss'))\n",
    "    ndata = q.filter(q.ticker.contains('NIFTY') & ((q.ticker.endswith('E.NFO'))| (q.ticker.endswith('E'))))\n",
    "    ndata = ndata.withColumn('ticker_check',substring('ticker',1,5))\n",
    "    ndata = ndata.filter(ndata.ticker_check.contains('NIFTY'))\n",
    "    ## REPLACING .NFO IN ticker\n",
    "    ndata = ndata.withColumn('ticker',regexp_replace('ticker','.NFO',''))\n",
    "    ndata = ndata.drop(col('ticker_check'))\n",
    "\n",
    "    ## CONVERTING PYSPARK DATAFRAME TO PANDAS DATAFRAME\n",
    "    ndata = ndata.toPandas()\n",
    "    return ndata\n",
    "    \n",
    "def nifty_monthly():\n",
    "    folpath = r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Monthly_Data\\\\\"\n",
    "    sym = 'NIFTY'\n",
    "    start_time = datetime.strptime('09:15:00', '%H:%M:%S').time()\n",
    "    end_time = datetime.strptime('15:30:00', '%H:%M:%S').time()\n",
    "    expiry_time = datetime.strptime('15:29:59', '%H:%M:%S').time()\n",
    "    s = 'NIFTY'\n",
    "\n",
    "    def add(stri):\n",
    "        obj = datetime.strptime(stri, \"%b\")\n",
    "        month_number = obj.month\n",
    "        return month_number\n",
    "\n",
    "    def get_symbol(tic):\n",
    "        li = list(filter(None, re.split(r'(\\d+)', tic)))\n",
    "        return li[0]\n",
    "\n",
    "    exp_file_path = r\"C:\\Users\\admin\\Downloads\\MonthlyExpiry.csv\"\n",
    "    exp_df = pd.read_csv(exp_file_path,parse_dates = [\"curr_exp_date\",\"curr_date\"],dayfirst =True).dropna()\n",
    "    exp_df.rename({'curr_date': 'New_date'}, axis=1, inplace=True)\n",
    "    exp_date = pd.read_excel(r'C:\\users\\admin\\desktop\\Expiry_DT.xlsx')    ## reading the expiry sheet file\n",
    "    \n",
    "    ## CALLING FUNCTION NIFTY_DATA TO GENERATE ONLY NIFTY TICKERS\n",
    "    ndata = nifty_data()\n",
    "    \n",
    "    temp = ndata.copy()\n",
    "    temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "    temp['Symbol'] = temp['ticker'].str[:7]\n",
    "    temp = temp[temp['Symbol']!='NIFTYIT']\n",
    "    temp['time'] = pd.to_datetime(temp['time']).dt.time\n",
    "    temp['ticker'] = temp['ticker'].str.replace('30MAR23','29MAR23',regex=True)\n",
    "    temp['Option_Type'] = temp['ticker'].str[-2:]\n",
    "    temp['Temp'] = temp[\"ticker\"].str.replace(s,\"\")\n",
    "    temp['Temp'] = temp['Temp'].str[:-2]\n",
    "    temp['Length_of_temp'] = temp['Temp'].str.len()\n",
    "    temp['Strike'] = np.where((temp['Temp'].str.len()==9) | (temp['Temp'].str.len()==11) , \n",
    "                              temp['Temp'].str[-4:] , \n",
    "                              temp['Temp'].str[-5:])\n",
    "    temp['Exp_Year'] = np.where((temp['Temp'].str.len()==9) | (temp['Temp'].str.len()==10) ,\n",
    "                               temp['Temp'].str[:2] ,\n",
    "                               temp['Temp'].str[5:7])\n",
    "    temp['Exp_month'] = temp['Temp'].str[2:5]\n",
    "    temp['Exp_Year'] = temp['Exp_Year'].astype('str')\n",
    "    temp['MonthYear'] = temp['Exp_month']+temp['Exp_Year']\n",
    "    temp = pd.merge(temp,exp_date,on='MonthYear')\n",
    "    temp = temp.drop(['MonthYear','Month','Year','Next_Exp_DT'],axis=1)\n",
    "    temp['Length_of_temp'] = temp['Length_of_temp'].astype('int64')\n",
    "    temp_10 = temp[(temp['Length_of_temp']==10) | (temp['Length_of_temp']==9)]\n",
    "\n",
    "    temp_12 = temp[(temp['Length_of_temp']==12) | (temp['Length_of_temp']==11)]\n",
    "    temp_12['DateDate'] = temp_12['Temp'].str[:2]\n",
    "    temp_12['DateDate'] = temp_12['DateDate'].astype('int64')\n",
    "    temp_12['Exp_DT'] = pd.to_datetime(temp_12['Exp_DT'],dayfirst=True)\n",
    "    temp_12['Exp_Day'] = temp_12['Exp_DT'].dt.day\n",
    "    temp_12 = temp_12[temp_12['Exp_Day']==temp_12['DateDate']]\n",
    "    temp_12 = temp_12.drop(['DateDate','Exp_Day'],axis=1)\n",
    "\n",
    "    temp_df = temp_10.append(temp_12,ignore_index=True)\n",
    "\n",
    "    temp_df['time'] = temp_df['time'].astype(str).str.replace(' 15:00:59','15:00:59')\n",
    "    temp_df['time'] = temp_df['time'].astype(str).str.replace(' 9:','09:',regex=True)\n",
    "    temp_df['time'] = pd.to_datetime(temp_df['time'], format='%H:%M:%S').dt.time\n",
    "    temp_df = temp_df[(temp_df['time']>=start_time) & (temp_df['time']<=end_time)]\n",
    "\n",
    "    temp_df['exp_month_number'] = temp_df.apply(lambda row : add(row[\"Exp_month\"]), axis = 1)\n",
    "    temp_df['New_date'] = temp_df['date']\n",
    "    temp_df[\"New_date\"] = pd.to_datetime(temp_df[\"New_date\"])\n",
    "    temp_df[\"current_month_number\"] = temp_df['New_date'].dt.month\n",
    "    temp_df[\"difference\"] = temp_df['exp_month_number'].astype(int) - temp_df[\"current_month_number\"].astype(int)\n",
    "    temp_df1 = pd.merge(temp_df, \n",
    "                 exp_df, \n",
    "                 on ='New_date', \n",
    "                 how ='left')\n",
    "    temp_df1.drop(temp_df1.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "    temp_df1[\"current_exp_month_number\"] = temp_df1['curr_exp_date'].dt.month\n",
    "    temp_df1[\"Diff_months\"] = temp_df1[\"current_exp_month_number\"] - temp_df1[\"current_month_number\"]\n",
    "    temp_df1[\"Diff_months\"] = temp_df1[\"Diff_months\"].astype(int) \n",
    "    temp_df1['Current_Year'] = temp_df1['New_date'].dt.year.astype(str).str[-2:]\n",
    "    temp_df1['Flag'] = np.where((temp_df1['Current_Year']==temp_df1['Exp_Year']) | (temp_df1['current_month_number']==12) & (temp_df1['exp_month_number']<=3),1,0)\n",
    "    temp_df1 = temp_df1[temp_df1['Flag']==1]\n",
    "    bdf = temp_df1[temp_df1[\"Diff_months\"] == 0]\n",
    "    adf = temp_df1[(temp_df1[\"Diff_months\"] == 1) | (temp_df1[\"Diff_months\"] == -11)]\n",
    "    if bdf.shape[0] + adf.shape[0] == temp_df1.shape[0]:\n",
    "        print(\"Sanity Check Success\")\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "\n",
    "    agb = adf.groupby([\"difference\"])\n",
    "    unique_val_list_a = list(adf[\"difference\"].unique())\n",
    "    bgb = bdf.groupby([\"difference\"])\n",
    "    unique_val_list_b = list(bdf[\"difference\"].unique())\n",
    "\n",
    "    if os.path.exists(folpath+sym+'-I.csv'):\n",
    "        os.remove(folpath+sym+'-I.csv')\n",
    "    if os.path.exists(folpath+sym+'-II.csv'):\n",
    "        os.remove(folpath+sym+'-II.csv')\n",
    "    if os.path.exists(folpath+sym+'-III.csv'):\n",
    "        os.remove(folpath+sym+'-III.csv')\n",
    "    if os.path.exists(folpath+sym+'-misc.csv'):\n",
    "        os.remove(folpath+sym+'-misc.csv')\n",
    "\n",
    "    for i in unique_val_list_b:\n",
    "        temp_df_new = bgb.get_group(i)\n",
    "        temp_df_new = temp_df_new.drop(temp_df_new.columns[9:],axis=1)\n",
    "        if i == 0:\n",
    "            temp_df_new.to_csv(folpath + sym + '-I.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "\n",
    "        if i == 1 or i == -11:\n",
    "            temp_df_new.to_csv(folpath + sym + '-II.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "\n",
    "        if i == 2 or i == -10:\n",
    "            temp_df_new.to_csv(folpath + sym + '-III.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "\n",
    "    for i in unique_val_list_a:\n",
    "        temp_df_new = agb.get_group(i)\n",
    "        temp_df_new = temp_df_new.drop(temp_df_new.columns[9:],axis=1)\n",
    "        if i == 1 or i == -11:\n",
    "            temp_df_new.to_csv(folpath + sym + '-I.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "\n",
    "        if i == 2 or i == -10:\n",
    "            temp_df_new.to_csv(folpath + sym + '-II.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "\n",
    "        if i == 3 or i == -9:\n",
    "            temp_df_new.to_csv(folpath + sym + '-III.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "\n",
    "    ##########################CREATING LABEL IN STANDARD FORM#####################\n",
    "    for i in range(3):\n",
    "        if i == 0:\n",
    "            file='I'\n",
    "        elif i == 1:\n",
    "            file='II'\n",
    "        elif i == 2:\n",
    "            file='III'\n",
    "        if os.path.exists(r'C:\\users\\admin\\desktop\\Pyspark\\Nifty\\Monthly\\NIFTY-'+file+\".csv\"):\n",
    "            os.remove(r'C:\\users\\admin\\desktop\\Pyspark\\Nifty\\Monthly\\NIFTY-'+file+\".csv\")\n",
    "        if os.path.exists(r'C:\\users\\admin\\desktop\\Pyspark_Contracts\\Nifty\\Monthly_Data\\NIFTY-'+file+'.csv'):\n",
    "            ddf = pd.read_csv(r'C:\\users\\admin\\desktop\\Pyspark_Contracts\\Nifty\\Monthly_Data\\NIFTY-'+file+'.csv')\n",
    "            ddf['Option_Type'] = ddf['ticker'].str[-2:]\n",
    "            ddf['Strike'] = np.where((ddf['ticker'].str.len()==16) | (ddf['ticker'].str.len()==18) , ddf['ticker'].str[-6:-2] , ddf['ticker'].str[-7:-2])\n",
    "            ddf['Symbol'] = 'NIFTY' + 'MONTHLY-' + file + ddf['Strike'].astype(int).astype(str) + ddf['Option_Type']\n",
    "            ddf['ticker'] = ddf['Symbol']\n",
    "            ddf = ddf.drop(ddf.columns[9:],axis=1)\n",
    "            ddf = ddf.rename(columns = {\"ticker\":\"Ticker\"})\n",
    "            ddf.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\Nifty\\Monthly\\\\NIFTY-\"+file+\".csv\",index=False)\n",
    "    print(\"NIFTY MONTHLY CONTRACTS CREATED\")\n",
    "\n",
    "def nifty_weekly():\n",
    "    folpath = r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Weekly_Data\\\\\"\n",
    "    sym = 'NIFTY'\n",
    "    start_time = datetime.strptime('09:15:00', '%H:%M:%S').time()\n",
    "    end_time = datetime.strptime('15:30:00', '%H:%M:%S').time()\n",
    "    expiry_time = datetime.strptime('15:29:59', '%H:%M:%S').time()\n",
    "    s = 'NIFTY'\n",
    "    def add(stri):\n",
    "        obj = datetime.strptime(stri, \"%b\")\n",
    "        month_number = obj.month\n",
    "        return month_number\n",
    "    def get_symbol(tic):\n",
    "        li = list(filter(None, re.split(r'(\\d+)', tic)))\n",
    "        return li[0]\n",
    "    exp_file_path = r\"C:\\Users\\admin\\Downloads\\WeeklyExpiry.csv\"\n",
    "    exp_date = pd.read_excel(r'C:\\users\\admin\\desktop\\Expiry_DT.xlsx')    ## reading the expiry sheet file\n",
    "    exp_df = pd.read_csv(exp_file_path,parse_dates = [\"date\"],dayfirst =True,usecols= ['date', 'Week_number'])\n",
    "    exp_df.rename({'curr_date': 'New_date'}, axis=1, inplace=True)\n",
    "    \n",
    "    ## CALLING FUNCTION NIFTY_DATA TO GENERATE ONLY NIFTY TICKERS\n",
    "    ndata=nifty_data()\n",
    "    \n",
    "    temp = ndata.copy()\n",
    "    temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "    temp['Symbol'] = temp['ticker'].str[:7]\n",
    "    temp = temp[temp['Symbol']!='NIFTYIT']\n",
    "    temp = temp.reset_index(drop=True)\n",
    "    temp['time'] = temp['time'].str.replace(' 15:00:59','15:00:59')\n",
    "    temp['time'] = temp['time'].str.replace(' 9:','09:',regex=True)\n",
    "    temp['time'] = pd.to_datetime(temp['time']).dt.time\n",
    "    temp['date'] = pd.to_datetime(temp['date'])\n",
    "    temp['ticker'] = temp['ticker'].str.replace('30MAR23','29MAR23',regex=True)\n",
    "    temp['Option_Type'] = temp['ticker'].str[-2:]\n",
    "    temp['Temp'] = temp[\"ticker\"].str.replace(s,\"\")\n",
    "    temp['Temp'] = temp['Temp'].str[:-2]\n",
    "    temp['EXPIRY_DT'] = temp['Temp'].str[:7]\n",
    "    temp['EXPIRY_DT'] = pd.to_datetime(temp['EXPIRY_DT'],dayfirst=True)\n",
    "    temp['Length_of_temp'] = temp['Temp'].str.len()\n",
    "    temp['Strike'] = np.where((temp['Temp'].str.len()==9) | (temp['Temp'].str.len()==11) , \n",
    "                              temp['Temp'].str[-4:] , \n",
    "                              temp['Temp'].str[-5:])\n",
    "    temp['Exp_year'] = np.where((temp['Temp'].str.len()==9) | (temp['Temp'].str.len()==10) ,\n",
    "                               temp['Temp'].str[:2] ,\n",
    "                               temp['Temp'].str[5:7])\n",
    "    temp['Exp_month'] = temp['Temp'].str[2:5]\n",
    "    temp['MonthYear'] = temp['Exp_month'] + temp['Exp_year']\n",
    "    temp = temp.rename(columns={'EXPIRY_DT' : 'expiry_date'})\n",
    "    temp1 = pd.merge(temp,exp_df,on='date',how='left')\n",
    "    temp1 = temp1.drop_duplicates()\n",
    "    temp1 = pd.merge(temp1,exp_date,on='MonthYear',how='left')\n",
    "    temp1 = temp1.drop(['Month','Year','MonthYear','Next_Exp_DT'],axis=1)\n",
    "\n",
    "    ## GETTING EXPIRY DATES FOR MONTHLY CONTRACTS\n",
    "    temp1['expiry_date'] = np.where(temp1['Length_of_temp']>=11,temp1['expiry_date'],temp1['Exp_DT'])\n",
    "    temp1 = temp1.drop(['Exp_DT'],axis=1)\n",
    "    exp_df = pd.read_csv(exp_file_path,parse_dates = [\"Weekly_Expiry_Date\"],dayfirst =True,usecols= ['Weekly_Expiry_Date', 'Expiry_Week_number'])\n",
    "    exp_df = exp_df.dropna()\n",
    "    exp_df = exp_df.rename(columns = {'Weekly_Expiry_Date':'expiry_date'})\n",
    "    temp2 = pd.merge(temp1, exp_df, on = 'expiry_date', how = 'left')\n",
    "    temp2 = temp2.drop_duplicates()\n",
    "    temp2['week_diff'] = temp2['Expiry_Week_number'] - temp2['Week_number']\n",
    "    final_df = temp2\n",
    "    final_df[\"week_diff\"] = final_df['week_diff'].replace(np.nan,10000)\n",
    "\n",
    "    agb = final_df.groupby([\"week_diff\"])\n",
    "    unique_val_list_a = list(final_df[\"week_diff\"].unique())\n",
    "    unique_val_list_a = sorted([a for a in unique_val_list_a if a>=0])[0:12]\n",
    "    print(unique_val_list_a)\n",
    "\n",
    "    ############CREATING -I,-II BASED ON WEEK DIFFERENCES###################\n",
    "    if os.path.exists(folpath+sym+'-I.csv'):\n",
    "        os.remove(folpath+sym+'-I.csv')\n",
    "    if os.path.exists(folpath+sym+'-II.csv'):\n",
    "        os.remove(folpath+sym+'-II.csv')\n",
    "    if os.path.exists(folpath+sym+'-III.csv'):\n",
    "        os.remove(folpath+sym+'-III.csv')\n",
    "    if os.path.exists(folpath+sym+'-IV.csv'):\n",
    "        os.remove(folpath+sym+'-IV.csv')\n",
    "    if os.path.exists(folpath+sym+'-V.csv'):\n",
    "        os.remove(folpath+sym+'-V.csv')\n",
    "    if os.path.exists(folpath+sym+'-VI.csv'):\n",
    "        os.remove(folpath+sym+'-VI.csv')\n",
    "    if os.path.exists(folpath+sym+'-VII.csv'):\n",
    "        os.remove(folpath+sym+'-VII.csv')\n",
    "    if os.path.exists(folpath+sym+'-VIII.csv'):\n",
    "        os.remove(folpath+sym+'-VIII.csv')\n",
    "    if os.path.exists(folpath+sym+'-IX.csv'):\n",
    "        os.remove(folpath+sym+'-IX.csv')\n",
    "    if os.path.exists(folpath+sym+'-X.csv'):\n",
    "        os.remove(folpath+sym+'-X.csv')\n",
    "    if os.path.exists(folpath+sym+'-XI.csv'):\n",
    "        os.remove(folpath+sym+'-XI.csv')\n",
    "    if os.path.exists(folpath+sym+'-XII.csv'):\n",
    "        os.remove(folpath+sym+'-XII.csv')  \n",
    "    if os.path.exists(folpath+sym+'-XIII.csv'):\n",
    "        os.remove(folpath+sym+'-XIII.csv')  \n",
    "    if os.path.exists(folpath+sym+'-XIV.csv'):\n",
    "        os.remove(folpath+sym+'-XIV.csv')  \n",
    "        \n",
    "    for i in sorted(unique_val_list_a):\n",
    "        temp_df = agb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        temp_df = temp_df.drop_duplicates()\n",
    "        if i == 0:\n",
    "            temp_df.to_csv(folpath + s + '-I.csv', mode = 'a', header = not os.path.exists(folpath + s + '-I.csv'), index=False)\n",
    "\n",
    "        if i == 1:\n",
    "            temp_df.to_csv(folpath + s + '-II.csv', mode = 'a', header = not os.path.exists(folpath + s + '-II.csv'), index=False)\n",
    "\n",
    "        if i == 2:\n",
    "            temp_df.to_csv(folpath + s + '-III.csv', mode = 'a', header = not os.path.exists(folpath + s + '-III.csv'), index=False)\n",
    "\n",
    "        if i == 3:\n",
    "            temp_df.to_csv(folpath + s + '-IV.csv', mode = 'a', header = not os.path.exists(folpath + s + '-IV.csv'), index=False)\n",
    "\n",
    "        if i == 4:\n",
    "            temp_df.to_csv(folpath + s + '-V.csv', mode = 'a', header = not os.path.exists(folpath + s + '-V.csv'), index=False)\n",
    "\n",
    "        if i == 5:\n",
    "            temp_df.to_csv(folpath + s + '-VI.csv', mode = 'a', header = not os.path.exists(folpath + s + '-VI.csv'), index=False)\n",
    "\n",
    "        if i == 6:\n",
    "            temp_df.to_csv(folpath + s + '-VII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-VII.csv'), index=False)\n",
    "\n",
    "        if i == 7:\n",
    "            temp_df.to_csv(folpath + s + '-VIII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-VIII.csv'), index=False)\n",
    "\n",
    "        if i == 8:\n",
    "            temp_df.to_csv(folpath + s + '-IX.csv', mode = 'a', header = not os.path.exists(folpath + s + '-IX.csv'), index=False)\n",
    "\n",
    "        if i == 9:\n",
    "            temp_df.to_csv(folpath + s + '-X.csv', mode = 'a', header = not os.path.exists(folpath + s + '-X.csv'), index=False)\n",
    "\n",
    "        if i == 10:\n",
    "            temp_df.to_csv(folpath + s + '-XI.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XI.csv'), index=False)\n",
    "\n",
    "        if i == 11:\n",
    "            temp_df.to_csv(folpath + s + '-XII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XII.csv'), index=False)\n",
    "\n",
    "        if i == 12:\n",
    "            temp_df.to_csv(folpath + s + '-XIII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XIII.csv'), index=False)\n",
    "\n",
    "        if i == 13:\n",
    "            temp_df.to_csv(folpath + s + '-XIV.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XIV.csv'), index=False)\n",
    "\n",
    "    #################LABELLING FILES IN STANDARD FORM######################\n",
    "    for i in range(15):\n",
    "        if i==0:\n",
    "            file='I'\n",
    "        elif i==1:\n",
    "            file='II'\n",
    "        elif i==2:\n",
    "            file='III'\n",
    "        elif i==3:\n",
    "            file='IV'\n",
    "        elif i==4:\n",
    "            file='V'\n",
    "        elif i==5:\n",
    "            file='VI'\n",
    "        elif i==6:\n",
    "            file='VII'\n",
    "        elif i==7:\n",
    "            file='VIII'\n",
    "        elif i==8:\n",
    "            file='IX'\n",
    "        elif i==9:\n",
    "            file='X'\n",
    "        elif i==10:\n",
    "            file='XI'\n",
    "        elif i==11:\n",
    "            file='XII'\n",
    "        elif i==12:\n",
    "            file='XIII'\n",
    "        elif i==13:\n",
    "            file='XIV'\n",
    "        if os.path.exists(r'C:\\users\\admin\\desktop\\Pyspark\\Nifty\\Weekly\\NIFTY-'+file+'.csv'):\n",
    "            os.remove(r'C:\\users\\admin\\desktop\\Pyspark\\Nifty\\Weekly\\NIFTY-'+file+'.csv')\n",
    "        if os.path.exists(r'C:\\users\\admin\\desktop\\Pyspark_Contracts\\Nifty\\Weekly_Data\\NIFTY-'+file+'.csv'):\n",
    "            ddf = pd.read_csv(r'C:\\users\\admin\\desktop\\Pyspark_Contracts\\Nifty\\Weekly_Data\\NIFTY-'+file+'.csv')\n",
    "            ddf['Option_Type'] = ddf['ticker'].str[-2:]\n",
    "            ddf['Strike'] = np.where((ddf['ticker'].str.len()==16) | (ddf['ticker'].str.len()==18) , ddf['ticker'].str[-6:-2] , ddf['ticker'].str[-7:-2])\n",
    "            ddf['Symbol'] = 'NIFTY' + 'WEEKLY-' + file + + ddf['Strike'].astype(int).astype(str) + ddf['Option_Type']\n",
    "            ddf['ticker'] = ddf['Symbol']\n",
    "            ddf = ddf.drop(ddf.columns[9:],axis=1)\n",
    "            ddf = ddf.rename(columns = {'date':'Date','ticker':'Ticker'})\n",
    "            ddf = ddf.drop_duplicates()\n",
    "            ddf.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\Nifty\\Weekly\\NIFTY-\"+file+\".csv\",index=False)\n",
    "    print(\"NIFTY WEEKLY CONTRACTS CREATED\")\n",
    "    \n",
    "def nifty_quarterly():\n",
    "    folpath = r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Quarterly_Data\\\\\"\n",
    "    sym = 'NIFTY'\n",
    "    start_time = datetime.strptime('09:15:00', '%H:%M:%S').time()\n",
    "    end_time = datetime.strptime('15:30:00', '%H:%M:%S').time()\n",
    "    expiry_time = datetime.strptime('15:29:59', '%H:%M:%S').time()\n",
    "    s = 'NIFTY'\n",
    "\n",
    "    def add(stri):\n",
    "        obj = datetime.strptime(stri, \"%b\")\n",
    "        month_number = obj.month\n",
    "        return month_number\n",
    "\n",
    "    def get_symbol(tic):\n",
    "        li = list(filter(None, re.split(r'(\\d+)', tic)))\n",
    "        return li[0]\n",
    "\n",
    "    exp_date = pd.read_excel(r'C:\\users\\admin\\desktop\\Expiry_DT.xlsx')    ## reading the expiry sheet file\n",
    "    exp_file_path = r\"C:\\Users\\admin\\Downloads\\MonthlyExpiry.csv\"\n",
    "    exp_df = pd.read_csv(exp_file_path,parse_dates = [\"curr_exp_date\",\"curr_date\"],dayfirst =True,usecols = [\"curr_exp_date\",\"curr_date\"]).dropna()\n",
    "    exp_df.rename({'curr_date': 'New_date'}, axis=1, inplace=True)\n",
    "    \n",
    "    ndata = nifty_data()\n",
    "    temp = ndata.copy()\n",
    "    temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "    temp = temp.reset_index(drop=True)\n",
    "    temp['time'] = temp['time'].str.replace(' 15:00:59','15:00:59')\n",
    "    temp['time'] = temp['time'].str.replace(' 9:','09:',regex=True)\n",
    "    temp['time'] = pd.to_datetime(temp['time']).dt.time\n",
    "    temp['date'] = pd.to_datetime(temp['date'],dayfirst=True)\n",
    "    temp['ticker'] = temp['ticker'].str.replace('30MAR23','29MAR23',regex=True)\n",
    "    temp['Option_Type'] = temp['ticker'].str[-2:]\n",
    "    temp['Temp'] = temp[\"ticker\"].str.replace(s,\"\")\n",
    "    temp['Temp'] = temp['Temp'].str[:-2]\n",
    "    temp['Length_of_temp'] = temp['Temp'].str.len()\n",
    "    temp['Strike'] = np.where((temp['Temp'].str.len()==9) | (temp['Temp'].str.len()==11) , \n",
    "                              temp['Temp'].str[-4:] , \n",
    "                              temp['Temp'].str[-5:])\n",
    "    temp['Exp_Year'] = np.where((temp['Temp'].str.len()==9) | (temp['Temp'].str.len()==10) ,\n",
    "                               temp['Temp'].str[:2] ,\n",
    "                               temp['Temp'].str[5:7])\n",
    "    temp['Current_Year'] = temp['date'].dt.year\n",
    "    temp['Current_Year'] = temp['Current_Year'].astype(str).str[-2:]\n",
    "    temp['Exp_month'] = temp['Temp'].str[2:5]\n",
    "    temp['Exp_Year'] = temp['Exp_Year'].astype('str')\n",
    "    temp['MonthYear'] = temp['Exp_month']+temp['Exp_Year']\n",
    "    temp = pd.merge(temp,exp_date,on='MonthYear')\n",
    "    temp = temp.drop(['MonthYear','Month','Year','Next_Exp_DT'],axis=1)\n",
    "\n",
    "    temp['Length_of_temp'] = temp['Length_of_temp'].astype('int64')\n",
    "    temp_10 = temp[(temp['Length_of_temp']==10) | (temp['Length_of_temp']==9)]\n",
    "\n",
    "    temp_12 = temp[(temp['Length_of_temp']==12) | (temp['Length_of_temp']==11)]\n",
    "\n",
    "    temp_12['DateDate'] = temp_12['Temp'].str[:2]\n",
    "    temp_12['DateDate'] = temp_12['DateDate'].astype('int64')\n",
    "    temp_12['Exp_DT'] = pd.to_datetime(temp['Exp_DT'],dayfirst=True)\n",
    "    temp_12['Exp_Day'] = temp_12['Exp_DT'].dt.day\n",
    "    temp_12 = temp_12[temp_12['Exp_Day']==temp_12['DateDate']]\n",
    "    temp_12 = temp_12.drop(['DateDate','Exp_Day'],axis=1)\n",
    "\n",
    "    temp_df = temp_10.append(temp_12,ignore_index=True)\n",
    "\n",
    "    temp_df['exp_month_number'] = temp_df.apply(lambda row : add(row[\"Exp_month\"]), axis = 1)\n",
    "    temp_df['New_date'] = temp_df['date']\n",
    "    temp_df[\"New_date\"] = pd.to_datetime(temp_df[\"New_date\"])\n",
    "    temp_df[\"current_month_number\"] = temp_df['New_date'].dt.month\n",
    "    temp_df[\"difference\"] = temp_df['exp_month_number'].astype(int) - temp_df[\"current_month_number\"].astype(int)\n",
    "    temp_df['Year_difference'] = temp_df['Exp_Year'].astype(int) - temp_df['Current_Year'].astype(int)\n",
    "    temp_df = temp_df[(temp_df['exp_month_number']==3) | (temp_df['exp_month_number']==6) | (temp_df['exp_month_number']==9) | (temp_df['exp_month_number']==12)]\n",
    "\n",
    "    temp1 = pd.merge(temp_df, \n",
    "                     exp_df, \n",
    "                     on ='New_date', \n",
    "                     how ='left')\n",
    "\n",
    "    temp1.drop(temp1.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "    temp1[\"current_exp_month_number\"] = temp1['curr_exp_date'].dt.month\n",
    "    temp1[\"Diff_months\"] = temp1[\"current_exp_month_number\"] - temp1[\"current_month_number\"]\n",
    "    temp1[\"Diff_months\"] = temp1[\"Diff_months\"].astype(int) \n",
    "\n",
    "    temp1 = temp1[temp1['Exp_DT']>=temp1['curr_exp_date']]                 ## to filter out dates which have wrong ticker\n",
    "\n",
    "    if os.path.exists(folpath+sym+'-I.csv'):\n",
    "        os.remove(folpath+sym+'-I.csv')\n",
    "    if os.path.exists(folpath+sym+'-II.csv'):\n",
    "        os.remove(folpath+sym+'-II.csv')\n",
    "    if os.path.exists(folpath+sym+'-III.csv'):\n",
    "        os.remove(folpath+sym+'-III.csv')\n",
    "    if os.path.exists(folpath+sym+'-IV.csv'):\n",
    "        os.remove(folpath+sym+'-IV.csv')\n",
    "\n",
    "\n",
    "    atemp = temp1[(temp1['Diff_months']==0) & (temp1['Year_difference']==0)]\n",
    "    agb = atemp.groupby(['difference'])\n",
    "    unique_a = list(atemp['difference'].unique())\n",
    "\n",
    "    for i in unique_a:\n",
    "        temp_df = agb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==0 or i==1 or i==2:\n",
    "            temp_df.to_csv(folpath + sym + '-I.csv', mode='a', header=not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "\n",
    "        if i==3 or i==4 or i==5:\n",
    "            temp_df.to_csv(folpath + sym + '-II.csv', mode='a', header=not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "\n",
    "        if i==6 or i==7 or i==8:\n",
    "            temp_df.to_csv(folpath + sym + '-III.csv', mode='a', header=not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "\n",
    "        if i==9 or i==10 or i==11:\n",
    "            temp_df.to_csv(folpath + sym + '-IV.csv', mode='a', header=not os.path.exists(folpath + sym + '-IV.csv'), index=False)\n",
    "\n",
    "\n",
    "    btemp = temp1[(temp1['Diff_months']==0) & (temp1['Year_difference']==1)]\n",
    "    bgb = btemp.groupby(['difference'])\n",
    "    unique_b = list(btemp['difference'].unique())        \n",
    "\n",
    "    for i in unique_b:\n",
    "        temp_df = bgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "\n",
    "        if i==-7 or i==-8 or i==-9:\n",
    "            temp_df.to_csv(folpath + sym + '-II.csv', mode='a', header=not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "\n",
    "        if i==-4 or i==-5 or i==-6:\n",
    "            temp_df.to_csv(folpath + sym + '-III.csv', mode='a', header=not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "\n",
    "        if i==-1 or i==-2 or i==-3:\n",
    "            temp_df.to_csv(folpath + sym + '-IV.csv', mode='a', header=not os.path.exists(folpath + sym + '-IV.csv'), index=False)\n",
    "\n",
    "\n",
    "\n",
    "    ctemp = temp1[((temp1['Diff_months']==1) | (temp1['Diff_months']==-11)) & (temp1['Year_difference']==0)]\n",
    "    cgb = ctemp.groupby(['difference'])\n",
    "    unique_c = list(ctemp['difference'].unique())\n",
    "\n",
    "    for i in unique_c:\n",
    "        temp_df = cgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "\n",
    "        if i==1 or i==2 or i==3:\n",
    "            temp_df.to_csv(folpath + sym + '-I.csv', mode='a', header=not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "\n",
    "        if i==4 or i==5 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-II.csv', mode='a', header=not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "\n",
    "        if i==7 or i==8 or i==9:\n",
    "            temp_df.to_csv(folpath + sym + '-III.csv', mode='a', header=not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "\n",
    "        if i==10 or i==11:\n",
    "            temp_df.to_csv(folpath + sym + '-IV.csv', mode='a', header=not os.path.exists(folpath + sym + '-IV.csv'), index=False)\n",
    "\n",
    "\n",
    "    dtemp = temp1[((temp1['Diff_months']==1) | (temp1['Diff_months']==-11)) & (temp1['Year_difference']==1)]\n",
    "    dgb = dtemp.groupby(['difference'])\n",
    "    unique_d = list(dtemp['difference'].unique())\n",
    "\n",
    "    for i in unique_d:\n",
    "        temp_df = dgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "\n",
    "        if i==-9:\n",
    "            temp_df.to_csv(folpath + sym + '-I.csv', mode='a', header=not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "\n",
    "        if i==-6 or i==-7:\n",
    "            temp_df.to_csv(folpath + sym + '-II.csv', mode='a', header=not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "\n",
    "        if i==-3 or i==-4:\n",
    "            temp_df.to_csv(folpath + sym + '-III.csv', mode='a', header=not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "\n",
    "        if i==0 or i==-1 or i==-2:\n",
    "            temp_df.to_csv(folpath + sym + '-IV.csv', mode='a', header=not os.path.exists(folpath + sym + '-IV.csv'), index=False)\n",
    "\n",
    "    for i in range(4):\n",
    "        if i==0:\n",
    "            file='I'\n",
    "        elif i==1:\n",
    "            file='II'\n",
    "        elif i==2:\n",
    "            file='III'\n",
    "        elif i==3:\n",
    "            file='IV'\n",
    "        if os.path.exists(r'C:\\users\\admin\\desktop\\Pyspark\\Nifty\\Quarterly\\NIFTY-'+file+'.csv'):\n",
    "            os.remove(r'C:\\users\\admin\\desktop\\Pyspark\\Nifty\\Quarterly\\NIFTY-'+file+'.csv')\n",
    "        if os.path.exists(r'C:\\users\\admin\\desktop\\Pyspark_Contracts\\Nifty\\Quarterly_Data\\NIFTY-'+file+'.csv'):\n",
    "            ddf = pd.read_csv(r'C:\\users\\admin\\desktop\\Pyspark_Contracts\\Nifty\\Quarterly_Data\\NIFTY-'+file+'.csv')\n",
    "            ddf['Option_Type'] = ddf['ticker'].str[-2:]\n",
    "            ddf['Strike'] = np.where((ddf['ticker'].str.len()==16) | (ddf['ticker'].str.len()==18) , ddf['ticker'].str[-6:-2] , ddf['ticker'].str[-7:-2])\n",
    "            ddf['Symbol'] = 'NIFTY' + 'QUARTERLY-' + file + ddf['Strike'].astype(int).astype(str) + ddf['Option_Type']\n",
    "            ddf['ticker'] = ddf['Symbol']\n",
    "            ddf = ddf.drop(ddf.columns[9:],axis=1)\n",
    "            ddf = ddf.rename(columns = {'date':'Date','ticker':'Ticker'})\n",
    "            ddf = ddf.drop_duplicates()\n",
    "            ddf.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\Nifty\\Quarterly\\NIFTY-\"+file+\".csv\",index=False)\n",
    "    print(\"NIFTY QUARTERLY CONTRACTS CREATED\")\n",
    "    \n",
    "def nifty_halfyearly():\n",
    "    folpath = r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\\\\"\n",
    "    sym = 'NIFTY'\n",
    "    s = 'NIFTY'\n",
    "    def add(stri):\n",
    "        obj = datetime.strptime(stri, \"%b\")\n",
    "        month_number = obj.month\n",
    "        return month_number\n",
    "    def get_symbol(tic):\n",
    "        li = list(filter(None, re.split(r'(\\d+)', tic)))\n",
    "        return li[0]\n",
    "\n",
    "    exp_date = pd.read_excel(r'C:\\users\\admin\\desktop\\Expiry_DT.xlsx')    ## reading the expiry sheet file\n",
    "\n",
    "    hy_exp_date = pd.read_csv(r\"C:\\Users\\admin\\Downloads\\half_yearly_expiry.csv\",dayfirst=True,parse_dates=['Date','E1'], usecols =['Date','E1'])\n",
    "    \n",
    "    ndata = nifty_data()\n",
    "    temp = ndata.copy()\n",
    "    temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "    temp = temp.reset_index(drop=True)\n",
    "    temp['time'] = temp['time'].str.replace(' 15:00:59','15:00:59')\n",
    "    temp['time'] = temp['time'].str.replace(' 9:','09:',regex=True)\n",
    "    temp['time'] = pd.to_datetime(temp['time']).dt.time\n",
    "    temp['date'] = pd.to_datetime(temp['date'],dayfirst=True)\n",
    "    temp['ticker'] = temp['ticker'].str.replace('30MAR23','29MAR23',regex=True)\n",
    "    temp['Option_Type'] = temp['ticker'].str[-2:]\n",
    "    temp['Temp'] = temp[\"ticker\"].str.replace(s,\"\")\n",
    "    temp['Temp'] = temp['Temp'].str[:-2]\n",
    "    temp['Length_of_temp'] = temp['Temp'].str.len()\n",
    "    temp['Strike'] = np.where((temp['Temp'].str.len()==9) | (temp['Temp'].str.len()==11) , \n",
    "                              temp['Temp'].str[-4:] , \n",
    "                              temp['Temp'].str[-5:])\n",
    "    temp['Exp_Year'] = np.where((temp['Temp'].str.len()==9) | (temp['Temp'].str.len()==10) ,\n",
    "                               temp['Temp'].str[:2] ,\n",
    "                               temp['Temp'].str[5:7])\n",
    "    temp['Current_Year'] = temp['date'].dt.year\n",
    "    temp['Current_Year'] = temp['Current_Year'].astype(str).str[-2:]\n",
    "    temp['Exp_month'] = temp['Temp'].str[2:5]\n",
    "    temp['Exp_Year'] = temp['Exp_Year'].astype('str')\n",
    "    temp['MonthYear'] = temp['Exp_month']+temp['Exp_Year']\n",
    "    temp = pd.merge(temp,exp_date,on='MonthYear')\n",
    "    temp = temp.drop(['MonthYear','Month','Year','Next_Exp_DT'],axis=1)\n",
    "    temp['Length_of_temp'] = temp['Length_of_temp'].astype('int64')\n",
    "    temp_10 = temp[(temp['Length_of_temp']==10) | (temp['Length_of_temp']==9)]\n",
    "\n",
    "    temp_12 = temp[(temp['Length_of_temp']==12) | (temp['Length_of_temp']==11)]\n",
    "    temp_12['DateDate'] = temp_12['Temp'].str[:2]\n",
    "    temp_12['DateDate'] = temp_12['DateDate'].astype('int64')\n",
    "    temp_12['Exp_DT'] = pd.to_datetime(temp['Exp_DT'],dayfirst=True)\n",
    "    temp_12['Exp_Day'] = temp_12['Exp_DT'].dt.day\n",
    "    temp_12 = temp_12[temp_12['Exp_Day']==temp_12['DateDate']]\n",
    "    temp_12 = temp_12.drop(['DateDate','Exp_Day'],axis=1)\n",
    "\n",
    "    temp_df = temp_10.append(temp_12,ignore_index=True)\n",
    "\n",
    "    temp_df['exp_month_number'] = temp_df.apply(lambda row : add(row[\"Exp_month\"]), axis = 1)\n",
    "    temp_df['New_date'] = temp_df['date']\n",
    "    temp_df[\"New_date\"] = pd.to_datetime(temp_df[\"New_date\"])\n",
    "    temp_df[\"current_month_number\"] = temp_df['New_date'].dt.month\n",
    "    temp_df[\"difference\"] = temp_df['exp_month_number'].astype(int) - temp_df[\"current_month_number\"].astype(int)\n",
    "    temp_df['Year_difference'] = temp_df['Exp_Year'].astype(int) - temp_df['Current_Year'].astype(int)\n",
    "    temp_df = temp_df[(temp_df['exp_month_number']==6) | (temp_df['exp_month_number']==12)]\n",
    "\n",
    "    hy_exp_date = hy_exp_date.rename({'Date':'New_date'},axis=1)\n",
    "    temp1 = pd.merge(temp_df, \n",
    "                         hy_exp_date, \n",
    "                         on ='New_date', \n",
    "                         how ='left')\n",
    "\n",
    "    temp1.drop(temp1.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "    temp1[\"current_exp_month_number\"] = temp1['E1'].dt.month\n",
    "    temp1[\"Diff_months\"] = temp1[\"current_exp_month_number\"] - temp1[\"current_month_number\"]\n",
    "    temp1[\"Diff_months\"] = temp1[\"Diff_months\"].astype(int) \n",
    "\n",
    "    temp1 = temp1[temp1['Exp_DT']>=temp1['E1']]                 ## to filter out dates which have wrong ticker\n",
    "\n",
    "    corner_case = temp1[((temp1['current_month_number']==12) & (temp1['current_exp_month_number']==6)) | ((temp1['current_month_number']==6) & (temp1['current_exp_month_number']==12))]\n",
    "    normal_case = temp1[((temp1['current_month_number']>6) & (temp1['current_month_number']<=12) & (temp1['current_exp_month_number']==12)) | ((temp1['current_month_number']>0) & (temp1['current_month_number']<=6) & (temp1['current_exp_month_number']==6))]\n",
    "    if(normal_case.shape[0]+corner_case.shape[0]==temp1.shape[0]):\n",
    "        print(\"Success\")\n",
    "\n",
    "    if os.path.exists(folpath+sym+'-I.csv'):\n",
    "        os.remove(folpath+sym+'-I.csv')\n",
    "    if os.path.exists(folpath+sym+'-II.csv'):\n",
    "        os.remove(folpath+sym+'-II.csv')\n",
    "    if os.path.exists(folpath+sym+'-III.csv'):\n",
    "        os.remove(folpath+sym+'-III.csv')\n",
    "    if os.path.exists(folpath+sym+'-IV.csv'):\n",
    "        os.remove(folpath+sym+'-IV.csv')\n",
    "    if os.path.exists(folpath+sym+'-V.csv'):\n",
    "        os.remove(folpath+sym+'-V.csv')\n",
    "    if os.path.exists(folpath+sym+'-VI.csv'):\n",
    "        os.remove(folpath+sym+'-VI.csv')\n",
    "    if os.path.exists(folpath+sym+'-VII.csv'):\n",
    "        os.remove(folpath+sym+'-VII.csv')\n",
    "    if os.path.exists(folpath+sym+'-VIII.csv'):\n",
    "        os.remove(folpath+sym+'-VIII.csv')\n",
    "    if os.path.exists(folpath+sym+'-IX.csv'):\n",
    "        os.remove(folpath+sym+'-IX.csv')\n",
    "    if os.path.exists(folpath+sym+'-X.csv'):\n",
    "        os.remove(folpath+sym+'-X.csv')\n",
    "\n",
    "    ## NORMAL CASE HY1\n",
    "    atemp = normal_case[(normal_case['Diff_months']<=5) & (normal_case['Diff_months']>=0) & (normal_case['Year_difference']==0) & ((normal_case['difference']>=0) & (normal_case['difference']<6))]\n",
    "    agb = atemp.groupby(['Diff_months'])\n",
    "    unique_a = list(atemp['Diff_months'].unique())\n",
    "    for i in unique_a:\n",
    "        temp_df = agb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i<=5 and i>=0:\n",
    "            temp_df.to_csv(folpath + sym + '-I.csv', mode='a', header=not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "\n",
    "    ## NORMAL CASE HY2\n",
    "    btemp = normal_case[((normal_case['Diff_months']<=5) & (normal_case['Year_difference']==0) & (normal_case['difference']>=6)) | ((normal_case['Diff_months']<=5) & (normal_case['Year_difference']==1) & (normal_case['difference']<=-6))]\n",
    "    bgb = btemp.groupby(['Diff_months'])\n",
    "    unique_b = list(btemp['Diff_months'].unique())\n",
    "    for i in unique_b:\n",
    "        temp_df = bgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i<=6 and i>=0:\n",
    "            temp_df.to_csv(folpath + sym + '-II.csv', mode='a', header=not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "\n",
    "    ## NORMAL CASE HY3\n",
    "    ctemp = normal_case[(normal_case['Diff_months']<=5) & (normal_case['Diff_months']>=0) & (normal_case['Year_difference']==1) & ((normal_case['difference']>=0) & (normal_case['difference']<6))]\n",
    "    cgb = ctemp.groupby(['Diff_months'])\n",
    "    unique_c = list(ctemp['Diff_months'].unique())\n",
    "    for i in unique_c:\n",
    "        temp_df = cgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i<=5 and i>=0:\n",
    "            temp_df.to_csv(folpath + sym + '-III.csv', mode='a', header=not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "\n",
    "    ## NORMAL CASE HY4\n",
    "    dtemp = normal_case[((normal_case['Diff_months']<=5) & (normal_case['Year_difference']==1) & (normal_case['difference']>=6)) | ((normal_case['Diff_months']<=5) & (normal_case['Year_difference']==2) & (normal_case['difference']<=-6))]\n",
    "    dgb = dtemp.groupby(['Diff_months'])\n",
    "    unique_d = list(dtemp['Diff_months'].unique())\n",
    "    for i in unique_d:\n",
    "        temp_df = dgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i<=6 and i>=0:\n",
    "            temp_df.to_csv(folpath + sym + '-IV.csv', mode='a', header=not os.path.exists(folpath + sym + '-IV.csv'), index=False)\n",
    "\n",
    "    ## NORMAL CASE HY5\n",
    "    etemp = normal_case[(normal_case['Diff_months']<=5) & (normal_case['Diff_months']>=0) & (normal_case['Year_difference']==2) & ((normal_case['difference']>=0) & (normal_case['difference']<6))]\n",
    "    egb = etemp.groupby(['Diff_months'])\n",
    "    unique_e = list(etemp['Diff_months'].unique())\n",
    "    for i in unique_e:\n",
    "        temp_df = egb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i<=5 and i>=0:\n",
    "            temp_df.to_csv(folpath + sym + '-V.csv', mode='a', header=not os.path.exists(folpath + sym + '-V.csv'), index=False)\n",
    "\n",
    "    ## NORMAL CASE HY6\n",
    "    ftemp = normal_case[((normal_case['Diff_months']<=5) & (normal_case['Year_difference']==2) & (normal_case['difference']>=6)) | ((normal_case['Diff_months']<=5) & (normal_case['Year_difference']==3) & (normal_case['difference']<=-6))]\n",
    "    fgb = ftemp.groupby(['Diff_months'])\n",
    "    unique_f = list(ftemp['Diff_months'].unique())\n",
    "    for i in unique_f:\n",
    "        temp_df = fgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i<=6 and i>=0:\n",
    "            temp_df.to_csv(folpath + sym + '-VI.csv', mode='a', header=not os.path.exists(folpath + sym + '-VI.csv'), index=False)\n",
    "\n",
    "    ## NORMAL CASE HY7\n",
    "    gtemp = normal_case[(normal_case['Diff_months']<=5) & (normal_case['Diff_months']>=0) & (normal_case['Year_difference']==3) & ((normal_case['difference']>=0) & (normal_case['difference']<6))]\n",
    "    ggb = gtemp.groupby(['Diff_months'])\n",
    "    unique_g = list(gtemp['Diff_months'].unique())\n",
    "    for i in unique_g:\n",
    "        temp_df = ggb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i<=5 and i>=0:\n",
    "            temp_df.to_csv(folpath + sym + '-VII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VII.csv'), index=False)\n",
    "\n",
    "    ## NORMAL CASE HY8\n",
    "    htemp = normal_case[((normal_case['Diff_months']<=5) & (normal_case['Year_difference']==3) & (normal_case['difference']>=6)) | ((normal_case['Diff_months']<=5) & (normal_case['Year_difference']==4) & (normal_case['difference']<=-6))]\n",
    "    hgb = htemp.groupby(['Diff_months'])\n",
    "    unique_h = list(htemp['Diff_months'].unique())\n",
    "    for i in unique_h:\n",
    "        temp_df = hgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i<=6 and i>=0:\n",
    "            temp_df.to_csv(folpath + sym + '-VIII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VIII.csv'), index=False)\n",
    "\n",
    "    ## NORMAL CASE HY9\n",
    "    itemp = normal_case[(normal_case['Diff_months']<=5) & (normal_case['Diff_months']>=0) & (normal_case['Year_difference']==4) & ((normal_case['difference']>=0) & (normal_case['difference']<6))]\n",
    "    igb = itemp.groupby(['Diff_months'])\n",
    "    unique_i = list(itemp['Diff_months'].unique())\n",
    "    for i in unique_i:\n",
    "        temp_df = igb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i<=5 and i>=0:\n",
    "            temp_df.to_csv(folpath + sym + '-IX.csv', mode='a', header=not os.path.exists(folpath + sym + '-IX.csv'), index=False)\n",
    "\n",
    "    ## NORMAL CASE HY10\n",
    "    jtemp = normal_case[((normal_case['Diff_months']<=5) & (normal_case['Year_difference']==4) & (normal_case['difference']>=6)) | ((normal_case['Diff_months']<=5) & (normal_case['Year_difference']==5) & (normal_case['difference']<=-6))]\n",
    "    jgb = jtemp.groupby(['Diff_months'])\n",
    "    unique_j = list(jtemp['Diff_months'].unique())\n",
    "    for i in unique_j:\n",
    "        temp_df = jgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i<=6 and i>=0:\n",
    "            temp_df.to_csv(folpath + sym + '-X.csv', mode='a', header=not os.path.exists(folpath + sym + '-X.csv'), index=False)\n",
    "\n",
    "    ## CORNER CASE HY1\n",
    "    ktemp = corner_case[((corner_case['Diff_months']==6) & (corner_case['Year_difference']==0) & (corner_case['difference']==6)) | ((corner_case['Diff_months']==-6) & (corner_case['Year_difference']==1) & (corner_case['difference']==-6))]\n",
    "    kgb = ktemp.groupby(['Diff_months'])\n",
    "    unique_k = list(ktemp['Diff_months'].unique())\n",
    "    for i in unique_k:\n",
    "        temp_df = kgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-6 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-I.csv', mode='a', header=not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "\n",
    "    ## CORNER CASE HY2\n",
    "    ltemp = corner_case[((corner_case['Diff_months']==6) & (corner_case['difference']==0) & (corner_case['Year_difference']==1)) | ((corner_case['Diff_months']==-6) & (corner_case['difference']==0) & (corner_case['Year_difference']==1))]\n",
    "    lgb = ltemp.groupby(['Diff_months'])\n",
    "    unique_l = list(ltemp['Diff_months'].unique())\n",
    "    for i in unique_l:\n",
    "        temp_df = lgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-6 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-II.csv', mode='a', header=not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "\n",
    "    ## CORNER CASE HY3\n",
    "    mtemp = corner_case[((corner_case['Diff_months']==6) & (corner_case['Year_difference']==1) & (corner_case['difference']==6)) | ((corner_case['Diff_months']==-6) & (corner_case['Year_difference']==2) & (corner_case['difference']==-6))]\n",
    "    mgb = mtemp.groupby(['Diff_months'])\n",
    "    unique_m = list(mtemp['Diff_months'].unique())\n",
    "    for i in unique_m:\n",
    "        temp_df = mgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-6 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-III.csv', mode='a', header=not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "\n",
    "    ## CORNER CASE HY4\n",
    "    ntemp = corner_case[((corner_case['Diff_months']==6) & (corner_case['difference']==0) & (corner_case['Year_difference']==2)) | ((corner_case['Diff_months']==-6) & (corner_case['difference']==0) & (corner_case['Year_difference']==2))]\n",
    "    ngb = ntemp.groupby(['Diff_months'])\n",
    "    unique_n = list(ntemp['Diff_months'].unique())\n",
    "    for i in unique_n:\n",
    "        temp_df = ngb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-6 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-IV.csv', mode='a', header=not os.path.exists(folpath + sym + '-IV.csv'), index=False)\n",
    "\n",
    "    ## CORNER CASE HY5\n",
    "    otemp = corner_case[((corner_case['Diff_months']==6) & (corner_case['Year_difference']==2) & (corner_case['difference']==6)) | ((corner_case['Diff_months']==-6) & (corner_case['Year_difference']==3) & (corner_case['difference']==-6))]\n",
    "    ogb = otemp.groupby(['Diff_months'])\n",
    "    unique_o = list(otemp['Diff_months'].unique())\n",
    "    for i in unique_o:\n",
    "        temp_df = ogb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-6 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-V.csv', mode='a', header=not os.path.exists(folpath + sym + '-V.csv'), index=False)\n",
    "\n",
    "    ## CORNER CASE HY6\n",
    "    ptemp = corner_case[((corner_case['Diff_months']==6) & (corner_case['difference']==0) & (corner_case['Year_difference']==3)) | ((corner_case['Diff_months']==-6) & (corner_case['difference']==0) & (corner_case['Year_difference']==3))]\n",
    "    pgb = ptemp.groupby(['Diff_months'])\n",
    "    unique_p = list(ptemp['Diff_months'].unique())\n",
    "    for i in unique_p:\n",
    "        temp_df = pgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-6 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-VI.csv', mode='a', header=not os.path.exists(folpath + sym + '-VI.csv'), index=False)\n",
    "\n",
    "    ## CORNER CASE HY7\n",
    "    qtemp = corner_case[((corner_case['Diff_months']==6) & (corner_case['Year_difference']==3) & (corner_case['difference']==6)) | ((corner_case['Diff_months']==-6) & (corner_case['Year_difference']==4) & (corner_case['difference']==-6))]\n",
    "    qgb = qtemp.groupby(['Diff_months'])\n",
    "    unique_q = list(qtemp['Diff_months'].unique())\n",
    "    for i in unique_q:\n",
    "        temp_df = qgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-6 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-VII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VII.csv'), index=False)\n",
    "\n",
    "    ## CORNER CASE HY8\n",
    "    rtemp = corner_case[((corner_case['Diff_months']==6) & (corner_case['difference']==0) & (corner_case['Year_difference']==4)) | ((corner_case['Diff_months']==-6) & (corner_case['difference']==0) & (corner_case['Year_difference']==4))]\n",
    "    rgb = rtemp.groupby(['Diff_months'])\n",
    "    unique_r = list(rtemp['Diff_months'].unique())\n",
    "    for i in unique_r:\n",
    "        temp_df = rgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-6 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-VIII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VIII.csv'), index=False)\n",
    "\n",
    "    ## CORNER CASE HY9\n",
    "    stemp = corner_case[((corner_case['Diff_months']==6) & (corner_case['Year_difference']==4) & (corner_case['difference']==6)) | ((corner_case['Diff_months']==-6) & (corner_case['Year_difference']==5) & (corner_case['difference']==-6))]\n",
    "    sgb = stemp.groupby(['Diff_months'])\n",
    "    unique_s = list(stemp['Diff_months'].unique())\n",
    "    for i in unique_s:\n",
    "        temp_df = sgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-6 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-IX.csv', mode='a', header=not os.path.exists(folpath + sym + '-IX.csv'), index=False)\n",
    "\n",
    "    ## CORNER CASE HY10\n",
    "    ttemp = corner_case[((corner_case['Diff_months']==6) & (corner_case['difference']==0) & (corner_case['Year_difference']==5)) | ((corner_case['Diff_months']==-6) & (corner_case['difference']==0) & (corner_case['Year_difference']==5))]\n",
    "    tgb = ttemp.groupby(['Diff_months'])\n",
    "    unique_t = list(ttemp['Diff_months'].unique())\n",
    "    for i in unique_t:\n",
    "        temp_df = tgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-6 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-X.csv', mode='a', header=not os.path.exists(folpath + sym + '-X.csv'), index=False)\n",
    "\n",
    "    for i in range(10):\n",
    "        if(i==0):\n",
    "            file='I'\n",
    "        elif(i==1):\n",
    "            file='II'\n",
    "        elif(i==2):\n",
    "            file='III'\n",
    "        elif(i==3):\n",
    "            file='IV'\n",
    "        elif(i==4):\n",
    "            file='V'\n",
    "        elif(i==5):\n",
    "            file='VI'\n",
    "        elif(i==6):\n",
    "            file='VII'\n",
    "        elif(i==7):\n",
    "            file='VIII'\n",
    "        elif(i==8):\n",
    "            file='IX'\n",
    "        else:\n",
    "            file='X'\n",
    "        if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark\\Nifty\\Half_Yearly\\\\Nifty-\"+file+'.csv'):\n",
    "            os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark\\Nifty\\Half_Yearly\\\\Nifty-\"+file+'.csv')\n",
    "        if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-\"+file+\".csv\"):\n",
    "            df1 = pd.read_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-\"+file+\".csv\")\n",
    "            df1['Option_Type'] = df1['ticker'].str[-2:]\n",
    "            df1['Strike'] = np.where((df1['ticker'].str.len()==16) | (df1['ticker'].str.len()==18) , df1['ticker'].str[-6:-2] , df1['ticker'].str[-7:-2])\n",
    "            df1['Symbol'] = 'NIFTY-' + file + df1['Strike'].astype(int).astype(str) + df1['Option_Type']\n",
    "            df1['ticker'] = df1['Symbol']\n",
    "            df1 = df1.drop(df1.columns[9:],axis=1)\n",
    "            df1.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\Nifty\\Half_Yearly\\\\Nifty-\"+file+'.csv',index=False)\n",
    "    print(\"NIFTY HALF YEARLY CONTRACTS CREATED\")\n",
    "    \n",
    "def nifty_yearly():\n",
    "    for i in range(5):\n",
    "        if(i==0):\n",
    "            file='I'\n",
    "            file1='I'\n",
    "            file2='II'\n",
    "            ## REMOVING YEARLY CONTRACT FILE \n",
    "            if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv'):\n",
    "                os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv')\n",
    "            ## CHECKING IF HALFYEARLY FILE EXISTS\n",
    "            if os.path.exists(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file1+'.csv'):\n",
    "                df1 = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file1+'.csv')\n",
    "            else:\n",
    "                df1 = pd.DataFrame()\n",
    "            ## CHECKING IF HALFYEARLY FILE EXISTS\n",
    "            if os.path.exists(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file2+'.csv'):\n",
    "                df2 = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file2+'.csv')\n",
    "            else:\n",
    "                df2 = pd.DataFrame()\n",
    "        elif(i==1):\n",
    "            file='II'\n",
    "            file1='III'\n",
    "            file2='IV'\n",
    "            ## REMOVING YEARLY CONTRACT FILE \n",
    "            if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv'):\n",
    "                os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv')\n",
    "            ## CHECKING IF HALFYEARLY FILE EXISTS\n",
    "            if os.path.exists(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file1+'.csv'):\n",
    "                df1 = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file1+'.csv')\n",
    "            else:\n",
    "                df1 = pd.DataFrame()\n",
    "            ## CHECKING IF HALFYEARLY FILE EXISTS\n",
    "            if os.path.exists(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file2+'.csv'):\n",
    "                df2 = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file2+'.csv')\n",
    "            else:\n",
    "                df2 = pd.DataFrame()\n",
    "        elif(i==2):\n",
    "            file='III'\n",
    "            file1='V'\n",
    "            file2='VI'\n",
    "            ## REMOVING YEARLY CONTRACT FILE \n",
    "            if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv'):\n",
    "                os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv')\n",
    "            if os.path.exists(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file1+'.csv'):\n",
    "                df1 = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file1+'.csv')\n",
    "            else:\n",
    "                df1 = pd.DataFrame()\n",
    "            if os.path.exists(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file2+'.csv'):\n",
    "                df2 = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file2+'.csv')\n",
    "            else:\n",
    "                df2 = pd.DataFrame()\n",
    "        elif(i==3):\n",
    "            file='IV'\n",
    "            file1='VII'\n",
    "            file2='VIII'\n",
    "            ## REMOVING YEARLY CONTRACT FILE \n",
    "            if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv'):\n",
    "                os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv')\n",
    "            ## CHECKING IF HALFYEARLY FILE EXISTS\n",
    "            if os.path.exists(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file1+'.csv'):\n",
    "                df1 = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file1+'.csv')\n",
    "            else:\n",
    "                df1 = pd.DataFrame()\n",
    "            ## CHECKING IF HALFYEARLY FILE EXISTS\n",
    "            if os.path.exists(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file2+'.csv'):\n",
    "                df2 = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file2+'.csv')\n",
    "            else:\n",
    "                df2 = pd.DataFrame()\n",
    "        elif(i==4):\n",
    "            file='V'\n",
    "            file1='IX'\n",
    "            file2='X'\n",
    "            ## REMOVING YEARLY CONTRACT FILE \n",
    "            if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv'):\n",
    "                os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv')\n",
    "            ## CHECKING IF HALFYEARLY FILE EXISTS\n",
    "            if os.path.exists(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file1+'.csv'):\n",
    "                df1 = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file1+'.csv')\n",
    "            else:\n",
    "                df1 = pd.DataFrame()\n",
    "            ## CHECKING IF HALFYEARLY FILE EXISTS\n",
    "            if os.path.exists(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file2+'.csv'):\n",
    "                df2 = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file2+'.csv')\n",
    "            else:\n",
    "                df2 = pd.DataFrame()\n",
    "        \n",
    "        if df1.empty and df2.empty:\n",
    "            print(\"No contracts for Half yearly\",file1,file2)\n",
    "        else:\n",
    "            print(i,\"YEARLY\",file,\"HALFYEARLY\",file1,file2)\n",
    "            if not df1.empty:\n",
    "                df1 = df1.sort_values(by='date')\n",
    "                df1['Month'] = df1['ticker'].str[7:10]\n",
    "                df1 = df1[df1['Month']=='DEC']\n",
    "            if not df2.empty:\n",
    "                df2 = df2.sort_values(by='date')\n",
    "                df2['Month'] = df2['ticker'].str[7:10]\n",
    "                df2 = df2[df2['Month']=='DEC']\n",
    "            final_df = df1.append(df2,ignore_index=True)\n",
    "            if not final_df.empty:\n",
    "                final_df = final_df.drop_duplicates()\n",
    "                final_df = final_df.drop(final_df.columns[9:],axis=1)\n",
    "                final_df.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv',index=False)\n",
    "\n",
    "    for i in range(5):\n",
    "        if(i==0):\n",
    "            file='I'\n",
    "        if(i==1):\n",
    "            file='II'\n",
    "        if(i==2):\n",
    "            file='III'\n",
    "        if(i==3):\n",
    "            file='IV'\n",
    "        if(i==4):\n",
    "            file='V'\n",
    "        if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark\\Nifty\\Yearly\\\\Nifty-\"+file+\".csv\"):\n",
    "            os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark\\Nifty\\Yearly\\\\Nifty-\"+file+\".csv\")\n",
    "        if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv'):\n",
    "            df = pd.read_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv')\n",
    "            df['Option_Type'] = df['ticker'].str[-2:]\n",
    "            df['Strike'] = np.where((df['ticker'].str.len()==16) | (df['ticker'].str.len()==18) , df['ticker'].str[-6:-2] , df['ticker'].str[-7:-2])\n",
    "            df['Symbol'] = 'NIFTY-' + file + df['Strike'].astype(int).astype(str) + df['Option_Type']\n",
    "            df['ticker'] = df['Symbol']\n",
    "            df = df.drop(df.columns[9:],axis=1)\n",
    "            df.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\Nifty\\Yearly\\\\Nifty-\"+file+\".csv\",index=False)\n",
    "    print(\"YEARLY CONTRACTS GENERATED\")\n",
    "\n",
    "def finnifty_data():\n",
    "    spark = SparkSession.builder.config(\"spark.jars\", \"C:\\\\Users\\\\admin\\\\Downloads\\\\postgresql-42.5.0.jar\") \\\n",
    "    .master(\"local\").appName(\"PySpark_Postgres_test\").getOrCreate()\n",
    "    #spark.sparkContext.setLogLevel(\"WARN\")\n",
    "    df = spark.read.format(\"jdbc\").option(\"url\", \"jdbc:postgresql://swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com/RawDataBase\").option(\"user\",\"postgres\").option(\"password\",\"swancap123\")\\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\").option(\"dbtable\", tablename)\\\n",
    "        .option(\"user\", \"postgres\").option(\"password\", \"swancap123\").load()\n",
    "    ## GETTING ONLY TIME IN TIME COLUMN\n",
    "    q = df.withColumn('time',date_format('time', 'HH:mm:ss'))\n",
    "    ## FILTERING FINNIFTY DATA\n",
    "    fndata = q.filter(q.ticker.contains('FINNIFTY') & ((q.ticker.endswith('E.NFO'))| (q.ticker.endswith('E'))))\n",
    "    ## REPLACING .NFO IN ticker\n",
    "    fndata = fndata.withColumn('ticker',regexp_replace('ticker','.NFO',''))\n",
    "    fndata = fndata.drop(col('ticker_check'))\n",
    "    ## CONVERTING PYSPARK DATAFRAME TO PANDAS DATAFRAME\n",
    "    fndata=fndata.toPandas()\n",
    "    return fndata\n",
    "\n",
    "def finnifty_monthly():\n",
    "    exp_df = pd.read_excel(r\"C:\\Users\\admin\\Desktop\\Expiry_Dates\\Finnifty.xlsx\",sheet_name='Monthly')\n",
    "    exp_df.rename({'curr_date': 'New_date'}, axis=1, inplace=True)\n",
    "    exp_date = pd.read_excel(r\"C:\\Users\\admin\\Desktop\\Expiry_Dates\\Finnifty_Monthly_Expiry.xlsx\")\n",
    "\n",
    "    folpath = r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\FinNifty\\Monthly_Data\\\\\"\n",
    "    finalpath = r\"C:\\Users\\admin\\Desktop\\Pyspark\\FinNifty\\Monthly\\\\\"\n",
    "    s = 'FINNIFTY'\n",
    "    def add(stri):\n",
    "        obj = datetime.strptime(stri, \"%b\")\n",
    "        month_number = obj.month\n",
    "        return month_number\n",
    "    sym = 'FINNIFTY'\n",
    "    fndata = finnifty_data()\n",
    "    dff = fndata.copy()\n",
    "    dff = dff[dff['ticker'].str.contains('FINNIFTY')]\n",
    "    dff = dff[(dff['ticker'].str.endswith('E')) | (dff['ticker'].str.endswith('E.NFO'))]\n",
    "    dff = dff.loc[:, ~dff.columns.str.contains('^Unnamed')]\n",
    "    dff['time'] = pd.to_datetime(dff['time']).dt.time\n",
    "    dff['date'] = pd.to_datetime(dff['date'],dayfirst=True)\n",
    "    dff['ticker'] = dff['ticker'].str.replace('30MAR23','29MAR23',regex=True)\n",
    "\n",
    "    dff['Option_Type'] = dff['ticker'].str[-2:]\n",
    "    dff['Temp'] = dff[\"ticker\"].str.replace(s,\"\")\n",
    "    dff['Temp'] = dff['Temp'].str[:-2]\n",
    "    dff['Length_of_Temp'] = dff['Temp'].str.len()\n",
    "    dff['Strike'] = np.where((dff['Temp'].str.len()==9) | (dff['Temp'].str.len()==11) , \n",
    "                              dff['Temp'].str[-4:] , \n",
    "                              dff['Temp'].str[-5:])\n",
    "    dff['Exp_Year'] = np.where((dff['Temp'].str.len()==9) | (dff['Temp'].str.len()==10) ,\n",
    "                               dff['Temp'].str[:2] ,\n",
    "                               dff['Temp'].str[5:7])\n",
    "    dff['Exp_month'] = dff['Temp'].str[2:5]\n",
    "\n",
    "    dff['Exp_Year'] = dff['Exp_Year'].astype('str')\n",
    "    dff['MonthYear'] = dff['Exp_month']+dff['Exp_Year']\n",
    "    dff = pd.merge(dff,exp_date,on='MonthYear')\n",
    "    dff = dff.drop(['MonthYear','Month','Year'],axis=1)\n",
    "    dff = dff.rename(columns={'Exp_DT':'Monthly_Expiry'})\n",
    "\n",
    "    dff['Length_of_Temp'] = dff['Length_of_Temp'].astype('int64')\n",
    "    temp_10 = dff[(dff['Length_of_Temp']==10) | (dff['Length_of_Temp']==9)]\n",
    "\n",
    "    temp_12 = dff[(dff['Length_of_Temp']==12) | (dff['Length_of_Temp']==11)]\n",
    "    temp_12['DateDate'] = temp_12['Temp'].str[:2]\n",
    "    temp_12['DateDate'] = temp_12['DateDate'].astype('int64')\n",
    "    temp_12['Exp_DT'] = pd.to_datetime(temp_12['Monthly_Expiry'],dayfirst=True)\n",
    "    temp_12['Exp_Day'] = temp_12['Exp_DT'].dt.day\n",
    "    temp_12 = temp_12[temp_12['Exp_Day']==temp_12['DateDate']]\n",
    "    temp_12 = temp_12.drop(['DateDate','Exp_Day'],axis=1)\n",
    "\n",
    "    temp_df = temp_10.append(temp_12,ignore_index=True)\n",
    "    temp_df['exp_month_number'] = temp_df.apply(lambda row : add(row[\"Exp_month\"]), axis = 1)\n",
    "    temp_df['New_date'] = temp_df['date']\n",
    "    temp_df[\"New_date\"] = pd.to_datetime(temp_df[\"New_date\"])\n",
    "    \n",
    "    temp_df[\"current_month_number\"] = temp_df['New_date'].dt.month\n",
    "    temp_df[\"difference\"] = temp_df['exp_month_number'].astype(int) - temp_df[\"current_month_number\"].astype(int)\n",
    "\n",
    "    temp_df1 = pd.merge(temp_df, \n",
    "                     exp_df, \n",
    "                     on ='New_date', \n",
    "                     how ='left')\n",
    "    temp_df1.drop(temp_df1.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "    temp_df1[\"current_exp_month_number\"] = temp_df1['curr_exp_date'].dt.month\n",
    "    temp_df1[\"Diff_months\"] = temp_df1[\"current_exp_month_number\"] - temp_df1[\"current_month_number\"]\n",
    "    temp_df1[\"Diff_months\"] = temp_df1[\"Diff_months\"].astype(int) \n",
    "    temp_df1['Current_Year'] = temp_df1['New_date'].dt.year.astype(str).str[-2:]\n",
    "\n",
    "    bdf = temp_df1[temp_df1[\"Diff_months\"] == 0]\n",
    "    adf = temp_df1[(temp_df1[\"Diff_months\"] == 1) | (temp_df1[\"Diff_months\"] == -11)]\n",
    "    agb = adf.groupby([\"difference\"])\n",
    "    unique_val_list_a = list(adf[\"difference\"].unique())\n",
    "\n",
    "    bgb = bdf.groupby([\"difference\"])\n",
    "    unique_val_list_b = list(bdf[\"difference\"].unique())\n",
    "\n",
    "    ## TO AVOID OVERWRITING, REMOVING FILE\n",
    "    for i in range(3):\n",
    "        if(i==0):\n",
    "            file='-I'\n",
    "        if(i==1):\n",
    "            file='-II'\n",
    "        if(i==2):\n",
    "            file='-III'\n",
    "        if(os.path.exists(folpath+sym+file+\".csv\")):\n",
    "            os.remove(folpath+sym+file+\".csv\")\n",
    "\n",
    "    for i in unique_val_list_b:\n",
    "        temp_df_new = bgb.get_group(i)\n",
    "        temp_df_new = temp_df_new.drop(temp_df_new.columns[9:],axis=1)\n",
    "        if i == 0:\n",
    "            temp_df_new.to_csv(folpath + sym + '-I.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "\n",
    "        if i == 1 or i == -11:\n",
    "            temp_df_new.to_csv(folpath + sym + '-II.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "\n",
    "        if i == 2 or i == -10:\n",
    "            temp_df_new.to_csv(folpath + sym + '-III.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "\n",
    "    for i in unique_val_list_a:\n",
    "        temp_df_new = agb.get_group(i)\n",
    "        temp_df_new = temp_df_new.drop(temp_df_new.columns[9:],axis=1)\n",
    "        if i == 1 or i == -11:\n",
    "            temp_df_new.to_csv(folpath + sym + '-I.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "\n",
    "        if i == 2 or i == -10:\n",
    "            temp_df_new.to_csv(folpath + sym + '-II.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "\n",
    "        if i == 3 or i == -9:\n",
    "            temp_df_new.to_csv(folpath + sym + '-III.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "\n",
    "    for i in range(3):\n",
    "        if(i==0):\n",
    "            file='-I'\n",
    "        if(i==1):\n",
    "            file='-II'\n",
    "        if(i==2):\n",
    "            file='-III'\n",
    "\n",
    "        if os.path.exists(finalpath+sym+file+\".csv\"):\n",
    "            os.remove(finalpath+sym+file+\".csv\")\n",
    "        if os.path.exists(folpath+sym+file+\".csv\"):\n",
    "            df = pd.read_csv(folpath+sym+file+\".csv\")\n",
    "            df['Option_Type'] = df['ticker'].str[-2:]\n",
    "            df['Strike'] = np.where((df['ticker'].str.len()==19) | (df['ticker'].str.len()==21) , df['ticker'].str[-6:-2] , df['ticker'].str[-7:-2])\n",
    "            df['Symbol'] = 'FINNIFTYMONTHLY' + file + df['Strike'].astype(int).astype(str) + df['Option_Type']\n",
    "            df['ticker'] = df['Symbol']\n",
    "            df = df.drop(df.columns[9:],axis=1)\n",
    "            df = df.sort_values(by='date')\n",
    "            print(file,df.shape[0])\n",
    "            df = df.drop_duplicates()\n",
    "            print(file,df.shape[0])\n",
    "            df.to_csv(finalpath+sym+file+\".csv\",index=False)\n",
    "    print(\"FINNIFTY MONTHLY CONTRACTS GENERATED\")\n",
    "    \n",
    "def finnifty_weekly():\n",
    "    exp_df1 = pd.read_excel(r\"C:\\Users\\admin\\Desktop\\Expiry_Dates\\Finnifty.xlsx\",sheet_name='Weekly',parse_dates=['date'],usecols= ['date','Week_number'])\n",
    "    exp_df2 = pd.read_excel(r\"C:\\Users\\admin\\Desktop\\Expiry_Dates\\Finnifty.xlsx\",sheet_name='Weekly',parse_dates=['Weekly_Expiry_Date'],usecols= ['Weekly_Expiry_Date', 'Expiry_Week_number'])\n",
    "    exp_date = pd.read_excel(r\"C:\\Users\\admin\\Desktop\\Expiry_Dates\\Finnifty_Monthly_Expiry.xlsx\")\n",
    "\n",
    "    folpath = r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\FinNifty\\Weekly_Data\\\\\"\n",
    "    finalpath = r\"C:\\Users\\admin\\Desktop\\Pyspark\\FinNifty\\Weekly\\\\\"\n",
    "    s = 'FINNIFTY'\n",
    "    def add(stri):\n",
    "        obj = datetime.strptime(stri, \"%b\")\n",
    "        month_number = obj.month\n",
    "        return month_number\n",
    "    sym = 'FINNIFTY'\n",
    "    fndata = finnifty_data()\n",
    "    dff = fndata.copy()\n",
    "    dff = dff[dff['ticker'].str.contains('FINNIFTY')]\n",
    "    dff = dff[(dff['ticker'].str.endswith('E')) | (dff['ticker'].str.endswith('E.NFO'))]\n",
    "    dff = dff.loc[:, ~dff.columns.str.contains('^Unnamed')]\n",
    "    dff['time'] = pd.to_datetime(dff['time']).dt.time\n",
    "    dff['date'] = pd.to_datetime(dff['date'],dayfirst=True)\n",
    "    dff['ticker'] = dff['ticker'].str.replace('30MAR23','29MAR23',regex=True)\n",
    "\n",
    "    dff['Option_Type'] = dff['ticker'].str[-2:]\n",
    "    dff['Temp'] = dff[\"ticker\"].str.replace(s,\"\")\n",
    "    dff['Temp'] = dff['Temp'].str[:-2]\n",
    "    dff['Length_of_Temp'] = dff['Temp'].str.len()\n",
    "    dff['Strike'] = np.where((dff['Temp'].str.len()==9) | (dff['Temp'].str.len()==11) , \n",
    "                              dff['Temp'].str[-4:] , \n",
    "                              dff['Temp'].str[-5:])\n",
    "    dff['Exp_Year'] = np.where((dff['Temp'].str.len()==9) | (dff['Temp'].str.len()==10) ,\n",
    "                               dff['Temp'].str[:2] ,\n",
    "                               dff['Temp'].str[5:7])\n",
    "    dff['Exp_month'] = dff['Temp'].str[2:5]\n",
    "    dff['EXPIRY_DT'] = dff['Temp'].str[:7]\n",
    "    dff['EXPIRY_DT'] = pd.to_datetime(dff['EXPIRY_DT'],dayfirst=True)\n",
    "\n",
    "    dff['Exp_Year'] = dff['Exp_Year'].astype('str')\n",
    "    dff['MonthYear'] = dff['Exp_month']+dff['Exp_Year']\n",
    "    dff = pd.merge(dff,exp_date,on='MonthYear')\n",
    "    dff = dff.drop(['MonthYear','Month','Year'],axis=1)\n",
    "    dff = dff.rename(columns={'Exp_DT':'Monthly_Expiry'})\n",
    "\n",
    "    ## GETTING EXPIRY DATES FOR MONTHLY CONTRACTS\n",
    "    dff['expiry_date'] = np.where(dff['Length_of_Temp']>=11,dff['EXPIRY_DT'],dff['Monthly_Expiry'])\n",
    "    dff = dff.drop(['EXPIRY_DT',\"Monthly_Expiry\"],axis=1)\n",
    "    ## GETTING WEEK NUMBER OF CURRENT DATE\n",
    "    dff = dff.rename(columns={'Date':'date'})\n",
    "    dff = pd.merge(dff,exp_df1,on='date',how='left')\n",
    "\n",
    "    ## GETTING WEEK NUMBER OF EXPIRY DATES\n",
    "    exp_df2['Weekly_Expiry_Date'] = pd.to_datetime(exp_df2['Weekly_Expiry_Date'],dayfirst=True)\n",
    "    exp_df2 = exp_df2.dropna()\n",
    "    exp_df2 = exp_df2.rename(columns = {'Weekly_Expiry_Date':'expiry_date'})\n",
    "    temp_df = pd.merge(dff, exp_df2, on = 'expiry_date', how = 'left')\n",
    "    temp_df = temp_df.drop_duplicates()\n",
    "    temp_df['week_diff'] = temp_df['Expiry_Week_number'] - temp_df['Week_number']\n",
    "    final_df = temp_df.copy()\n",
    "    final_df[\"week_diff\"] = final_df['week_diff'].replace(np.nan,10000)\n",
    "    \n",
    "    agb = final_df.groupby([\"week_diff\"])\n",
    "    unique_val_list_a = list(final_df[\"week_diff\"].unique())\n",
    "    unique_val_list_a = sorted([a for a in unique_val_list_a if a>=0])[0:14]\n",
    "    print(unique_val_list_a)\n",
    "    for i in range(12):\n",
    "        if(i==0):\n",
    "            file='-I'\n",
    "        if(i==1):\n",
    "            file='-II'\n",
    "        if(i==2):\n",
    "            file='-III'\n",
    "        if(i==3):\n",
    "            file='-IV'\n",
    "        if(i==4):\n",
    "            file='-V'\n",
    "        if(i==5):\n",
    "            file='-VI'\n",
    "        if(i==6):\n",
    "            file='-VII'\n",
    "        if(i==7):\n",
    "            file='-VIII'\n",
    "        if(i==8):\n",
    "            file='-IX'\n",
    "        if(i==9):\n",
    "            file='-X'\n",
    "        if(i==10):\n",
    "            file='-XI'\n",
    "        if(i==11):\n",
    "            file='-XII'\n",
    "            \n",
    "        if(os.path.exists(folpath+sym+file+\".csv\")):\n",
    "            os.remove(folpath+sym+file+\".csv\")\n",
    "\n",
    "    for i in sorted(unique_val_list_a):\n",
    "        temp_df = agb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i == 0:\n",
    "            temp_df.to_csv(folpath + s + '-I.csv', mode = 'a', header = not os.path.exists(folpath + s + '-I.csv'), index=False)\n",
    "\n",
    "        if i == 1:\n",
    "            temp_df.to_csv(folpath + s + '-II.csv', mode = 'a', header = not os.path.exists(folpath + s + '-II.csv'), index=False)\n",
    "\n",
    "        if i == 2:\n",
    "            temp_df.to_csv(folpath + s + '-III.csv', mode = 'a', header = not os.path.exists(folpath + s + '-III.csv'), index=False)\n",
    "\n",
    "        if i == 3:\n",
    "            temp_df.to_csv(folpath + s + '-IV.csv', mode = 'a', header = not os.path.exists(folpath + s + '-IV.csv'), index=False)\n",
    "\n",
    "        if i == 4:\n",
    "            temp_df.to_csv(folpath + s + '-V.csv', mode = 'a', header = not os.path.exists(folpath + s + '-V.csv'), index=False)\n",
    "\n",
    "        if i == 5:\n",
    "            temp_df.to_csv(folpath + s + '-VI.csv', mode = 'a', header = not os.path.exists(folpath + s + '-VI.csv'), index=False)\n",
    "\n",
    "        if i == 6:\n",
    "            temp_df.to_csv(folpath + s + '-VII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-VII.csv'), index=False)\n",
    "\n",
    "        if i == 7:\n",
    "            temp_df.to_csv(folpath + s + '-VIII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-VIII.csv'), index=False)\n",
    "\n",
    "        if i == 8:\n",
    "            temp_df.to_csv(folpath + s + '-IX.csv', mode = 'a', header = not os.path.exists(folpath + s + '-IX.csv'), index=False)\n",
    "\n",
    "        if i == 9:\n",
    "            temp_df.to_csv(folpath + s + '-X.csv', mode = 'a', header = not os.path.exists(folpath + s + '-X.csv'), index=False)\n",
    "\n",
    "        if i == 10:\n",
    "            temp_df.to_csv(folpath + s + '-XI.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XI.csv'), index=False)\n",
    "\n",
    "        if i == 11:\n",
    "            temp_df.to_csv(folpath + s + '-XII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XII.csv'), index=False)\n",
    "\n",
    "        if i == 12:\n",
    "            temp_df.to_csv(folpath + s + '-XIII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XIII.csv'), index=False)\n",
    "\n",
    "        if i == 13:\n",
    "            temp_df.to_csv(folpath + s + '-XIV.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XIV.csv'), index=False)\n",
    "\n",
    "    for i in range(12):\n",
    "        if(i==0):\n",
    "            file='-I'\n",
    "        if(i==1):\n",
    "            file='-II'\n",
    "        if(i==2):\n",
    "            file='-III'\n",
    "        if(i==3):\n",
    "            file='-IV'\n",
    "        if(i==4):\n",
    "            file='-V'\n",
    "        if(i==5):\n",
    "            file='-VI'\n",
    "        if(i==6):\n",
    "            file='-VII'\n",
    "        if(i==7):\n",
    "            file='-VIII'\n",
    "        if(i==8):\n",
    "            file='-IX'\n",
    "        if(i==9):\n",
    "            file='-X'\n",
    "        if(i==10):\n",
    "            file='-XI'\n",
    "        if(i==11):\n",
    "            file='-XII'\n",
    "        if(i==12):\n",
    "            file='-XIII'\n",
    "        if(i==13):\n",
    "            file='-XIV'\n",
    "        if os.path.exists(finalpath+sym+file+\".csv\"):\n",
    "            os.remove(finalpath+sym+file+\".csv\")\n",
    "        if(os.path.exists(folpath+sym+file+\".csv\")):\n",
    "            print(file)\n",
    "            df = pd.read_csv(folpath+sym+str(file)+\".csv\")\n",
    "            df['Option_Type'] = df['ticker'].str[-2:]\n",
    "            df['Strike'] = np.where((df['ticker'].str.len()==19) | (df['ticker'].str.len()==21) , df['ticker'].str[-6:-2] , df['ticker'].str[-7:-2])\n",
    "            df['Symbol'] = 'FINNIFTYWEEKLY' + file + df['Strike'].astype(int).astype(str) + df['Option_Type']\n",
    "            df['ticker'] = df['Symbol']\n",
    "            df = df.drop(df.columns[9:],axis=1)\n",
    "            df = df.sort_values(by='date')\n",
    "            print(df.shape[0])\n",
    "            df = df.drop_duplicates()\n",
    "            print(df.shape[0])\n",
    "            df.to_csv(finalpath+sym+str(file)+\".csv\",index=False)\n",
    "        else:\n",
    "            print(file,\"not exists\")\n",
    "    print(\"FINNIFTY WEEKLY CONTRACTS CREATED\")\n",
    "\n",
    "    \n",
    "print(\"BANKNIFTY CONTRACTS BEING CREATED\")\n",
    "banknifty_monthly()\n",
    "banknifty_weekly()\n",
    "banknifty_quarterly()\n",
    "banknifty_halfyearly()\n",
    "banknifty_yearly()\n",
    "print(\"\\nBANKNIFTY CONTRACTS CREATED\")\n",
    "\n",
    "print(\"\\n\\nNIFTY CONTRACTS BEING CREATED\")\n",
    "nifty_monthly()\n",
    "nifty_weekly()\n",
    "nifty_quarterly()\n",
    "nifty_halfyearly()\n",
    "nifty_yearly()\n",
    "print(\"\\nNIFTY CONTRACTS CREATED\")\n",
    "\n",
    "print(\"\\n\\nFINNIFTY CONTRACTS BEING CREATED\")\n",
    "finnifty_monthly()\n",
    "finnifty_weekly()\n",
    "print(\"\\nFINNIFTY CONTRACTS CREATED\")\n",
    "\n",
    "et = time.time()\n",
    "print(\"ELAPSED TIME\",et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eef83c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
