{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a28c47-5191-473d-b38e-d1e0c73d323c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a date in YYYY-MM-DD format  2023-09-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r06092023\n",
      "BankNifty Contracts being created\n",
      "Week1\n",
      "Week2\n",
      "Week3\n",
      "Week5\n",
      "\n",
      "\n",
      "Week4\n",
      "Week8\n",
      "Week13\n",
      "Weekly Contracts Created!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2ad50ded4d40c4b11442741874fe7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly1\n",
      "Monthly2\n",
      "Monthly3\n",
      "Monthly Contracts Created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30df9a256c924ef5bc0a23675f2bf803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarter1\n",
      "Quarter2\n",
      "Quarterly Contracts Created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38790ed1aed7486abc3202a506fbfee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HalfYearly1\n",
      "Half Yearly contracts created!\n",
      "No Contracts for HalfYearly 3 4\n",
      "No Contracts for HalfYearly 5 6\n",
      "No Contracts for HalfYearly 7 8\n",
      "No Contracts for HalfYearly 9 10\n",
      "Yearly Contracts Created\n",
      "BankNifty Contracts created\n",
      "\n",
      "Nifty Contracts being created\n",
      "Week1\n",
      "Week2\n",
      "Week3\n",
      "Week4\n",
      "Week5\n",
      "Week8\n",
      "Week13\n",
      "Weekly Contracts Created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf34fc55ea45442a9b8053179245e038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly1\n",
      "Monthly2\n",
      "Monthly3\n",
      "Monthly Contracts Created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b3a69080df4d379c2a1c2cc6f76995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarter1\n",
      "Quarter2\n",
      "Quarter3\n",
      "Quarter4\n",
      "Quarterly Contracts Created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26aea8a1e96d4a00a1b202524f29c030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HalfYearly1\n",
      "HalfYearly2\n",
      "HalfYearly3\n",
      "HalfYearly5\n",
      "Half Yearly contracts created!\n",
      "No Contracts for HalfYearly 7 8\n",
      "No Contracts for HalfYearly 9 10\n",
      "Yearly Contracts Created\n",
      "Nifty Contracts created\n",
      "\n",
      "FinNifty Contracts being created\n",
      "Week1\n",
      "Week2\n",
      "Week3\n",
      "Weekly Contracts Created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8afd553719142c283fdf4fdff427e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly1\n",
      "Monthly Contracts Created\n",
      "FinNifty Contracts created\n",
      "\n",
      "\n",
      "Elapsed time 18.966927528381348\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import os\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import array_contains\n",
    "from pyspark.sql.functions import date_format\n",
    "from pyspark.sql.functions import *\n",
    "import requests\n",
    "from telethon.sync import TelegramClient\n",
    "\n",
    "date1 = input('Enter a date in YYYY-MM-DD format ')                                     ## TO BE CHANGED DAILY AS PER UPDATION DATE\n",
    "year , month , day = map(int,date1.split('-'))\n",
    "day , month = f\"{day:02d}\",f\"{month:02d}\"\n",
    "tablename=\"r\"+str(day)+str(month)+str(year)\n",
    "print(tablename)\n",
    "\n",
    "st = time.time()\n",
    "def banknifty_data():\n",
    "    spark = SparkSession.builder.config(\"spark.jars\", \"C:\\\\Users\\\\admin\\\\Downloads\\\\postgresql-42.5.1.jar\") \\\n",
    "    .master(\"local\").appName(\"PySpark_Postgres_test\").getOrCreate()\n",
    "    \n",
    "    df = spark.read.format(\"jdbc\").option(\"url\", \"jdbc:postgresql://swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com/RawDataBase\").option(\"user\",\"postgres\").option(\"password\",\"swancap123\")\\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\").option(\"dbtable\", tablename)\\\n",
    "        .option(\"user\", \"postgres\").option(\"password\", \"swancap123\").load()\n",
    "\n",
    "    ## GETTING ONLY TIME IN TIME COLUMN\n",
    "    q = df.withColumn('time',date_format('time', 'HH:mm:ss'))\n",
    "    banknifty = q.filter(q.ticker.contains('BANKNIFTY') & ((q.ticker.endswith('E.NFO'))| (q.ticker.endswith('E'))))\n",
    "    ## REPLACING .NFO IN ticker\n",
    "    banknifty = banknifty.withColumn('ticker',regexp_replace('ticker','.NFO',''))\n",
    "\n",
    "    ## CONVERTING PYSPARK DATAFRAME TO PANDAS DATAFRAME\n",
    "    banknifty = banknifty.toPandas()\n",
    "    banknifty = banknifty.rename(columns={'ticker':'Ticker','date':'Date','time':'Time','open':'Open','high':'High','low':'Low','close':'Close','volume':'Volume'})\n",
    "    \n",
    "    # df = pd.read_csv(r\"C:\\\\users\\\\admin\\\\desktop\\\\NSEFO_06092023.csv\")\n",
    "    # banknifty = df[(df['Ticker'].str.contains('BANKNIFTY') & (df['Ticker'].str.endswith('E.NFO')))].reset_index(drop=True)\n",
    "    # banknifty['Ticker'] = banknifty['Ticker'].str.replace('.NFO','')\n",
    "    \n",
    "    banknifty = banknifty[(banknifty['Time']>='09:15:59') & (banknifty['Time']<='15:29:59')].reset_index(drop=True)\n",
    "    banknifty['Date'] = pd.to_datetime(banknifty['Date'],format='mixed',dayfirst=True)\n",
    "    banknifty['Temp'] = banknifty['Ticker'].str.replace('BANKNIFTY','').str.replace('.NFO','').str[:-2]\n",
    "    banknifty['Length_Of_Temp'] = np.where(banknifty['Temp'].str.len()==12,12,banknifty['Temp'].str.len())\n",
    "    banknifty['Ticker_Expiry_Date'] = pd.to_datetime(banknifty['Temp'].str[:7],format='mixed',dayfirst=True)\n",
    "    banknifty['Exp_year'] = banknifty['Ticker_Expiry_Date'].dt.year\n",
    "    banknifty['Exp_month'] = banknifty['Ticker_Expiry_Date'].dt.month\n",
    "    banknifty = banknifty[banknifty['Ticker_Expiry_Date']>=banknifty['Date']].reset_index(drop=True)                             ## filtering out wrong ticker dates\n",
    "    banknifty['DayOfWeek'] = banknifty['Date'].dt.isocalendar().day\n",
    "    banknifty['ExpiryDayOfWeek'] = banknifty['Ticker_Expiry_Date'].dt.isocalendar().day\n",
    "    banknifty['Current_Week_number'] = banknifty['Date'].dt.isocalendar().week\n",
    "    banknifty['Expiry_Week_number_check'] = banknifty['Ticker_Expiry_Date'].dt.isocalendar().week\n",
    "    # banknifty.to_csv(r'C:\\\\users\\\\admin\\\\desktop\\\\banknifty1.csv',index=False)\n",
    "    banknifty['Expiry_Week_number'] = np.where(banknifty['ExpiryDayOfWeek']<=3,banknifty['Ticker_Expiry_Date'].dt.isocalendar().week-1,banknifty['Ticker_Expiry_Date'].dt.isocalendar().week)\n",
    "    banknifty['Expiry_Week_number'] = np.where((banknifty['DayOfWeek']<=3) & (banknifty['ExpiryDayOfWeek']<=3),banknifty['Expiry_Week_number']+1,banknifty['Expiry_Week_number'])\n",
    "    banknifty['Week_Diff'] = banknifty['Expiry_Week_number'] - banknifty['Current_Week_number']\n",
    "    banknifty[\"Week_Diff\"] = banknifty['Week_Diff'].replace(np.nan,10000)\n",
    "    return banknifty\n",
    "\n",
    "def banknifty_weekly():\n",
    "    ## REMOVING ALREADY STORED FILES\n",
    "    weekly_files = os.listdir(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Weekly')\n",
    "    for files in weekly_files:\n",
    "        os.remove(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Weekly\\\\'+files)\n",
    "    \n",
    "    banknifty = banknifty_data()\n",
    "    weekly1 = banknifty[banknifty['ExpiryDayOfWeek']<=3]\n",
    "    weekly2 = banknifty[banknifty['ExpiryDayOfWeek']==4]\n",
    "    agb = weekly1.groupby([\"Week_Diff\"])\n",
    "    unique_val_list_a = list(weekly1[\"Week_Diff\"].unique())\n",
    "    unique_val_list_a = sorted([a for a in unique_val_list_a if a>=0])[0:12]\n",
    "    for i in sorted(unique_val_list_a):\n",
    "        if i <= 14:\n",
    "            print(f'Week{i+1}')\n",
    "            temp_df = agb.get_group(i)\n",
    "            file = np.where(i==0,'I',np.where(i==1,'II',np.where(i==2,'III',np.where(i==3,'IV',np.where(i==4,'V',np.where(i==5,'VI',np.where(i==6,'VII',np.where(i==7,'VIII',np.where(i==8,'IX',np.where(i==9,'X',np.where(i==10,'XI',np.where(i==11,'XII',np.where(i==12,'XIII',np.where(i==13,'XIV',''))))))))))))))\n",
    "            temp_df['Symbol'] = 'BANKNIFTY' + 'WEEKLY-' + str(file) + temp_df['Temp'].str[-5:].astype(int).astype(str) + temp_df['Ticker'].str[-2:]\n",
    "            temp_df['Ticker'] = temp_df['Symbol']\n",
    "            temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "            temp_df = temp_df.drop_duplicates()\n",
    "            temp_df.to_csv(fr'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Weekly\\\\BANKNIFTY-{file}.csv',index=False)\n",
    "    print(\"\\n\")\n",
    "    agb = weekly2.groupby([\"Week_Diff\"])\n",
    "    unique_val_list_a = list(weekly2[\"Week_Diff\"].unique())\n",
    "    unique_val_list_a = sorted([a for a in unique_val_list_a if a>=0])[0:12]\n",
    "    for i in sorted(unique_val_list_a):\n",
    "        if i <= 14:\n",
    "            print(f\"Week{i+1}\")\n",
    "            temp_df = agb.get_group(i)\n",
    "            file = np.where(i==0,'I',np.where(i==1,'II',np.where(i==2,'III',np.where(i==3,'IV',np.where(i==4,'V',np.where(i==5,'VI',np.where(i==6,'VII',np.where(i==7,'VIII',np.where(i==8,'IX',np.where(i==9,'X',np.where(i==10,'XI',np.where(i==11,'XII',np.where(i==12,'XIII',np.where(i==13,'XIV',''))))))))))))))\n",
    "            temp_df['Symbol'] = 'BANKNIFTY' + 'WEEKLY-' + str(file) + temp_df['Temp'].str[-5:].astype(int).astype(str) + temp_df['Ticker'].str[-2:]\n",
    "            temp_df['Ticker'] = temp_df['Symbol']\n",
    "            temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "            temp_df = temp_df.drop_duplicates()\n",
    "            temp_df.to_csv(fr'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Weekly\\\\BANKNIFTY-{file}.csv',index=False)\n",
    "    print(\"Weekly Contracts Created!\")\n",
    "\n",
    "def banknifty_monthly():\n",
    "    ## REMOVING ALREADY STORED FILES\n",
    "    weekly_files = os.listdir(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Monthly')\n",
    "    for files in weekly_files:\n",
    "        os.remove(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Monthly\\\\'+files)\n",
    "    \n",
    "    banknifty = banknifty_data()\n",
    "    i = 0\n",
    "    monthly_df = pd.DataFrame()\n",
    "    for name,group in tqdm(banknifty.groupby(['Exp_year','Exp_month'])):\n",
    "        monthly_df = pd.concat([monthly_df,group[group['Ticker_Expiry_Date'] == group['Ticker_Expiry_Date'].max()]],ignore_index=True)\n",
    "        if i <3 :\n",
    "            print(f\"Monthly{i+1}\")\n",
    "            monthly = group[group['Ticker_Expiry_Date'] == group['Ticker_Expiry_Date'].max()]\n",
    "            # display(monthly)\n",
    "            file = np.where(i==0,'I',np.where(i==1,'II',np.where(i==2,'III','')))\n",
    "            monthly['Symbol'] = 'BANKNIFTY' + 'MONTHLY-' + str(file) + monthly['Temp'].str[-5:].astype(int).astype(str) + monthly['Ticker'].str[-2:]\n",
    "            monthly['Ticker'] = monthly['Symbol']\n",
    "            monthly = monthly.drop(monthly.columns[9:],axis=1)\n",
    "            monthly.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Monthly\\\\Banknifty-{file}.csv',index=False)\n",
    "            i+=1\n",
    "    print(\"Monthly Contracts Created\")\n",
    "    return monthly_df\n",
    "\n",
    "def banknifty_quarterly():\n",
    "    ## REMOVING ALREADY STORED FILES\n",
    "    weekly_files = os.listdir(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Quarterly')\n",
    "    for files in weekly_files:\n",
    "        os.remove(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Quarterly\\\\'+files)\n",
    "        \n",
    "    quarterly = banknifty_monthly()\n",
    "    quarterly = quarterly[(quarterly['Exp_month'] == 3) | (quarterly['Exp_month'] == 6) | (quarterly['Exp_month'] == 9) | (quarterly['Exp_month'] == 12)].reset_index(drop=True)\n",
    "    quarter = 0\n",
    "    quarter_check = 3\n",
    "    quarterly_final_df = pd.DataFrame()\n",
    "    for name, group in tqdm(quarterly.groupby(['Exp_year','Exp_month'])):\n",
    "        quarterly_final_df = pd.concat([quarterly_final_df,group],ignore_index=True)\n",
    "        # print(name)\n",
    "        if quarter == 0:\n",
    "            print(f\"Quarter{quarter+1}\")\n",
    "            quarterly_df = group[group['Ticker_Expiry_Date'] == group['Ticker_Expiry_Date'].max()]\n",
    "            # display(quarterly_df)\n",
    "            file = np.where(quarter==0,'I',np.where(quarter==1,'II',np.where(quarter==2,'III',np.where(quarter==3,'IV',''))))\n",
    "            quarterly_df['Symbol'] = 'BANKNIFTY' + 'QUARTERLY-' + str(file) + quarterly_df['Temp'].str[-5:].astype(int).astype(str) + quarterly_df['Ticker'].str[-2:]\n",
    "            quarterly_df['Ticker'] = quarterly_df['Symbol']\n",
    "            quarterly_df = quarterly_df.drop(quarterly_df.columns[9:],axis=1)\n",
    "            quarterly_df.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Quarterly\\\\Banknifty-{file}.csv',index=False)\n",
    "            quarter_month_counter = group.iloc[0]['Exp_month']\n",
    "            quarter_year_counter = group.iloc[0]['Exp_year']\n",
    "            quarter +=1\n",
    "            \n",
    "        else:\n",
    "            if quarter_month_counter == 12:\n",
    "                quarter_month_counter = 0\n",
    "            if group.iloc[0]['Exp_month'] - quarter_month_counter == quarter_check:\n",
    "                print(f\"Quarter{quarter+1}\")\n",
    "                quarterly_df = group[group['Ticker_Expiry_Date'] == group['Ticker_Expiry_Date'].max()]\n",
    "                # display(quarterly_df)\n",
    "                file = np.where(quarter==0,'I',np.where(quarter==1,'II',np.where(quarter==2,'III',np.where(quarter==3,'IV',''))))\n",
    "                quarterly_df['Symbol'] = 'BANKNIFTY' + 'QUARTERLY-' + str(file) + quarterly_df['Temp'].str[-5:].astype(int).astype(str) + quarterly_df['Ticker'].str[-2:]\n",
    "                quarterly_df['Ticker'] = quarterly_df['Symbol']\n",
    "                quarterly_df = quarterly_df.drop(quarterly_df.columns[9:],axis=1)\n",
    "                quarterly_df.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Quarterly\\\\Banknifty-{file}.csv',index=False)\n",
    "                quarter_month_counter = group.iloc[0]['Exp_month']\n",
    "                quarter_year_counter = group.iloc[0]['Exp_year']\n",
    "                quarter +=1\n",
    "            else:\n",
    "                while(quarter<4):\n",
    "                    quarter +=1\n",
    "                    quarter_check+=3\n",
    "                    if group.iloc[0]['Exp_month'] - quarter_month_counter == quarter_check:\n",
    "                        print(f\"Quarter{quarter+1}\")\n",
    "                        quarterly_df = group[group['Ticker_Expiry_Date'] == group['Ticker_Expiry_Date'].max()]\n",
    "                        # display(quarterly_df)\n",
    "                        file = np.where(quarter==0,'I',np.where(quarter==1,'II',np.where(quarter==2,'III',np.where(quarter==3,'IV',''))))\n",
    "                        quarterly_df['Symbol'] = 'BANKNIFTY' + 'QUARTERLY-' + str(file) + quarterly_df['Temp'].str[-5:].astype(int).astype(str) + quarterly_df['Ticker'].str[-2:]\n",
    "                        quarterly_df['Ticker'] = quarterly_df['Symbol']\n",
    "                        quarterly_df = quarterly_df.drop(quarterly_df.columns[9:],axis=1)\n",
    "                        quarterly_df.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Quarterly\\\\Banknifty-{file}.csv',index=False)\n",
    "                        quarter_month_counter = group.iloc[0]['Exp_month']\n",
    "                        quarter_year_counter = group.iloc[0]['Exp_year']\n",
    "                        quarter +=1\n",
    "    print(\"Quarterly Contracts Created\")\n",
    "    return quarterly_final_df\n",
    "\n",
    "def banknifty_halfyearly():\n",
    "    ## REMOVING ALREADY STORED FILES\n",
    "    weekly_files = os.listdir(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Half_Yearly')\n",
    "    for files in weekly_files:\n",
    "        os.remove(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Half_Yearly\\\\'+files)\n",
    "        \n",
    "    half_yearly = banknifty_quarterly()\n",
    "    half_yearly = half_yearly[(half_yearly['Exp_month'] == 6) | (half_yearly['Exp_month'] == 12)].reset_index(drop=True)\n",
    "    half_year = 0\n",
    "    halfyear_check = 6\n",
    "    for name, group in tqdm(half_yearly.groupby(['Exp_year','Exp_month'])):\n",
    "        # print(name)\n",
    "        \n",
    "        if half_year == 0:\n",
    "            print(f\"HalfYearly{half_year+1}\")\n",
    "            half_yearly_df = group[group['Ticker_Expiry_Date'] == group['Ticker_Expiry_Date'].max()]\n",
    "            # display(half_yearly_df)\n",
    "            half_yearly_df = half_yearly_df.drop(half_yearly_df.columns[9:],axis=1)\n",
    "            half_yearly_df.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Half_Yearly\\\\Banknifty-{half_year+1}.csv',index=False)\n",
    "            halfyear_month_counter = group.iloc[0]['Exp_month']\n",
    "            halfyear_year_counter = group.iloc[0]['Exp_year']\n",
    "            half_year +=1\n",
    "        else:\n",
    "            if halfyear_month_counter == 12:\n",
    "                halfyear_month_counter = 0\n",
    "            if group.iloc[0]['Exp_month'] - halfyear_month_counter == halfyear_check:\n",
    "                print(f\"HalfYearly{half_year+1}\")\n",
    "                half_yearly_df = group[group['Ticker_Expiry_Date'] == group['Ticker_Expiry_Date'].max()]\n",
    "                # display(half_yearly_df)\n",
    "                half_yearly_df = half_yearly_df.drop(half_yearly_df.columns[9:],axis=1)\n",
    "                half_yearly_df.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Half_Yearly\\\\Banknifty-{half_year+1}.csv',index=False)\n",
    "                halfyear_month_counter = group.iloc[0]['Exp_month']\n",
    "                halfyear_year_counter = group.iloc[0]['Exp_year']\n",
    "                half_year +=1\n",
    "            else:\n",
    "                while(half_year<10):\n",
    "                    half_year +=1\n",
    "                    halfyear_check+=6\n",
    "                    if group.iloc[0]['Exp_month'] - halfyear_month_counter == halfyear_check:\n",
    "                        print(f\"HalfYearly{half_year+1}\")\n",
    "                        half_yearly_df = group[group['Ticker_Expiry_Date'] == group['Ticker_Expiry_Date'].max()]\n",
    "                        # display(half_yearly_df)\n",
    "                        half_yearly_df = half_yearly_df.drop(half_yearly_df.columns[9:],axis=1)\n",
    "                        half_yearly_df.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Half_Yearly\\\\Banknifty-{half_year+1}.csv',index=False)\n",
    "                        halfyear_month_counter = group.iloc[0]['Exp_month']\n",
    "                        halfyear_year_counter = group.iloc[0]['Exp_year']\n",
    "                        halfyear_check=0\n",
    "                        break\n",
    "    print(\"Half Yearly contracts created!\")\n",
    "\n",
    "def banknifty_yearly():\n",
    "    ## REMOVING ALREADY STORED FILES\n",
    "    weekly_files = os.listdir(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Yearly')\n",
    "    for files in weekly_files:\n",
    "        os.remove(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Yearly\\\\'+files)\n",
    "        \n",
    "    yearly_file = 1\n",
    "    half_yearly_file1 = 1\n",
    "    half_yearly_file2 = 2\n",
    "    for i in range(5):\n",
    "        # print(i,yearly_file,half_yearly_file1,half_yearly_file2)\n",
    "        if os.path.exists(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Half_Yearly\\\\Banknifty-{half_yearly_file1}.csv'):\n",
    "            df1 = pd.read_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Half_Yearly\\\\Banknifty-{half_yearly_file1}.csv')\n",
    "        else:\n",
    "            df1 = pd.DataFrame()\n",
    "        if os.path.exists(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Half_Yearly\\\\Banknifty-{half_yearly_file2}.csv'):\n",
    "            df2 = pd.read_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Half_Yearly\\\\Banknifty-{half_yearly_file2}.csv')\n",
    "        else:\n",
    "            df2 = pd.DataFrame()\n",
    "        if df1.empty and df2.empty == True:\n",
    "            print(f\"No Contracts for HalfYearly {half_yearly_file1} {half_yearly_file2}\")\n",
    "        else:\n",
    "            final_df = pd.DataFrame()\n",
    "            if not df1.empty:\n",
    "                df1['Temp'] = df1['Ticker'].str.replace('BANKNIFTY','').str.replace('.NFO','').str[:-2]\n",
    "                df1['Ticker_Expiry_Date'] = pd.to_datetime(df1['Temp'].str[:7],format='mixed',dayfirst=True)\n",
    "                df1['Exp_month'] = df1['Ticker_Expiry_Date'].dt.month\n",
    "                df1 = df1[df1['Exp_month']==12].reset_index(drop=True)\n",
    "            if not df2.empty:\n",
    "                df2['Temp'] = df2['Ticker'].str.replace('BANKNIFTY','').str.replace('.NFO','').str[:-2]\n",
    "                df2['Ticker_Expiry_Date'] = pd.to_datetime(df2['Temp'].str[:7],format='mixed',dayfirst=True)\n",
    "                df2['Exp_month'] = df2['Ticker_Expiry_Date'].dt.month\n",
    "                df2 = df2[df2['Exp_month']==12].reset_index(drop=True)\n",
    "            final_df = pd.concat([df1,df2],ignore_index=True)\n",
    "            \n",
    "            if not df1.empty:\n",
    "                file1 = np.where(half_yearly_file1==1,'I',np.where(half_yearly_file1==3,'III',np.where(half_yearly_file1==5,'V',np.where(half_yearly_file1==7,'VII',np.where(half_yearly_file1==9,'IX','')))))\n",
    "                df1['Symbol'] = 'BANKNIFTY-' + str(file1) + df1['Temp'].str[-5:].astype(int).astype(str) + df1['Ticker'].str[-2:]\n",
    "                df1['Ticker'] = df1['Symbol']\n",
    "                df1 = df1.drop(df1.columns[9:],axis=1)\n",
    "                df1.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Half_Yearly\\\\Banknifty-{file1}.csv',index=False)\n",
    "            \n",
    "            if not df2.empty:\n",
    "                file2 = np.where(half_yearly_file2==2,'II',np.where(half_yearly_file2==4,'IV',np.where(half_yearly_file2==6,'VI',np.where(half_yearly_file2==8,'VIII',np.where(half_yearly_file2==10,'X','')))))\n",
    "                df2['Symbol'] = 'BANKNIFTY-' + str(file2) + df2['Temp'].str[-5:].astype(int).astype(str) + df2['Ticker'].str[-2:]\n",
    "                df2['Ticker'] = df2['Symbol']\n",
    "                df2 = df2.drop(df2.columns[9:],axis=1)\n",
    "                df2.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Half_Yearly\\\\Banknifty-{file2}.csv',index=False)\n",
    "                \n",
    "            file = np.where(i==0,'I',np.where(i==1,'II',np.where(i==2,'III',np.where(i==3,'IV',np.where(i==4,'V','')))))\n",
    "            final_df['Symbol'] = 'BANKNIFTY-' + str(file) + final_df['Temp'].str[-5:] + final_df['Ticker'].str[-2:]\n",
    "            final_df['Ticker'] = final_df['Symbol']\n",
    "            final_df = final_df.drop(final_df.columns[9:],axis=1)\n",
    "            final_df.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\BankNifty\\\\Yearly\\\\BankNifty-{file}.csv',index=False)\n",
    "        yearly_file+=1\n",
    "        half_yearly_file1+=2\n",
    "        half_yearly_file2+=2\n",
    "    print(\"Yearly Contracts Created\")\n",
    "\n",
    "def nifty_data():\n",
    "    spark = SparkSession.builder.config(\"spark.jars\", \"C:\\\\Users\\\\admin\\\\Downloads\\\\postgresql-42.5.1.jar\") \\\n",
    "    .master(\"local\").appName(\"PySpark_Postgres_test\").getOrCreate()\n",
    "    \n",
    "    df = spark.read.format(\"jdbc\").option(\"url\", \"jdbc:postgresql://swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com/RawDataBase\").option(\"user\",\"postgres\").option(\"password\",\"swancap123\")\\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\").option(\"dbtable\", tablename)\\\n",
    "        .option(\"user\", \"postgres\").option(\"password\", \"swancap123\").load()\n",
    "\n",
    "    ## GETTING ONLY TIME IN TIME COLUMN\n",
    "    q = df.withColumn('time',date_format('time', 'HH:mm:ss'))\n",
    "     = q.filter(q.ticker.contains('NIFTY') & ((q.ticker.endswith('E.NFO'))| (q.ticker.endswith('E'))))\n",
    "    nifty = nifty.withColumn('ticker_check',substring('ticker',1,5))\n",
    "    nifty = nifty.filter(nifty.ticker_check.contains('NIFTY'))\n",
    "    ## REPLACING .NFO IN ticker\n",
    "    nifty = nifty.withColumn('ticker',regexp_replace('ticker','.NFO',''))\n",
    "    nifty = nifty.drop(col('ticker_check'))\n",
    "\n",
    "    ## CONVERTING PYSPARK DATAFRAME TO PANDAS DATAFRAME\n",
    "    nifty = nifty.toPandas()\n",
    "    nifty = nifty.rename(columns={'ticker':'Ticker','date':'Date','time':'Time','open':'Open','high':'High','low':'Low','close':'Close','volume':'Volume'})\n",
    "    \n",
    "    # df = pd.read_csv(r\"C:\\\\users\\\\admin\\\\desktop\\\\NSEFO_06092023.csv\")\n",
    "    # nifty = df[(df['Ticker'].str.startswith('NIFTY') & (df['Ticker'].str.endswith('E.NFO')))].reset_index(drop=True)\n",
    "    # nifty['Ticker'] = nifty['Ticker'].str.replace('.NFO','')\n",
    "    \n",
    "    nifty = nifty[(nifty['Time']>='09:15:59') & (nifty['Time']<='15:29:59')].reset_index(drop=True)\n",
    "    nifty['Date'] = pd.to_datetime(nifty['Date'],format='mixed',dayfirst=True)\n",
    "    nifty['Temp'] = nifty['Ticker'].str.replace('NIFTY','').str.replace('.NFO','').str[:-2]\n",
    "    nifty['Length_Of_Temp'] = np.where(nifty['Temp'].str.len()==12,12,nifty['Temp'].str.len())\n",
    "    nifty['Ticker_Expiry_Date'] = pd.to_datetime(nifty['Temp'].str[:7],format='mixed',dayfirst=True)\n",
    "    nifty['Exp_year'] = nifty['Ticker_Expiry_Date'].dt.year\n",
    "    nifty['Exp_month'] = nifty['Ticker_Expiry_Date'].dt.month\n",
    "    nifty = nifty[nifty['Ticker_Expiry_Date']>=nifty['Date']].reset_index(drop=True)                             ## filtering out wrong ticker dates\n",
    "    nifty['DayOfWeek'] = nifty['Date'].dt.isocalendar().day\n",
    "    nifty['ExpiryDayOfWeek'] = nifty['Ticker_Expiry_Date'].dt.isocalendar().day\n",
    "    nifty['Current_Week_number'] = nifty['Date'].dt.isocalendar().week\n",
    "    nifty['Expiry_Week_number_check'] = nifty['Ticker_Expiry_Date'].dt.isocalendar().week\n",
    "    # banknifty.to_csv(r'C:\\\\users\\\\admin\\\\desktop\\\\banknifty1.csv',index=False)\n",
    "    nifty['Expiry_Week_number'] = np.where(nifty['ExpiryDayOfWeek']<=4,nifty['Ticker_Expiry_Date'].dt.isocalendar().week-1,nifty['Ticker_Expiry_Date'].dt.isocalendar().week)\n",
    "    nifty['Expiry_Week_number'] = np.where((nifty['DayOfWeek']<=4) & (nifty['ExpiryDayOfWeek']<=4),nifty['Expiry_Week_number']+1,nifty['Expiry_Week_number'])\n",
    "    nifty['Week_Diff'] = nifty['Expiry_Week_number'] - nifty['Current_Week_number']\n",
    "    nifty[\"Week_Diff\"] = nifty['Week_Diff'].replace(np.nan,10000)\n",
    "    return nifty\n",
    "\n",
    "def nifty_weekly():\n",
    "    ## REMOVING ALREADY STORED FILES\n",
    "    weekly_files = os.listdir(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Weekly')\n",
    "    for files in weekly_files:\n",
    "        os.remove(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Weekly\\\\'+files)\n",
    "        \n",
    "    nifty = nifty_data()\n",
    "    weekly1 = nifty[nifty['ExpiryDayOfWeek']<=4].reset_index(drop=True)\n",
    "    agb = weekly1.groupby([\"Week_Diff\"])\n",
    "    unique_val_list_a = list(weekly1[\"Week_Diff\"].unique())\n",
    "    unique_val_list_a = sorted([a for a in unique_val_list_a if a>=0])[0:12]\n",
    "    for i in sorted(unique_val_list_a):\n",
    "        if i <= 14:\n",
    "            print(f'Week{i+1}')\n",
    "            temp_df = agb.get_group(i)\n",
    "            file = np.where(i==0,'I',np.where(i==1,'II',np.where(i==2,'III',np.where(i==3,'IV',np.where(i==4,'V',np.where(i==5,'VI',np.where(i==6,'VII',np.where(i==7,'VIII',np.where(i==8,'IX',np.where(i==9,'X',np.where(i==10,'XI',np.where(i==11,'XII',np.where(i==12,'XIII',np.where(i==13,'XIV',''))))))))))))))\n",
    "            temp_df['Symbol'] = 'NIFTY' + 'WEEKLY-' + str(file) + temp_df['Temp'].str[-5:].astype(int).astype(str) + temp_df['Ticker'].str[-2:]\n",
    "            temp_df['Ticker'] = temp_df['Symbol']\n",
    "            temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "            temp_df = temp_df.drop_duplicates()\n",
    "            temp_df.to_csv(fr'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Weekly\\\\NIFTY-{file}.csv',index=False)\n",
    "    print(\"Weekly Contracts Created\")\n",
    "\n",
    "def nifty_monthly():\n",
    "    ## REMOVING ALREADY STORED FILES\n",
    "    weekly_files = os.listdir(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Monthly')\n",
    "    for files in weekly_files:\n",
    "        os.remove(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Monthly\\\\'+files)\n",
    "        \n",
    "    nifty = nifty_data()\n",
    "    i = 0\n",
    "    monthly_df = pd.DataFrame()\n",
    "    for name,group in tqdm(nifty.groupby(['Exp_year','Exp_month'])):\n",
    "        monthly_df = pd.concat([monthly_df,group[group['Ticker_Expiry_Date'] == group['Ticker_Expiry_Date'].max()]],ignore_index=True)\n",
    "        if i <3 :\n",
    "            print(f\"Monthly{i+1}\")\n",
    "            monthly = group[group['Ticker_Expiry_Date'] == group['Ticker_Expiry_Date'].max()]\n",
    "            # display(monthly)\n",
    "            file = np.where(i==0,'I',np.where(i==1,'II',np.where(i==2,'III','')))\n",
    "            monthly['Symbol'] = 'NIFTY' + 'MONTHLY-' + str(file) + monthly['Temp'].str[-5:].astype(int).astype(str) + monthly['Ticker'].str[-2:]\n",
    "            monthly['Ticker'] = monthly['Symbol']\n",
    "            monthly = monthly.drop(monthly.columns[9:],axis=1)\n",
    "            monthly.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Monthly\\\\NIFTY-{file}.csv',index=False)\n",
    "            i+=1\n",
    "    print(\"Monthly Contracts Created\")\n",
    "    return monthly_df\n",
    "\n",
    "def nifty_quarterly():\n",
    "    ## REMOVING ALREADY STORED FILES\n",
    "    weekly_files = os.listdir(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Quarterly')\n",
    "    for files in weekly_files:\n",
    "        os.remove(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Quarterly\\\\'+files)\n",
    "        \n",
    "    quarterly = nifty_monthly()\n",
    "    quarterly = quarterly[(quarterly['Exp_month'] == 3) | (quarterly['Exp_month'] == 6) | (quarterly['Exp_month'] == 9) | (quarterly['Exp_month'] == 12)].reset_index(drop=True)\n",
    "    quarter = 0\n",
    "    quarter_check = 3\n",
    "    quarterly_final_df = pd.DataFrame()\n",
    "    for name, group in tqdm(quarterly.groupby(['Exp_year','Exp_month'])):\n",
    "        quarterly_final_df = pd.concat([quarterly_final_df,group],ignore_index=True)\n",
    "        # print(name)\n",
    "        if quarter == 0:\n",
    "            print(f\"Quarter{quarter+1}\")\n",
    "            file = np.where(quarter==0,'I',np.where(quarter==1,'II',np.where(quarter==2,'III',np.where(quarter==3,'IV',''))))\n",
    "            quarterly_df = group[group['Ticker_Expiry_Date'] == group['Ticker_Expiry_Date'].max()]\n",
    "            # display(quarterly_df)\n",
    "            quarterly_df['Symbol'] = 'NIFTY' + 'QUARTERLY-' + str(file) + quarterly_df['Temp'].str[-5:].astype(int).astype(str) + quarterly_df['Ticker'].str[-2:]\n",
    "            quarterly_df['Ticker'] = quarterly_df['Symbol']\n",
    "            quarterly_df = quarterly_df.drop(quarterly_df.columns[9:],axis=1)\n",
    "            quarterly_df.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Quarterly\\\\NIFTY-{file}.csv',index=False)\n",
    "            quarter_month_counter = group.iloc[0]['Exp_month']\n",
    "            quarter_year_counter = group.iloc[0]['Exp_year']\n",
    "            quarter +=1\n",
    "            \n",
    "        else:\n",
    "            if quarter_month_counter == 12:\n",
    "                quarter_month_counter = 0\n",
    "            if group.iloc[0]['Exp_month'] - quarter_month_counter == quarter_check:\n",
    "                print(f\"Quarter{quarter+1}\")\n",
    "                file = np.where(quarter==0,'I',np.where(quarter==1,'II',np.where(quarter==2,'III',np.where(quarter==3,'IV',''))))\n",
    "                quarterly_df = group[group['Ticker_Expiry_Date'] == group['Ticker_Expiry_Date'].max()]\n",
    "                quarterly_df['Symbol'] = 'NIFTY' + 'QUARTERLY-' + str(file) + quarterly_df['Temp'].str[-5:].astype(int).astype(str) + quarterly_df['Ticker'].str[-2:]\n",
    "                quarterly_df['Ticker'] = quarterly_df['Symbol']\n",
    "                # display(quarterly_df)\n",
    "                quarterly_df = quarterly_df.drop(quarterly_df.columns[9:],axis=1)\n",
    "                quarterly_df.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Quarterly\\\\NIFTY-{file}.csv',index=False)\n",
    "                quarter_month_counter = group.iloc[0]['Exp_month']\n",
    "                quarter_year_counter = group.iloc[0]['Exp_year']\n",
    "                quarter +=1\n",
    "            else:\n",
    "                while(quarter<4):\n",
    "                    quarter +=1\n",
    "                    quarter_check+=3\n",
    "                    if group.iloc[0]['Exp_month'] - quarter_month_counter == quarter_check:\n",
    "                        print(f\"Quarter{quarter+1}\")\n",
    "                        file = np.where(quarter==0,'I',np.where(quarter==1,'II',np.where(quarter==2,'III',np.where(quarter==3,'IV',''))))\n",
    "                        quarterly_df = group[group['Ticker_Expiry_Date'] == group['Ticker_Expiry_Date'].max()]\n",
    "                        quarterly_df['Symbol'] = 'NIFTY' + 'QUARTERLY-' + str(file) + quarterly_df['Temp'].str[-5:].astype(int).astype(str) + quarterly_df['Ticker'].str[-2:]\n",
    "                        quarterly_df['Ticker'] = quarterly_df['Symbol']\n",
    "                        # display(quarterly_df)\n",
    "                        quarterly_df = quarterly_df.drop(quarterly_df.columns[9:],axis=1)\n",
    "                        quarterly_df.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Quarterly\\\\NIFTY-{file}.csv',index=False)\n",
    "                        quarter_month_counter = group.iloc[0]['Exp_month']\n",
    "                        quarter_year_counter = group.iloc[0]['Exp_year']\n",
    "                        quarter +=1\n",
    "    print(\"Quarterly Contracts Created\")\n",
    "    return quarterly_final_df\n",
    "\n",
    "def nifty_halfyearly():\n",
    "    ## REMOVING ALREADY STORED FILES\n",
    "    weekly_files = os.listdir(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Half_Yearly')\n",
    "    for files in weekly_files:\n",
    "        os.remove(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Half_Yearly\\\\'+files)\n",
    "        \n",
    "    half_yearly = nifty_quarterly()\n",
    "    half_yearly = half_yearly[(half_yearly['Exp_month'] == 6) | (half_yearly['Exp_month'] == 12)].reset_index(drop=True)\n",
    "    half_year = 0\n",
    "    halfyear_check = 6\n",
    "    for name, group in tqdm(half_yearly.groupby(['Exp_year','Exp_month'])):\n",
    "        # print(name)\n",
    "        if half_year == 0:\n",
    "            print(f\"HalfYearly{half_year+1}\")\n",
    "            half_yearly_df = group[group['Ticker_Expiry_Date'] == group['Ticker_Expiry_Date'].max()]\n",
    "            # file = np.where(half_year==0,'I',np.where(half_year==1,'II',np.where(half_year==2,'III',np.where(half_year==3,'IV',np.where(half_year==4,'V',np.where(half_year==5,'VI',np.where(half_year==6,'VII',np.where(half_year==7,'VIII',np.where(half_year==8,'IX',np.where(half_year==9,'X',''))))))))))\n",
    "            # half_yearly_df['Symbol'] = 'NIFTY-' + str(file) + half_yearly_df['Temp'].str[-5:].astype(int).astype(str) + half_yearly_df['Ticker'].str[-2:]\n",
    "            # half_yearly_df['Ticker'] = half_yearly_df['Symbol']\n",
    "            # display(half_yearly_df)\n",
    "            half_yearly_df = half_yearly_df.drop(half_yearly_df.columns[9:],axis=1)\n",
    "            half_yearly_df.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Half_Yearly\\\\Nifty-{half_year+1}.csv',index=False)\n",
    "            halfyear_month_counter = group.iloc[0]['Exp_month']\n",
    "            halfyear_year_counter = group.iloc[0]['Exp_year']\n",
    "            half_year +=1\n",
    "        else:\n",
    "            if halfyear_month_counter == 12:\n",
    "                halfyear_month_counter = 0\n",
    "            if group.iloc[0]['Exp_month'] - halfyear_month_counter == halfyear_check:\n",
    "                print(f\"HalfYearly{half_year+1}\")\n",
    "                half_yearly_df = group[group['Ticker_Expiry_Date'] == group['Ticker_Expiry_Date'].max()]\n",
    "                # file = np.where(half_year==0,'I',np.where(half_year==1,'II',np.where(half_year==2,'III',np.where(half_year==3,'IV',np.where(half_year==4,'V',np.where(half_year==5,'VI',np.where(half_year==6,'VII',np.where(half_year==7,'VIII',np.where(half_year==8,'IX',np.where(half_year==9,'X',''))))))))))\n",
    "                # half_yearly_df['Symbol'] = 'NIFTY-' + str(file) + half_yearly_df['Temp'].str[-5:].astype(int).astype(str) + half_yearly_df['Ticker'].str[-2:]\n",
    "                # half_yearly_df['Ticker'] = half_yearly_df['Symbol']\n",
    "                # display(half_yearly_df)\n",
    "                half_yearly_df = half_yearly_df.drop(half_yearly_df.columns[9:],axis=1)\n",
    "                half_yearly_df.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Half_Yearly\\\\Nifty-{half_year+1}.csv',index=False)\n",
    "                halfyear_month_counter = group.iloc[0]['Exp_month']\n",
    "                halfyear_year_counter = group.iloc[0]['Exp_year']\n",
    "                half_year +=1\n",
    "            else:\n",
    "                while(half_year<10):\n",
    "                    if group.iloc[0]['Exp_year'] - halfyear_year_counter == 2:\n",
    "                        half_year += 2\n",
    "                    elif group.iloc[0]['Exp_year'] - halfyear_year_counter == 3:\n",
    "                        half_year += 3\n",
    "                    else:\n",
    "                        half_year +=1\n",
    "                    halfyear_check+=6\n",
    "                    if group.iloc[0]['Exp_month'] - halfyear_month_counter == halfyear_check:\n",
    "                        print(f\"HalfYearly{half_year+1}\")\n",
    "                        half_yearly_df = group[group['Ticker_Expiry_Date'] == group['Ticker_Expiry_Date'].max()]\n",
    "                        # file = np.where(half_year==0,'I',np.where(half_year==1,'II',np.where(half_year==2,'III',np.where(half_year==3,'IV',np.where(half_year==4,'V',np.where(half_year==5,'VI',np.where(half_year==6,'VII',np.where(half_year==7,'VIII',np.where(half_year==8,'IX',np.where(half_year==9,'X',''))))))))))\n",
    "                        # half_yearly_df['Symbol'] = 'NIFTY-' + str(file) + half_yearly_df['Temp'].str[-5:].astype(int).astype(str) + half_yearly_df['Ticker'].str[-2:]\n",
    "                        # half_yearly_df['Ticker'] = half_yearly_df['Symbol']\n",
    "                        # display(half_yearly_df)\n",
    "                        half_yearly_df = half_yearly_df.drop(half_yearly_df.columns[9:],axis=1)\n",
    "                        half_yearly_df.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Half_Yearly\\\\Nifty-{half_year+1}.csv',index=False)\n",
    "                        halfyear_month_counter = group.iloc[0]['Exp_month']\n",
    "                        halfyear_year_counter = group.iloc[0]['Exp_year']\n",
    "                        halfyear_check=0\n",
    "                        break\n",
    "    print(\"Half Yearly contracts created!\")\n",
    "\n",
    "def nifty_yearly():\n",
    "    ## REMOVING ALREADY STORED FILES\n",
    "    weekly_files = os.listdir(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Yearly')\n",
    "    for files in weekly_files:\n",
    "        os.remove(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Yearly\\\\'+files)\n",
    "        \n",
    "    yearly_file = 1\n",
    "    half_yearly_file1 = 1\n",
    "    half_yearly_file2 = 2\n",
    "    for i in range(5):\n",
    "        # print(i,yearly_file,half_yearly_file1,half_yearly_file2)\n",
    "        if os.path.exists(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Half_Yearly\\\\Nifty-{half_yearly_file1}.csv'):\n",
    "            df1 = pd.read_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Half_Yearly\\\\Nifty-{half_yearly_file1}.csv')\n",
    "        else:\n",
    "            df1 = pd.DataFrame()\n",
    "        if os.path.exists(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Half_Yearly\\\\Nifty-{half_yearly_file2}.csv'):\n",
    "            df2 = pd.read_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Half_Yearly\\\\Nifty-{half_yearly_file2}.csv')\n",
    "        else:\n",
    "            df2 = pd.DataFrame()\n",
    "        if df1.empty and df2.empty == True:\n",
    "            print(f\"No Contracts for HalfYearly {half_yearly_file1} {half_yearly_file2}\")\n",
    "        else:\n",
    "            final_df = pd.DataFrame()\n",
    "            if not df1.empty:\n",
    "                df1['Temp'] = df1['Ticker'].str.replace('NIFTY','').str.replace('.NFO','').str[:-2]\n",
    "                df1['Ticker_Expiry_Date'] = pd.to_datetime(df1['Temp'].str[:7],format='mixed',dayfirst=True)\n",
    "                df1['Exp_month'] = df1['Ticker_Expiry_Date'].dt.month\n",
    "                df1_new = df1[df1['Exp_month']==12].reset_index(drop=True)\n",
    "            if not df2.empty:\n",
    "                df2['Temp'] = df2['Ticker'].str.replace('NIFTY','').str.replace('.NFO','').str[:-2]\n",
    "                df2['Ticker_Expiry_Date'] = pd.to_datetime(df2['Temp'].str[:7],format='mixed',dayfirst=True)\n",
    "                df2['Exp_month'] = df2['Ticker_Expiry_Date'].dt.month\n",
    "                df2_new = df2[df2['Exp_month']==12].reset_index(drop=True)\n",
    "            final_df = pd.concat([df1_new,df2_new],ignore_index=True)\n",
    "            \n",
    "            if not df1.empty:\n",
    "                file1 = np.where(half_yearly_file1==1,'I',np.where(half_yearly_file1==3,'III',np.where(half_yearly_file1==5,'V',np.where(half_yearly_file1==7,'VII',np.where(half_yearly_file1==9,'IX','')))))\n",
    "                df1['Symbol'] = 'NIFTY-' + str(file1) + df1['Temp'].str[-5:].astype(int).astype(str) + df1['Ticker'].str[-2:]\n",
    "                df1['Ticker'] = df1['Symbol']\n",
    "                df1 = df1.drop(df1.columns[9:],axis=1)\n",
    "                df1.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Half_Yearly\\\\Nifty-{file1}.csv',index=False)\n",
    "\n",
    "            if not df2.empty:\n",
    "                file2 = np.where(half_yearly_file2==2,'II',np.where(half_yearly_file2==4,'IV',np.where(half_yearly_file2==6,'VI',np.where(half_yearly_file2==8,'VIII',np.where(half_yearly_file2==10,'X','')))))\n",
    "                df2['Symbol'] = 'NIFTY-' + str(file2) + df2['Temp'].str[-5:].astype(int).astype(str) + df2['Ticker'].str[-2:]\n",
    "                df2['Ticker'] = df2['Symbol']\n",
    "                df2 = df2.drop(df2.columns[9:],axis=1)\n",
    "                df2.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Half_Yearly\\\\Nifty-{file2}.csv',index=False)\n",
    "            \n",
    "            file = np.where(i==0,'I',np.where(i==1,'II',np.where(i==2,'III',np.where(i==3,'IV',np.where(i==4,'V','')))))\n",
    "            final_df['Symbol'] = 'NIFTY-' + str(file) + final_df['Temp'].str[-5:] + final_df['Ticker'].str[-2:]\n",
    "            final_df['Ticker'] = final_df['Symbol']\n",
    "            final_df = final_df.drop(final_df.columns[9:],axis=1)\n",
    "            final_df.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\Nifty\\\\Yearly\\\\Nifty-{file}.csv',index=False)\n",
    "        yearly_file+=1\n",
    "        half_yearly_file1+=2\n",
    "        half_yearly_file2+=2\n",
    "    print(\"Yearly Contracts Created\")\n",
    "\n",
    "def finnifty_data():\n",
    "    spark = SparkSession.builder.config(\"spark.jars\", \"C:\\\\Users\\\\admin\\\\Downloads\\\\postgresql-42.5.1.jar\") \\\n",
    "    .master(\"local\").appName(\"PySpark_Postgres_test\").getOrCreate()\n",
    "    #spark.sparkContext.setLogLevel(\"WARN\")\n",
    "    df = spark.read.format(\"jdbc\").option(\"url\", \"jdbc:postgresql://swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com/RawDataBase\").option(\"user\",\"postgres\").option(\"password\",\"swancap123\")\\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\").option(\"dbtable\", tablename)\\\n",
    "        .option(\"user\", \"postgres\").option(\"password\", \"swancap123\").load()\n",
    "    ## GETTING ONLY TIME IN TIME COLUMN\n",
    "    q = df.withColumn('time',date_format('time', 'HH:mm:ss'))\n",
    "    ## FILTERING FINNIFTY DATA\n",
    "    finnifty = q.filter(q.ticker.contains('FINNIFTY') & ((q.ticker.endswith('E.NFO'))| (q.ticker.endswith('E'))))\n",
    "    ## REPLACING .NFO IN ticker\n",
    "    finnifty = finnifty.withColumn('ticker',regexp_replace('ticker','.NFO',''))\n",
    "    finnifty = finnifty.drop(col('ticker_check'))\n",
    "    ## CONVERTING PYSPARK DATAFRAME TO PANDAS DATAFRAME\n",
    "    finnifty = finnifty.toPandas()\n",
    "    finnifty = finnifty.rename(columns={'ticker':'Ticker','date':'Date','time':'Time','open':'Open','high':'High','low':'Low','close':'Close','volume':'Volume'})\n",
    "\n",
    "    # df = pd.read_csv(r\"C:\\\\users\\\\admin\\\\desktop\\\\NSEFO_06092023.csv\")\n",
    "    # finnifty = df[(df['Ticker'].str.startswith('FINNIFTY') & (df['Ticker'].str.endswith('E.NFO')))].reset_index(drop=True)\n",
    "    # finnifty['Ticker'] = finnifty['Ticker'].str.replace('.NFO','')\n",
    "    \n",
    "    finnifty = finnifty[(finnifty['Time']>='09:15:59') & (finnifty['Time']<='15:29:59')].reset_index(drop=True)\n",
    "    finnifty['Date'] = pd.to_datetime(finnifty['Date'],format='mixed',dayfirst=True)\n",
    "    finnifty['Ticker'] = finnifty['Ticker'].str.replace('.NFO','')\n",
    "    finnifty['Temp'] = finnifty['Ticker'].str.replace('FINNIFTY','').str.replace('.NFO','').str[:-2]\n",
    "    finnifty['Length_Of_Temp'] = np.where(finnifty['Temp'].str.len()==15,15,finnifty['Temp'].str.len())\n",
    "    finnifty['Ticker_Expiry_Date'] = pd.to_datetime(finnifty['Temp'].str[:7],format='mixed',dayfirst=True)\n",
    "    finnifty['Exp_year'] = finnifty['Ticker_Expiry_Date'].dt.year\n",
    "    finnifty['Exp_month'] = finnifty['Ticker_Expiry_Date'].dt.month\n",
    "    finnifty = finnifty[finnifty['Ticker_Expiry_Date']>=finnifty['Date']].reset_index(drop=True)                             ## filtering out wrong ticker dates\n",
    "    finnifty['DayOfWeek'] = finnifty['Date'].dt.isocalendar().day\n",
    "    finnifty['ExpiryDayOfWeek'] = finnifty['Ticker_Expiry_Date'].dt.isocalendar().day\n",
    "    finnifty['Current_Week_number'] = finnifty['Date'].dt.isocalendar().week\n",
    "    finnifty['Expiry_Week_number_check'] = finnifty['Ticker_Expiry_Date'].dt.isocalendar().week\n",
    "    # banknifty.to_csv(r'C:\\\\users\\\\admin\\\\desktop\\\\banknifty1.csv',index=False)\n",
    "    finnifty['Expiry_Week_number'] = np.where(finnifty['ExpiryDayOfWeek']<=2,finnifty['Ticker_Expiry_Date'].dt.isocalendar().week-1,finnifty['Ticker_Expiry_Date'].dt.isocalendar().week)\n",
    "    finnifty['Expiry_Week_number'] = np.where((finnifty['DayOfWeek']<=2) & (finnifty['ExpiryDayOfWeek']<=2),finnifty['Expiry_Week_number']+1,finnifty['Expiry_Week_number'])\n",
    "    finnifty['Week_Diff'] = finnifty['Expiry_Week_number'] - finnifty['Current_Week_number']\n",
    "    finnifty[\"Week_Diff\"] = finnifty['Week_Diff'].replace(np.nan,10000)\n",
    "    return finnifty\n",
    "\n",
    "def finnifty_weekly():\n",
    "    ## REMOVING ALREADY STORED FILES\n",
    "    weekly_files = os.listdir(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\FinNifty\\\\Weekly')\n",
    "    for files in weekly_files:\n",
    "        os.remove(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\FinNifty\\\\Weekly\\\\'+files)\n",
    "        \n",
    "    finnifty = finnifty_data()\n",
    "    weekly1 = finnifty[finnifty['ExpiryDayOfWeek']<=2].reset_index(drop=True)\n",
    "    agb = weekly1.groupby([\"Week_Diff\"])\n",
    "    unique_val_list_a = list(weekly1[\"Week_Diff\"].unique())\n",
    "    unique_val_list_a = sorted([a for a in unique_val_list_a if a>=0])[0:12]\n",
    "    for i in sorted(unique_val_list_a):\n",
    "        if i <= 14:\n",
    "            print(f'Week{i+1}')\n",
    "            temp_df = agb.get_group(i)\n",
    "            file = np.where(i==0,'I',np.where(i==1,'II',np.where(i==2,'III',np.where(i==3,'IV',np.where(i==4,'V',np.where(i==5,'VI',np.where(i==6,'VII',np.where(i==7,'VIII',np.where(i==8,'IX',np.where(i==9,'X',np.where(i==10,'XI',np.where(i==11,'XII',np.where(i==12,'XIII',np.where(i==13,'XIV',''))))))))))))))\n",
    "            temp_df['Symbol'] = 'FINNIFTY' + 'WEEKLY-' + str(file) + temp_df['Temp'].str[-5:].astype(int).astype(str) + temp_df['Ticker'].str[-2:]\n",
    "            temp_df['Ticker'] = temp_df['Symbol']\n",
    "            temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "            temp_df = temp_df.drop_duplicates()\n",
    "            temp_df.to_csv(fr'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\FinNifty\\\\Weekly\\\\FINNIFTY-{file}.csv',index=False)\n",
    "    print(\"Weekly Contracts Created\")\n",
    "\n",
    "def finnifty_monthly():\n",
    "    ## REMOVING ALREADY STORED FILES\n",
    "    weekly_files = os.listdir(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\FinNifty\\\\Monthly')\n",
    "    for files in weekly_files:\n",
    "        os.remove(r'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\FinNifty\\\\Monthly\\\\'+files)\n",
    "        \n",
    "    finnifty = finnifty_data()\n",
    "    i = 0\n",
    "    monthly_df = pd.DataFrame()\n",
    "    for name,group in tqdm(finnifty.groupby(['Exp_year','Exp_month'])):\n",
    "        monthly_df = pd.concat([monthly_df,group[group['Ticker_Expiry_Date'] == group['Ticker_Expiry_Date'].max()]],ignore_index=True)\n",
    "        if i <3 :\n",
    "            print(f\"Monthly{i+1}\")\n",
    "            monthly = group[group['Ticker_Expiry_Date'] == group['Ticker_Expiry_Date'].max()]\n",
    "            # display(monthly)\n",
    "            file = np.where(i==0,'I',np.where(i==1,'II',np.where(i==2,'III','')))\n",
    "            monthly['Symbol'] = 'FINNIFTY' + 'MONTHLY-' + str(file) + monthly['Temp'].str[-5:].astype(int).astype(str) + monthly['Ticker'].str[-2:]\n",
    "            monthly['Ticker'] = monthly['Symbol']\n",
    "            monthly = monthly.drop(monthly.columns[9:],axis=1)\n",
    "            monthly.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\Pyspark\\\\FinNifty\\\\Monthly\\\\FINNIFTY-{file}.csv',index=False)\n",
    "            i+=1\n",
    "    print(\"Monthly Contracts Created\")\n",
    "    return monthly_df\n",
    "\n",
    "print(\"BankNifty Contracts being created\")\n",
    "banknifty_weekly()\n",
    "banknifty_halfyearly()\n",
    "banknifty_yearly()\n",
    "print(\"BankNifty Contracts created\\n\")\n",
    "print(\"Nifty Contracts being created\")\n",
    "nifty_weekly()\n",
    "nifty_halfyearly()\n",
    "nifty_yearly()\n",
    "print(\"Nifty Contracts created\\n\")\n",
    "print(\"FinNifty Contracts being created\")\n",
    "finnifty_weekly()\n",
    "finnifty_monthly()\n",
    "print(\"FinNifty Contracts created\\n\")\n",
    "# nifty_halfyearly()\n",
    "# nifty_yearly()\n",
    "\n",
    "et = time.time()\n",
    "\n",
    "link1 = \"BankNifty options creation finished!\"\n",
    "base_url =f\"https://api.telegram.org/bot6237928541:AAHl267HrSFBRFE-iIajz_x8eNkPydiQEEs/sendMessage?chat_id=-939411532&text={link1}\"\n",
    "requests.get(base_url)\n",
    "\n",
    "print(\"\\nElapsed time\",et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5750c6db-c0ca-4150-af50-4595aba9754e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
