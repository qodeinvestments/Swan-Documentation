{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7086c186-5562-4b68-a180-ab995e0b5042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter O for Options data, U for Underlying data, B for Both the data, E for Exiting  B\n",
      "Enter the index you want in the format below - \n",
      "BankNifty\n",
      "Nifty\n",
      "FinNifty  BankNifty\n",
      "Enter schema (MonthlyI, MonthlyII , WeeklyI , QuarterlyI and so on) -  MonthlyII\n",
      "Enter start date as YYYY-MM-DD  2023-01-01\n",
      "Enter end date as YYYY-MM-DD  2023-01-31\n",
      "Enter 1 for 1 minute, 5 for 5 minutes, 15 for 15 minutes, E for EOD, A for All timeframes\n",
      " 5\n",
      "Enter Y if you want Greeks or N  Y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATING OPTIONS DATA\n",
      "Generating data from  2023-01-01  to  2023-01-31\n",
      "CONVERTING TO 5Min\n",
      "OPTIONS DATA GENERATED!\n",
      "elapsed_time: 19.173693656921387\n",
      "\n",
      "GENERATING UNDERLYING DATA\n",
      "CONVERTING TO 5min\n",
      "UNDERLYING DATA GENERATED!\n",
      "elapsed_time: 0.9736931324005127\n",
      "Greeks Generated!\n",
      "Start time :  2023-08-10 16:24:56.606233\n",
      "symbolFilename : BANKNIFTYMONTHLYII\n",
      "symbol : BANKNFTYMONTHLY\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d954188049b4479eae620a5b1da86047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COMPLETED.\n",
      "Total time taken  224.28692030906677\n"
     ]
    }
   ],
   "source": [
    "#import the modules\n",
    "import psycopg2 as pg\n",
    "import time\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pyspark\n",
    "import calendar\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from datetime import timedelta\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import array_contains\n",
    "from pyspark.sql.functions import date_format\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.stats import norm\n",
    "import re\n",
    "########################################################## CONVERTING 1-min to DIFFERENT TIMEFRAMES - UNDERLYING ######################################\n",
    "\n",
    "def EOD_underlying(ddf,index):\n",
    "    print(\"CONVERTING TO EOD\")\n",
    "    final_df = ddf.copy()\n",
    "    final_df['Date'] = pd.to_datetime(final_df['Date'], format='mixed',dayfirst=True)\n",
    "    final_df = final_df[(final_df['Time']>=time1) & (final_df['Time']<=time2)]\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    final_df = final_df.sort_values(by=['Date'])\n",
    "    final_df = final_df.rename(columns={'Time' : 'Timestamp',\n",
    "                                        'Open' : 'Adj_Open',\n",
    "                                        'High' : 'Adj_High',\n",
    "                                        'Low' : 'Adj_Low',\n",
    "                                        'Close' : 'Adj_Close',\n",
    "                                        'Volume' : 'Adj_Volume'})\n",
    "    final_df['Date'] = pd.to_datetime(final_df['Date'],dayfirst=True).dt.date\n",
    "    final_df = final_df.sort_values(by=['Date', 'Timestamp'])\n",
    "    final_df['Date'] = final_df['Date'].astype(str)\n",
    "    final_df['Timestamp'] = final_df['Timestamp'].astype(str)\n",
    "    final_df['Datetime'] = pd.to_datetime(final_df['Date'] + ' ' + final_df['Timestamp'], format='mixed',dayfirst=True)\n",
    "\n",
    "    final_df = final_df.set_index(\"Datetime\")\n",
    "\n",
    "    ddf = final_df.groupby(['Date', pd.Grouper(freq='B')]).agg({\"Adj_Open\" : \"first\", \n",
    "                                                          \"Adj_High\" : \"max\",\n",
    "                                                          \"Adj_Low\" : \"min\",\n",
    "                                                          \"Adj_Close\" : \"last\", \n",
    "                                                          'Adj_Volume' : 'sum'})\n",
    "    ddf.columns = [\"Adj_Open\", \"Adj_High\", \"Adj_Low\", \"Adj_Close\", 'Adj_Volume']\n",
    "    ddf = ddf.reset_index()\n",
    "    ddf['Ticker'] = f\"{index}\".upper()+'.EQ-NSE'\n",
    "\n",
    "    ddf = ddf.sort_values(by=['Datetime'])\n",
    "    ddf.reset_index(drop=True,inplace=True)\n",
    "    ddf = ddf.rename(columns={'Adj_Open':'EQ_Open','Adj_High':'EQ_High','Adj_Low':'EQ_Low','Adj_Close':'EQ_Close','Adj_Volume':'EQ_Volume'})\n",
    "    ddf = ddf[['Ticker','Date','EQ_Open','EQ_High','EQ_Low','EQ_Close','EQ_Volume']]\n",
    "    ddf.to_csv(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_EqData\\\\{index}_EOD.csv\",index=False)\n",
    "    \n",
    "def fifteen_underlying(ddf,index):\n",
    "    print(\"CONVERTING TO 15min\")\n",
    "    final_df = ddf.copy()\n",
    "    final_df['Date'] = pd.to_datetime(final_df['Date'], format='mixed',dayfirst=True)\n",
    "    final_df = final_df[(final_df['Time']>=time1) & (final_df['Time']<=time2)]\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    final_df = final_df.sort_values(by=['Date'])\n",
    "    final_df = final_df.rename(columns={'Time' : 'Timestamp',\n",
    "                                        'Open' : 'Adj_Open',\n",
    "                                        'High' : 'Adj_High',\n",
    "                                        'Low' : 'Adj_Low',\n",
    "                                        'Close' : 'Adj_Close',\n",
    "                                        'Volume' : 'Adj_Volume'})\n",
    "    final_df['Date'] = pd.to_datetime(final_df['Date'],dayfirst=True).dt.date\n",
    "    final_df = final_df.sort_values(by=['Date', 'Timestamp'])\n",
    "    final_df['Date'] = final_df['Date'].astype(str)\n",
    "    final_df['Timestamp'] = final_df['Timestamp'].astype(str)\n",
    "    final_df['Datetime'] = pd.to_datetime(final_df['Date'] + ' ' + final_df['Timestamp'], format='mixed',dayfirst=True)\n",
    "\n",
    "    final_df = final_df.set_index(\"Datetime\")\n",
    "\n",
    "    ddf = final_df.groupby(['Date', pd.Grouper(freq='15min')]).agg({\"Adj_Open\" : \"first\", \n",
    "                                                          \"Adj_High\" : \"max\",\n",
    "                                                          \"Adj_Low\" : \"min\",\n",
    "                                                          \"Adj_Close\" : \"last\", \n",
    "                                                          'Adj_Volume' : 'sum'})\n",
    "    ddf.columns = [\"Adj_Open\", \"Adj_High\", \"Adj_Low\", \"Adj_Close\", 'Adj_Volume']\n",
    "    ddf = ddf.reset_index()\n",
    "    ddf['Ticker'] = f\"{index}\".upper()+'.EQ-NSE'\n",
    "\n",
    "    ddf = ddf.sort_values(by=['Datetime'])\n",
    "    ddf['Time'] = pd.to_datetime(ddf['Datetime']).dt.time\n",
    "    ddf.reset_index(drop=True,inplace=True)\n",
    "    ddf = ddf.rename(columns={'Adj_Open':'EQ_Open','Adj_High':'EQ_High','Adj_Low':'EQ_Low','Adj_Close':'EQ_Close','Adj_Volume':'EQ_Volume'})\n",
    "    ddf = ddf[['Ticker','Date','Time','EQ_Open','EQ_High','EQ_Low','EQ_Close','EQ_Volume']]\n",
    "    ddf.to_csv(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_EqData\\\\{index}_15min.csv\",index=False)\n",
    "\n",
    "def five_underlying(ddf,index):\n",
    "    print(\"CONVERTING TO 5min\")\n",
    "    final_df = ddf.copy()\n",
    "    final_df['Date'] = pd.to_datetime(final_df['Date'], format='mixed',dayfirst=True)\n",
    "    final_df = final_df[(final_df['Time']>=time1) & (final_df['Time']<=time2)]\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    final_df = final_df.sort_values(by=['Date'])\n",
    "    final_df = final_df.rename(columns={'Time' : 'Timestamp',\n",
    "                                        'Open' : 'Adj_Open',\n",
    "                                        'High' : 'Adj_High',\n",
    "                                        'Low' : 'Adj_Low',\n",
    "                                        'Close' : 'Adj_Close',\n",
    "                                        'Volume' : 'Adj_Volume'})\n",
    "    final_df['Date'] = pd.to_datetime(final_df['Date'],dayfirst=True).dt.date\n",
    "    final_df = final_df.sort_values(by=['Date', 'Timestamp'])\n",
    "    final_df['Date'] = final_df['Date'].astype(str)\n",
    "    final_df['Timestamp'] = final_df['Timestamp'].astype(str)\n",
    "    final_df['Datetime'] = pd.to_datetime(final_df['Date'] + ' ' + final_df['Timestamp'], format='mixed',dayfirst=True)\n",
    "\n",
    "    final_df = final_df.set_index(\"Datetime\")\n",
    "\n",
    "    ddf = final_df.groupby(['Date', pd.Grouper(freq='5min')]).agg({\"Adj_Open\" : \"first\", \n",
    "                                                          \"Adj_High\" : \"max\",\n",
    "                                                          \"Adj_Low\" : \"min\",\n",
    "                                                          \"Adj_Close\" : \"last\", \n",
    "                                                          'Adj_Volume' : 'sum'})\n",
    "    ddf.columns = [\"Adj_Open\", \"Adj_High\", \"Adj_Low\", \"Adj_Close\", 'Adj_Volume']\n",
    "    ddf = ddf.reset_index()\n",
    "    ddf['Ticker'] = f\"{index}\".upper()+'.EQ-NSE'\n",
    "\n",
    "    ddf = ddf.sort_values(by=['Datetime'])\n",
    "    ddf['Time'] = pd.to_datetime(ddf['Datetime']).dt.time\n",
    "    ddf.reset_index(drop=True,inplace=True)\n",
    "    ddf = ddf.rename(columns={'Adj_Open':'EQ_Open','Adj_High':'EQ_High','Adj_Low':'EQ_Low','Adj_Close':'EQ_Close','Adj_Volume':'EQ_Volume'})\n",
    "    ddf = ddf[['Ticker','Date','Time','EQ_Open','EQ_High','EQ_Low','EQ_Close','EQ_Volume']]\n",
    "    ddf.to_csv(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_EqData\\\\{index}_5min.csv\",index=False)\n",
    "\n",
    "def one_underlying(ddf,index):\n",
    "    final_df = ddf.copy()\n",
    "    final_df['Date'] = pd.to_datetime(final_df['Date'], format= 'mixed', dayfirst=True)\n",
    "    final_df = final_df[(final_df['Time']>=time1) & (final_df['Time']<=time2)]\n",
    "    final_df = final_df.sort_values(by=['Date','Time'])\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    final_df = final_df[['Ticker','Date','Time','Open','High','Low','Close','Volume']]\n",
    "    final_df.to_csv(fr\"C:\\\\Users\\\\admin\\\\desktop\\\\{index}_EqData\\\\{index}_1min.csv\",index=False)\n",
    "    \n",
    "###################################################### CONVERTING 1-min to DIFFERENT TIMEFRAMES - OPTIONS DATA ##########################################\n",
    "\n",
    "def EOD(ddf,index,schema,hyphen_index):\n",
    "    print(\"CONVERTING TO EOD\")\n",
    "    ddf = ddf.rename(columns={'ticker' : 'Ticker',\n",
    "                            'date' : 'Date',\n",
    "                            'time' : 'Time',\n",
    "                            'open' : 'Open',\n",
    "                            'high' : 'High', \n",
    "                            'low' : 'Low',\n",
    "                            'close' : 'Close',\n",
    "                            'volume' : 'Volume', \n",
    "                            'Open Int' : 'Open Interest'})\n",
    "    ddf['Date'] = pd.to_datetime(ddf['Date'], dayfirst=True)\n",
    "    ddf = ddf.sort_values(by=['Date'])\n",
    "    \n",
    "    symbol = index.upper()\n",
    "    j='-' + schema[hyphen_index:]\n",
    "    schema_find = schema[:hyphen_index].upper()\n",
    "    \n",
    "    final_df = ddf.copy()\n",
    "    final_df['Final_strike'] = final_df['Ticker'].str.replace(j, '')\n",
    "    final_df['Final_strike'] = final_df['Final_strike'].str.replace(f'{index.upper()}'+schema_find, '').str.replace(f'{index.upper()}','').str.replace('CE', '').str.replace('PE', '')\n",
    "    final_df['Final_strike'] = final_df['Final_strike'].astype(float)\n",
    "    final_df['Option_Type'] = final_df['Ticker'].str[-2:]\n",
    "    \n",
    "    final_df = final_df.rename(columns={'Time' : 'Timestamp',\n",
    "                                        'Open' : 'Adj_Open',\n",
    "                                        'High' : 'Adj_High',\n",
    "                                        'Low' : 'Adj_Low',\n",
    "                                        'Close' : 'Adj_Close',\n",
    "                                        'Volume' : 'Adj_Volume',\n",
    "                                        'Open Interest' : 'Adj_OI',        \n",
    "                                        'Option_type' : 'Option_Type'})\n",
    "    final_df['Date'] = pd.to_datetime(final_df['Date'],dayfirst=True).dt.date\n",
    "    final_df = final_df.sort_values(by=['Date', 'Timestamp'])\n",
    "    final_df['Date'] = final_df['Date'].astype(str)\n",
    "    final_df['Timestamp'] = final_df['Timestamp'].astype(str)\n",
    "    final_df['Datetime'] = pd.to_datetime(final_df['Date'] + ' ' + final_df['Timestamp'], format = 'mixed',dayfirst=True)\n",
    "\n",
    "    final_df = final_df.set_index(\"Datetime\")\n",
    "    final_df['Adj_OI_1'] = final_df['Adj_OI']\n",
    "\n",
    "    df_eod = final_df.groupby(['Final_strike', 'Option_Type', pd.Grouper(freq='B')]).agg({\"Adj_Open\" : \"first\", \n",
    "                                                          \"Adj_High\" : \"max\",\n",
    "                                                          \"Adj_Low\" : \"min\",\n",
    "                                                          \"Adj_Close\" : \"last\", \n",
    "                                                          'Adj_Volume' : 'sum',\n",
    "                                                          'Adj_OI' : 'first',\n",
    "                                                          'Adj_OI_1' : 'last'})\n",
    "    df_eod.columns = [\"Adj_Open\", \"Adj_High\", \"Adj_Low\", \"Adj_Close\", 'Adj_Volume', 'First_OI', 'Last_OI']\n",
    "    df_eod = df_eod.reset_index()\n",
    "    df_eod['rem'] = df_eod['Final_strike']%df_eod['Final_strike'].astype(int)\n",
    "    df_eod.loc[df_eod['rem'] == 0, 'Ticker'] = symbol + schema_find + j +  df_eod['Final_strike'].astype(int).astype(str) + df_eod['Option_Type']\n",
    "    df_eod.loc[df_eod['rem'] != 0, 'Ticker'] = symbol + schema_find + j + df_eod['Final_strike'].round(2).astype(str) + df_eod['Option_Type']\n",
    "\n",
    "    df_eod = df_eod.sort_values(by=['Datetime', 'Final_strike'])\n",
    "    df_eod = df_eod.rename(columns={'Datetime' : 'Date'})\n",
    "    df_eod['Date'] = pd.to_datetime(df_eod['Date'],dayfirst=True)\n",
    "    ## CHECKING IF NULL VALUES\n",
    "    df_eod['New_OI'] = df_eod['Last_OI']\n",
    "    df_eod = df_eod.rename(columns={'Adj_Open':'Open','Adj_High':'High','Adj_Low':'Low','Adj_Close':'Close','Adj_Volume':'Volume','New_OI':'Open_Interest'})\n",
    "    df_eod = df_eod.drop(['First_OI','Last_OI','Option_Type','Final_strike','rem'],axis=1)\n",
    "    df_eod = df_eod[['Ticker','Date','Open','High','Low','Close','Volume','Open_Interest']]\n",
    "    df_eod.reset_index(drop=True,inplace=True)\n",
    "    df_eod.to_csv(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_Opt_EOD.csv\", mode='a', header = not os.path.exists(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_Opt_EOD.csv\"), index=False)\n",
    "\n",
    "def fifteen_min(ddf,index,schema,hyphen_index):\n",
    "    print(\"CONVERTING TO 15Min\")\n",
    "    ddf = ddf.rename(columns={'ticker' : 'Ticker',\n",
    "                            'date' : 'Date',\n",
    "                            'time' : 'Time',\n",
    "                            'open' : 'Open',\n",
    "                            'high' : 'High', \n",
    "                            'low' : 'Low',\n",
    "                            'close' : 'Close',\n",
    "                            'volume' : 'Volume', \n",
    "                            'Open Int' : 'Open Interest'})\n",
    "    ddf['Date'] = pd.to_datetime(ddf['Date'], dayfirst=True)\n",
    "    ddf = ddf.sort_values(by=['Date'])\n",
    "    \n",
    "    symbol = index.upper()\n",
    "    j='-' + schema[hyphen_index:]\n",
    "    schema_find = schema[:hyphen_index].upper()\n",
    "\n",
    "    final_df = ddf.copy()\n",
    "    final_df['Final_strike'] = final_df['Ticker'].str.replace(j, '')\n",
    "    final_df['Final_strike'] = final_df['Final_strike'].str.replace(f'{index.upper()}'+schema_find, '').str.replace(f'{index.upper()}','').str.replace('CE', '').str.replace('PE', '')\n",
    "    final_df['Final_strike'] = final_df['Final_strike'].astype(float)\n",
    "    final_df['Option_Type'] = final_df['Ticker'].str[-2:]\n",
    "    \n",
    "    final_df = final_df.rename(columns={'Time' : 'Timestamp',\n",
    "                                        'Open' : 'Adj_Open',\n",
    "                                        'High' : 'Adj_High',\n",
    "                                        'Low' : 'Adj_Low',\n",
    "                                        'Close' : 'Adj_Close',\n",
    "                                        'Volume' : 'Adj_Volume',\n",
    "                                        'Open Interest' : 'Adj_OI',        \n",
    "                                        'Option_type' : 'Option_Type'})\n",
    "    final_df['Date'] = pd.to_datetime(final_df['Date'],dayfirst=True).dt.date\n",
    "    final_df = final_df.sort_values(by=['Date', 'Timestamp'])\n",
    "    final_df['Date'] = final_df['Date'].astype(str)\n",
    "    final_df['Timestamp'] = final_df['Timestamp'].astype(str)\n",
    "    final_df['Datetime'] = pd.to_datetime(final_df['Date'] + ' ' + final_df['Timestamp'], format='mixed',dayfirst=True)\n",
    "\n",
    "    final_df = final_df.set_index(\"Datetime\")\n",
    "    final_df['Adj_OI_1'] = final_df['Adj_OI']\n",
    "\n",
    "    df_eod = final_df.groupby(['Final_strike', 'Option_Type', pd.Grouper(freq='15min')]).agg({\"Adj_Open\" : \"first\", \n",
    "                                                          \"Adj_High\" : \"max\",\n",
    "                                                          \"Adj_Low\" : \"min\",\n",
    "                                                          \"Adj_Close\" : \"last\", \n",
    "                                                          'Adj_Volume' : 'sum',\n",
    "                                                          'Adj_OI' : 'first',\n",
    "                                                          'Adj_OI_1' : 'last'})\n",
    "    df_eod.columns = [\"Adj_Open\", \"Adj_High\", \"Adj_Low\", \"Adj_Close\", 'Adj_Volume', 'First_OI', 'Last_OI']\n",
    "    df_eod = df_eod.reset_index()\n",
    "    df_eod['rem'] = df_eod['Final_strike']%df_eod['Final_strike'].astype(int)\n",
    "    df_eod.loc[df_eod['rem'] == 0, 'Ticker'] = symbol + schema_find + j +  df_eod['Final_strike'].astype(int).astype(str) + df_eod['Option_Type']\n",
    "    df_eod.loc[df_eod['rem'] != 0, 'Ticker'] = symbol + schema_find + j + df_eod['Final_strike'].round(2).astype(str) + df_eod['Option_Type'] \n",
    "\n",
    "    df_eod = df_eod.sort_values(by=['Datetime', 'Final_strike'])\n",
    "    df_eod = df_eod.rename(columns={'Datetime' : 'Date'})\n",
    "    df_eod['Time'] = pd.to_datetime(df_eod['Date']).dt.time\n",
    "    df_eod['Date'] = pd.to_datetime(df_eod['Date'],dayfirst=True).dt.date\n",
    "    ## CHECKING IF NULL VALUES\n",
    "    df_eod['New_OI'] = df_eod['Last_OI']\n",
    "    df_eod = df_eod.rename(columns={'Adj_Open':'Open','Adj_High':'High','Adj_Low':'Low','Adj_Close':'Close','Adj_Volume':'Volume','New_OI':'Open_Interest'})\n",
    "    df_eod = df_eod.drop(['First_OI','Last_OI','Option_Type','Final_strike','rem'],axis=1)\n",
    "    df_eod = df_eod[['Ticker','Date','Time','Open','High','Low','Close','Volume','Open_Interest']]\n",
    "    df_eod.reset_index(drop=True,inplace=True)\n",
    "    df_eod.to_csv(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_Opt_15min.csv\", mode='a', header = not os.path.exists(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_Opt_15min.csv\"), index=False)\n",
    "    \n",
    "def five_min(ddf,index,schema,hyphen_index):\n",
    "    print(\"CONVERTING TO 5Min\")\n",
    "    ddf = ddf.rename(columns={'ticker' : 'Ticker',\n",
    "                            'date' : 'Date',\n",
    "                            'time' : 'Time',\n",
    "                            'open' : 'Open',\n",
    "                            'high' : 'High', \n",
    "                            'low' : 'Low',\n",
    "                            'close' : 'Close',\n",
    "                            'volume' : 'Volume', \n",
    "                            'Open Int' : 'Open Interest'})\n",
    "    ddf['Date'] = pd.to_datetime(ddf['Date'], dayfirst=True)\n",
    "    ddf = ddf.sort_values(by=['Date'])\n",
    "    \n",
    "    symbol = index.upper()\n",
    "    j='-' + schema[hyphen_index:]\n",
    "    schema_find = schema[:hyphen_index].upper()\n",
    "\n",
    "    final_df = ddf.copy()\n",
    "    final_df['Final_strike'] = final_df['Ticker'].str.replace(j, '')\n",
    "    final_df['Final_strike'] = final_df['Final_strike'].str.replace(f'{index.upper()}'+schema_find, '').str.replace(f'{index.upper()}','').str.replace('CE', '').str.replace('PE', '')\n",
    "    final_df['Final_strike'] = final_df['Final_strike'].astype(float)\n",
    "    final_df['Option_Type'] = final_df['Ticker'].str[-2:]\n",
    "    \n",
    "    final_df = final_df.rename(columns={'Time' : 'Timestamp',\n",
    "                                        'Open' : 'Adj_Open',\n",
    "                                        'High' : 'Adj_High',\n",
    "                                        'Low' : 'Adj_Low',\n",
    "                                        'Close' : 'Adj_Close',\n",
    "                                        'Volume' : 'Adj_Volume',\n",
    "                                        'Open Interest' : 'Adj_OI',        \n",
    "                                        'Option_type' : 'Option_Type'})\n",
    "    final_df['Date'] = pd.to_datetime(final_df['Date'],dayfirst=True).dt.date\n",
    "    final_df = final_df.sort_values(by=['Date', 'Timestamp'])\n",
    "    final_df['Date'] = final_df['Date'].astype(str)\n",
    "    final_df['Timestamp'] = final_df['Timestamp'].astype(str)\n",
    "    final_df['Datetime'] = pd.to_datetime(final_df['Date'] + ' ' + final_df['Timestamp'], format='mixed',dayfirst=True)\n",
    "\n",
    "    final_df = final_df.set_index(\"Datetime\")\n",
    "    final_df['Adj_OI_1'] = final_df['Adj_OI']\n",
    "\n",
    "    df_eod = final_df.groupby(['Final_strike', 'Option_Type', pd.Grouper(freq='5min')]).agg({\"Adj_Open\" : \"first\", \n",
    "                                                          \"Adj_High\" : \"max\",\n",
    "                                                          \"Adj_Low\" : \"min\",\n",
    "                                                          \"Adj_Close\" : \"last\", \n",
    "                                                          'Adj_Volume' : 'sum',\n",
    "                                                          'Adj_OI' : 'first',\n",
    "                                                          'Adj_OI_1' : 'last'})\n",
    "    df_eod.columns = [\"Adj_Open\", \"Adj_High\", \"Adj_Low\", \"Adj_Close\", 'Adj_Volume', 'First_OI', 'Last_OI']\n",
    "    df_eod = df_eod.reset_index()\n",
    "    df_eod['rem'] = df_eod['Final_strike']%df_eod['Final_strike'].astype(int)\n",
    "    df_eod.loc[df_eod['rem'] == 0, 'Ticker'] = symbol + schema_find + j +  df_eod['Final_strike'].astype(int).astype(str) + df_eod['Option_Type']\n",
    "    df_eod.loc[df_eod['rem'] != 0, 'Ticker'] = symbol + schema_find + j + df_eod['Final_strike'].round(2).astype(str) + df_eod['Option_Type'] \n",
    "\n",
    "    df_eod = df_eod.sort_values(by=['Datetime', 'Final_strike'])\n",
    "    df_eod = df_eod.rename(columns={'Datetime' : 'Date'})\n",
    "    df_eod['Time'] = pd.to_datetime(df_eod['Date']).dt.time\n",
    "    df_eod['Date'] = pd.to_datetime(df_eod['Date'],dayfirst=True).dt.date\n",
    "    \n",
    "    ## CHECKING IF NULL VALUES\n",
    "    df_eod['New_OI'] = df_eod['Last_OI']\n",
    "    df_eod = df_eod.rename(columns={'Adj_Open':'Open','Adj_High':'High','Adj_Low':'Low','Adj_Close':'Close','Adj_Volume':'Volume','New_OI':'Open_Interest'})\n",
    "    df_eod = df_eod.drop(['First_OI','Last_OI','Option_Type','Final_strike','rem'],axis=1)\n",
    "    df_eod = df_eod[['Ticker','Date','Time','Open','High','Low','Close','Volume','Open_Interest']]\n",
    "    df_eod.reset_index(drop=True,inplace=True)\n",
    "    df_eod.to_csv(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_Opt_5min.csv\", mode='a', header = not os.path.exists(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_Opt_5min.csv\"), index=False)\n",
    "\n",
    "def one_min(ddf,index,schema,hyphen_index):\n",
    "    ddf = ddf.rename(columns={'ticker' : 'Ticker',\n",
    "                            'date' : 'Date',\n",
    "                            'time' : 'Time',\n",
    "                            'open' : 'Open',\n",
    "                            'high' : 'High', \n",
    "                            'low' : 'Low',\n",
    "                            'close' : 'Close',\n",
    "                            'volume' : 'Volume', \n",
    "                            'Open Int' : 'Open_Interest'})\n",
    "    ddf['Date'] = pd.to_datetime(ddf['Date'], dayfirst=True)\n",
    "    ddf = ddf.sort_values(by=['Date'])\n",
    "    ddf = ddf[(ddf['Time']>=time1) & ((ddf['Time']<=time2))]\n",
    "    ddf = ddf.sort_values(by=['Date','Time'])\n",
    "    ddf.reset_index(drop=True,inplace=True)\n",
    "    ddf = ddf[['Ticker','Date','Time','Open','High','Low','Close','Volume','Open_Interest']]\n",
    "    ddf.to_csv(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_Opt_1min.csv\", mode='a', header = not os.path.exists(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_Opt_1min.csv\"), index=False)\n",
    "    \n",
    "########################################################## OPTIONS DATA FUNCTION ###############################################################\n",
    "\n",
    "def option_data(index,date1,date2,conversion,schema):\n",
    "    hyphen_index = schema.find(\"I\")\n",
    "\n",
    "    st=time.time()\n",
    "    ## CREATING A DIRECTORY OF THE REQUIRED INDEX AND SCHEMA\n",
    "    if not os.path.exists(rf\"C:\\\\users\\\\admin\\\\desktop\\\\{index}_{schema}_Data\\\\\"):\n",
    "        os.makedirs(rf\"C:\\users\\admin\\desktop\\\\{index}_{schema}_Data\\\\\")\n",
    "\n",
    "    date1 = datetime.strptime(date1, \"%Y-%m-%d\").date()\n",
    "    date2 = datetime.strptime(date2, \"%Y-%m-%d\").date()\n",
    "    year1 = date1.year\n",
    "    year2 = date2.year\n",
    "    print(\"\\nGENERATING OPTIONS DATA\")\n",
    "    for i in range(int(year1),int(year2)+1):\n",
    "        ddate1 = '-01-01'\n",
    "        ddate2 = '-12-31'\n",
    "        year_start = str(str(i)+ddate1)\n",
    "        year_end = str(str(i)+ddate2)\n",
    "        year_start = datetime.strptime(year_start, \"%Y-%m-%d\").date()\n",
    "        year_end = datetime.strptime(year_end, \"%Y-%m-%d\").date()\n",
    "        if date1 > year_start :\n",
    "            year_start = date1\n",
    "        else:\n",
    "            year_start = year_start\n",
    "        if year_end > date2 :\n",
    "            year_end = date2\n",
    "        else:\n",
    "            year_end = year_end\n",
    "\n",
    "        ddf = pd.DataFrame()\n",
    "        engine = pg.connect(f\"dbname='{index}db' user='postgres' host='swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com' port='5432' password='swancap123'\")\n",
    "        print(\"Generating data from \", year_start , \" to \" , year_end)\n",
    "        ddf = pd.read_sql(f'select * from \"{index}{schema}\".select_datewise(\\'{year_start}\\',\\'{year_end}\\')',con=engine)\n",
    "        ddf = ddf.sort_values(by=[\"date\",'time'])\n",
    "        ddf.reset_index(drop=True,inplace=True)\n",
    "        # with open(f\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_\"+str(i)+\".csv\", \"w\") as file:\n",
    "        #     cursor.copy_expert(sql, file)\n",
    "        if conversion == 'E':\n",
    "            EOD(ddf,index,schema,hyphen_index)\n",
    "    \n",
    "        elif conversion == '15':\n",
    "            fifteen_min(ddf,index,schema,hyphen_index)\n",
    "    \n",
    "        elif conversion == '5':\n",
    "            five_min(ddf,index,schema,hyphen_index)\n",
    "    \n",
    "        elif conversion == '1':\n",
    "            one_min(ddf,index,schema,hyphen_index)\n",
    "\n",
    "        elif conversion == 'a' or conversion == 'A':\n",
    "            EOD(ddf,index,schema,hyphen_index)\n",
    "            fifteen_min(ddf,index,schema,hyphen_index)\n",
    "            five_min(ddf,index,schema,hyphen_index)\n",
    "            one_min(ddf,index,schema,hyphen_index)\n",
    "\n",
    "    et=time.time()\n",
    "    elapsed_time=et-st;\n",
    "    print(\"OPTIONS DATA GENERATED!\")\n",
    "    print(\"elapsed_time:\",elapsed_time)\n",
    "\n",
    "########################################################## UNDERLYING DATA FUNCTION ###############################################################\n",
    "\n",
    "def underlying_data(index,date1,date2,conversion):\n",
    "\n",
    "    if not os.path.exists(rf\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_EqData\\\\\"):\n",
    "        os.makedirs(rf\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_EqData\\\\\")\n",
    "    \n",
    "    start_date = datetime.strptime(date1,\"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(date2,\"%Y-%m-%d\")\n",
    "    start_date=start_date.date()\n",
    "    end_date = end_date.date()\n",
    "    print(\"\\nGENERATING UNDERLYING DATA\")\n",
    "    st = time.time()\n",
    "    \n",
    "    engine = pg.connect(\"dbname='IndexEQ' user='postgres' host='swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com' port='5432' password='swancap123'\")\n",
    "    ddf = pd.read_sql(f'select * from \"{index}\".\"AllData\" where \"Date\" between \\'{date1}\\' and \\'{date2}\\'', con=engine)\n",
    "    ddf['Ticker'] = f'{index.upper()}' + '.EQ-NSE'\n",
    "    ddf = ddf.sort_values(by=[\"Date\",'Time'])\n",
    "\n",
    "    if conversion == 'E':\n",
    "        EOD_underlying(ddf,index)\n",
    "    elif conversion == '15':\n",
    "        fifteen_underlying(ddf,index)\n",
    "    elif conversion == '5':\n",
    "        five_underlying(ddf,index)\n",
    "    elif conversion == '1':\n",
    "        one_underlying(ddf,index)\n",
    "    elif conversion == 'a' or conversion == 'A':\n",
    "        EOD_underlying(ddf,index)\n",
    "        fifteen_underlying(ddf,index)\n",
    "        five_underlying(ddf,index)\n",
    "        one_underlying(ddf,index)\n",
    "\n",
    "    et=time.time()\n",
    "    elapsed_time=et-st;\n",
    "    print(\"UNDERLYING DATA GENERATED!\")\n",
    "    print(\"elapsed_time:\",elapsed_time)\n",
    "    engine.close()\n",
    "\n",
    "######################################################## MAIN CODE STARTS FROM HERE ######################################################################\n",
    "admin_path = 'admin'\n",
    "time1 = datetime.strptime('09:15:00','%H:%M:%S').time()\n",
    "time2 = datetime.strptime('15:30:00','%H:%M:%S').time()\n",
    "\n",
    "data = input(\"Enter O for Options data, U for Underlying data, B for Both the data, E for Exiting \")\n",
    "\n",
    "################################################ TAKING INPUTS FOR INDEX, DATE RANGE AND TIMEFRAME #############################################\n",
    "\n",
    "if data == 'o' or data == 'O' or data == 'b' or data == 'B':\n",
    "    index = input(\"Enter the index you want in the format below - \\nBankNifty\\nNifty\\nFinNifty \")\n",
    "    schema = input(\"Enter schema (MonthlyI, MonthlyII , WeeklyI , QuarterlyI and so on) - \")\n",
    "    date1 = input(\"Enter start date as YYYY-MM-DD \")\n",
    "    date2 = input(\"Enter end date as YYYY-MM-DD \")\n",
    "    conversion = input(\"Enter 1 for 1 minute, 5 for 5 minutes, 15 for 15 minutes, E for EOD, A for All timeframes\\n\")\n",
    "    greeks_input = input('Enter Y if you want Greeks or N ')\n",
    "\n",
    "elif data == 'u' or data == 'U':\n",
    "    index = input(\"Enter the index you want in the format below - \\nBankNifty\\nNifty\\nFinNifty\\nIndiaVix \")\n",
    "    date1 = input(\"Enter start date as YYYY-MM-DD \")\n",
    "    date2 = input(\"Enter end date as YYYY-MM-DD \")\n",
    "    conversion = input(\"Enter 1 for 1 minute, 5 for 5 minutes, 15 for 15 minutes, E for EOD, A for All timeframes\\n\")\n",
    "\n",
    "elif data == 'e' or data == 'E':\n",
    "    print(\"Exit!\")\n",
    "\n",
    "else:\n",
    "    print(\"Wrong option\")\n",
    "\n",
    "start_time = time.time()\n",
    "    \n",
    "if data == 'O' or data == 'o':\n",
    "    option_data(index,date1,date2,conversion,schema)\n",
    "\n",
    "elif data == 'U' or data == 'u':\n",
    "    underlying_data(index,date1,date2,conversion)\n",
    "\n",
    "elif data == 'B' or data == 'b':\n",
    "    option_data(index,date1,date2,conversion,schema)\n",
    "    underlying_data(index,date1,date2,conversion)\n",
    "\n",
    "if greeks_input == 'y' or greeks_input == 'Y':\n",
    "    \n",
    "    if conversion == 'E':\n",
    "        def greeks(Spot, Strike, MTE, OPT, Option_Type):\n",
    "            if Option_Type == 'CE':\n",
    "                NormDist = norm.cdf\n",
    "                Rate = 0.065\n",
    "                Dividend = 0.015\n",
    "                Upper = 5\n",
    "                Lower = 0\n",
    "                TargetCE = OPT\n",
    "                if MTE == 0:\n",
    "                    CallIV = 5\n",
    "                    CallDelta = 1 if Spot > Strike else 0\n",
    "                    CallGamma = 0\n",
    "                    CallTheta = 0\n",
    "                    CallVega = 0\n",
    "                else:\n",
    "                    while ((Upper - Lower) > 0.00001):   \n",
    "                        dOne = (math.log(Spot/Strike)+((Rate - Dividend + (0.5 * (((Upper + Lower)/2)**2)))*MTE))/(((Upper + Lower)/2)*(MTE**0.5))\n",
    "                        dTwo = dOne - ((Upper + Lower)/2) * MTE ** 0.5\n",
    "                        ndOne = NormDist(dOne)\n",
    "                        ndTwo = NormDist(dTwo)\n",
    "                        CallPremium =  (math.exp(-Dividend * MTE) * (Spot * ndOne)) - (Strike * math.exp(-Rate * MTE) * ndTwo)\n",
    "                        if(CallPremium > TargetCE):\n",
    "                            Upper = (Upper + Lower) / 2\n",
    "                        else:\n",
    "                            Lower = (Upper + Lower) / 2\n",
    "                    CallIV = (Upper + Lower) / 2  \n",
    "                    ndashOne = 1 / (2 * math.pi) ** 0.5 * (math.exp(-(dOne**2)/2))\n",
    "                    CallVega = Spot*((MTE**(1/2))*ndashOne*math.exp(-Dividend*MTE))/100\n",
    "                    CallGamma = ((((1/math.sqrt((2*math.pi)))*math.exp(((-1*(dOne**2))/2)))*math.exp(((-1*MTE)*Dividend)))/((Spot*CallIV)*math.sqrt(MTE)))\n",
    "                    CallDelta = ndOne * math.exp(-Dividend * MTE)\n",
    "                    CallTheta = ((((-1*((((Spot*((1/math.sqrt((2*math.pi)))*math.exp(((-1*(dOne**2))/2))))*CallIV)*math.exp(((-1*MTE)*Dividend)))/(2*math.sqrt(MTE))))+((Dividend*Spot)*CallDelta))-(((Rate*Strike)*math.exp(((-1*Rate)*MTE)))*NormDist(dTwo))))/365\n",
    "                return CallIV, CallDelta, CallGamma, CallTheta, CallVega\n",
    "                        \n",
    "            elif Option_Type == 'PE':\n",
    "                NormDist = norm.cdf\n",
    "                Rate = 0.065\n",
    "                Dividend = 0.015\n",
    "                Upper = 5\n",
    "                Lower = 0\n",
    "                TargetPE = OPT\n",
    "                if MTE==0:\n",
    "                    PutIV = 5\n",
    "                    PutDelta = -1 if Spot < Strike else 0\n",
    "                    PutGamma = 0\n",
    "                    PutTheta = 0\n",
    "                    PutVega = 0\n",
    "                else:\n",
    "                    while ((Upper - Lower) > 0.00001):\n",
    "                        dOne = (math.log(Spot/Strike)+((Rate - Dividend + (0.5*(((Upper + Lower)/2)**2)))*MTE))/(((Upper + Lower)/2)*MTE**0.5)\n",
    "                        dTwo = dOne - ((Upper + Lower)/2) * MTE ** 0.5\n",
    "                        ndOne = NormDist(dOne)\n",
    "                        ndTwo = NormDist(dTwo)\n",
    "                        PutPremium =  math.exp(-Rate * MTE) * Strike * (NormDist(-dTwo)) -math.exp(-Dividend * MTE) *  Spot* (NormDist( -dOne))\n",
    "                        if(PutPremium > TargetPE):\n",
    "                            Upper = (Upper + Lower) / 2\n",
    "                        else:\n",
    "                            Lower = (Upper + Lower) / 2\n",
    "                    PutIV = (Upper + Lower) / 2\n",
    "                    ndashOne = 1 / (2*math.pi) ** 0.5 * (math.exp(-(dOne**2)/2))\n",
    "                    PutVega = Spot*((MTE**(1/2))*ndashOne*math.exp(-Dividend*MTE))/100\n",
    "                    PutGamma = ((((1/math.sqrt((2*math.pi)))*math.exp(((-1*(dOne**2))/2)))*math.exp(((-1*MTE)*Dividend)))/((Spot*PutIV)*math.sqrt(MTE)))\n",
    "                    PutTheta = (((((-1*((((Spot*((1/math.sqrt((2*math.pi)))*math.exp(((-1*dOne**2)/2))))*PutIV)*math.exp(((-1*MTE)*Dividend)))))/(2*math.sqrt(MTE)))-(((Dividend*Spot)*NormDist((-1*dOne)))*math.exp(((-1*MTE)*Dividend))))+(((Rate*Strike)*math.exp(((-1*Rate)*MTE)))*NormDist((-1*dTwo)))))/365\n",
    "                    PutDelta = (ndOne-1) * math.exp(-Dividend * MTE)\n",
    "                return PutIV, PutDelta, PutGamma, PutTheta, PutVega\n",
    "        \n",
    "        st_g = time.time()\n",
    "        eq_df = pd.read_csv(rf\"C:\\\\users\\\\admin\\\\desktop\\\\{index}_EqData\\\\{index}_EOD.csv\",parse_dates=['Date'])\n",
    "        opt_df = pd.read_csv(fr\"C:\\Users\\admin\\Desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_Opt_EOD.csv\",parse_dates=['Date'])\n",
    "        eq_df = eq_df.rename(columns={' Time' : 'Time','Open' : 'EQ_Open','High' : 'EQ_High','Low' : 'EQ_Low','Close' : 'EQ_Close'})\n",
    "        eq_df['Date'] = pd.to_datetime(eq_df['Date'],format='mixed',dayfirst=True)\n",
    "        opt_df = opt_df.rename(columns={'date' : 'Date',\n",
    "                                'ticker' : 'Ticker',\n",
    "                                'time' : 'Time',\n",
    "                                'open' : 'Open',\n",
    "                                'high' : 'High',\n",
    "                                'low' : 'Low',\n",
    "                                'close' : 'Close',\n",
    "                                'volume' : 'Volume',\n",
    "                                'Open_Interest' : 'OpenInterest'})\n",
    "        opt_df = opt_df.rename(columns={'Open' : 'Adj_Open','High' : 'Adj_High','Low' : 'Adj_Low','Close' : 'Adj_Close'})\n",
    "        \n",
    "        opt_df['Date'] = pd.to_datetime(opt_df['Date'], format='mixed',dayfirst=True)\n",
    "        opt_df['Year'] = opt_df['Date'].dt.year\n",
    "        opt_df = opt_df.drop(['Year'], axis=1)\n",
    "        opt_df = opt_df.merge(eq_df[['Date','EQ_Open','EQ_High','EQ_Low','EQ_Close']], on=['Date'], how='left')\n",
    "        \n",
    "        exp_df['Date'] = pd.to_datetime(exp_df['Date'], format='mixed',dayfirst=True)\n",
    "        if schema[schema.find('y')+1:] == 'I':\n",
    "            opt_df = opt_df.merge(exp_df[['Date', 'E1']], on=['Date'], how='left')\n",
    "            opt_df = opt_df.rename(columns={'E1' : 'Expiry_Date'})\n",
    "        elif schema[schema.find('y')+1:] == 'II':\n",
    "            opt_df = opt_df.merge(exp_df[['Date', 'E2']], on=['Date'], how='left')\n",
    "            opt_df = opt_df.rename(columns={'E2' : 'Expiry_Date'})\n",
    "        elif schema[schema.find('y')+1:] == 'III':\n",
    "            opt_df = opt_df.merge(exp_df[['Date', 'E3']], on=['Date'], how='left')\n",
    "            opt_df = opt_df.rename(columns={'E3' : 'Expiry_Date'})\n",
    "        \n",
    "        opt_df = opt_df.rename(columns={'E1' : 'Expiry_Date'})\n",
    "        \n",
    "        opt_df['Date'] = pd.to_datetime(opt_df['Date'],dayfirst=True)\n",
    "        opt_df['Expiry_Date'] = pd.to_datetime(opt_df['Expiry_Date'], dayfirst=True)\n",
    "        opt_df['YTE'] = (opt_df['Expiry_Date'] - opt_df['Date']).dt.days\n",
    "        opt_df['YTE/365'] = opt_df['YTE']/365\n",
    "        \n",
    "        opt_df['Final_strike'] = opt_df['Ticker'].str.replace(f'{index.upper()}{schema[:schema.find(\"y\")+1].upper()}-{schema[schema.find(\"y\")+1:]}',\"\").str[:-2].astype(int)    \n",
    "        # opt_df['Final_strike'] = opt_df['Ticker'].str.replace(f'{stock_name}-I','').str[:-2].astype(float)#.str.replace(f'{schema_name+hyphens[k]}', '').str.replace(f'{index[i].upper()+hyphens[k]}','').str.replace(f'{index[i].upper()+schema_name+hyphens[k]}','').str.replace(f'{index[i].upper()}','')\n",
    "        opt_df['Option_Type'] = opt_df['Ticker'].str[-2:]\n",
    "        \n",
    "        greeks_series = opt_df.apply(lambda x: greeks(x['EQ_Close'], x['Final_strike'], x['YTE/365'], x['Adj_Close'], x['Option_Type']), axis=1)\n",
    "        #df = df.drop(['Delta'], axis=1)\n",
    "        try:\n",
    "            opt_df[['IV', 'Delta', 'Gamma', 'Theta', 'Vega']] = pd.DataFrame(list(greeks_series))\n",
    "        except:\n",
    "            print(opt_df)\n",
    "            print(opt_df)\n",
    "        opt_df = opt_df.drop(['YTE', 'YTE/365'], axis=1)\n",
    "        opt_df = opt_df.sort_values(by=['Date', 'Option_Type', 'Final_strike'])\n",
    "        # df[['IV', 'Delta', 'Gamma', 'Theta', 'Vega']] = pd.DataFrame(list(greeks_series))\n",
    "        # df = df.sort_values(by=['Date', 'Time', 'Option_Type', 'Final_strike'])\n",
    "        # df = df[['Date', 'Time', 'Ticker','IV', 'Delta', 'Gamma', 'Theta', 'Vega']]\n",
    "        opt_df.to_csv(fr'C:\\\\users\\admin\\\\desktop\\\\{index}_{schema}_Greeks_EOD.csv',index=False)\n",
    "        print(\"\\nGreeks Generated!\")\n",
    "        et_g = time.time()\n",
    "        print(\"Time taken to generate greeks\",et_g-st_g)\n",
    "        # file paths\n",
    "        output_path = r\"C:\\\\users\\\\admin\\\\desktop\\\\\"\n",
    "        # select delta values\n",
    "        delta_list = [0.05, 0.10, 0.15, 0.20, 0.25,\n",
    "                      0.30, 0.35, 0.40, 0.45, 0.50, \n",
    "                      0.55, 0.60, 0.65, 0.70, 0.75, \n",
    "                      0.80, 0.85, 0.90, 0.95]\n",
    "        \n",
    "        # load main csv\n",
    "        print('Start time : ', datetime.now())\n",
    "        \n",
    "        opt_df.rename(columns={\n",
    "                           'Adj_Open' : 'OPT_Open',\n",
    "                           'Adj_High' : 'OPT_High',\n",
    "                           'Adj_Low' : 'OPT_Low',\n",
    "                           'Adj_Close' : 'OPT_Close',\n",
    "                           'Adj_Volume' : 'OPT_Contracts',\n",
    "                           # 'Volume' : 'OPT_Contracts',\n",
    "                            #'New_OI' : 'OPT_OI',\n",
    "                           'Last_OI' : 'OPT_OI',\n",
    "                           'OpenInterest' : 'OPT_OI',\n",
    "                           'Final_strike' : 'Strike',\n",
    "                           'CONTRACTS' : 'OPT_Contracts',\n",
    "                           'OPEN_INT' : 'OPT_OI'}, inplace=True)\n",
    "        \n",
    "        # extract Strike and Option Type from the Ticker if it's not there in the input file already.\n",
    "        \n",
    "        # df['Strike'] = df['Ticker'].str.extract('([0-9]+[./]*[0-9]*)').astype(float)\n",
    "        \n",
    "        # df['Option_Type'] = df[\"Ticker\"].str[-2:]\n",
    "        \n",
    "        # df['Option_Type'] = np.where((df['Option_Type'] == 'CE') | (df['Option_Type'] == 'PE'),\n",
    "        #                              df['Option_Type'], 'XX')\n",
    "        # get the symbol from filename\n",
    "        symbolFilename = index.upper()+schema.upper()\n",
    "        print('symbolFilename :', symbolFilename)\n",
    "        \n",
    "        # remove '-I'/'-II'/'-III' from filename\n",
    "        symbol = symbolFilename.replace('-III', '')\n",
    "        symbol = symbol.replace('-VIII', '')\n",
    "        symbol = symbol.replace('-VII', '')\n",
    "        symbol = symbol.replace('-VI', '')\n",
    "        symbol = symbol.replace('-V', '')\n",
    "        symbol = symbol.replace('-IV', '')\n",
    "        symbol = symbol.replace('-II', '')\n",
    "        symbol = symbol.replace('-I', '')\n",
    "        print('symbol :', symbol)\n",
    "        \n",
    "        # substitute any special characters ('-', '&', '_') in Dispersion file names with empty string ('_')\n",
    "        charactersDroppedSymbol = re.sub('\\ |\\_|\\.|\\-|\\&|\\;|\\:', '', symbol)\n",
    "        df2 = opt_df.copy()\n",
    "        # calculate difference between 'EQ_Close' and 'Strike' and get the minimum difference for a group\n",
    "        df2['Difference'] = abs(df2['EQ_Close'] - df2['Strike'].astype(float))\n",
    "        dfg = df2.groupby(['Date', 'Option_Type'])['Difference']\n",
    "        df2['Min'] = dfg.transform('min')\n",
    "        \n",
    "        # delete output file if it already exists\n",
    "        try:\n",
    "            os.remove(output_path + symbolFilename + '.csv')\n",
    "        except Exception as e:\n",
    "            #print('e1 : ', e)\n",
    "            pass\n",
    "        \n",
    "        # get 'At The Money' for each group\n",
    "        dfg = df2.groupby(['Date', 'Option_Type'])\n",
    "        for name, group in tqdm(dfg):\n",
    "            # get 'At The Money' for each group\n",
    "            try:\n",
    "                atTheMoney = max(group[(group['Difference'] == group['Min'])]['Strike'])\n",
    "                group['At_The_Money'] = atTheMoney\n",
    "            \n",
    "            except Exception as e:\n",
    "                #print('e3 : ', e)\n",
    "                group['At_The_Money'] = np.nan\n",
    "                \n",
    "            group = group[['Date', 'Ticker', 'OPT_Open', 'OPT_High', 'OPT_Low', 'OPT_Close', 'Volume', 'OPT_OI','EQ_Open',\n",
    "                       'EQ_High','EQ_Low','EQ_Close','Expiry_Date','Strike','Option_Type', 'IV', 'Delta', 'Theta', 'Gamma', 'Vega',\n",
    "                        'At_The_Money']]\n",
    "            \n",
    "            # loop through different delta values\n",
    "            for delta in delta_list:\n",
    "                if delta == 0.50:\n",
    "                    group.rename(columns={'Min' : f'Delta_{delta*100:.0f}_Diff_Min',\n",
    "                                          'Difference' : f'Delta_{delta*100:.0f}_Diff'}, \n",
    "                                 inplace=True)\n",
    "                    group[f'Delta_{delta*100:.0f}_Strike'] = group['At_The_Money']\n",
    "                else:\n",
    "                    if group['Option_Type'].iloc[0] == 'CE':\n",
    "                        group[f'Delta_{delta*100:.0f}_Diff'] = abs(group['Delta'] - delta)\n",
    "                    elif group['Option_Type'].iloc[0] == 'PE':\n",
    "                        group[f'Delta_{delta*100:.0f}_Diff'] = abs(group['Delta'] - (-delta))\n",
    "                    elif group['Option_Type'].iloc[0] == 'XX':\n",
    "                        group[f'Delta_{delta*100:.0f}_Diff'] = np.nan\n",
    "                    group[f'Delta_{delta*100:.0f}_Diff_Min'] = group[f'Delta_{delta*100:.0f}_Diff'].min()        \n",
    "        \n",
    "                    try:\n",
    "                        deltaStrike = max(group[group[f'Delta_{delta*100:.0f}_Diff'] == group[f'Delta_{delta*100:.0f}_Diff_Min']]['Strike'])\n",
    "                        group[f'Delta_{delta*100:.0f}_Strike'] = deltaStrike\n",
    "                    except Exception as e:\n",
    "                        #print('e2 : ', e)\n",
    "                        group[f'Delta_{delta*100:.0f}_Strike'] = np.nan\n",
    "                    # dropping unnecessary columns\n",
    "                    group = group.drop([f'Delta_{delta*100:.0f}_Diff_Min', f'Delta_{delta*100:.0f}_Diff'], axis=1)\n",
    "            # write output to csv\n",
    "            group.to_csv(output_path + symbolFilename + conversion + '.csv', mode='a', header=not os.path.exists(output_path + symbolFilename + conversion + '.csv'), index=False)\n",
    "\n",
    "        \n",
    "    elif conversion != 'E':\n",
    "        def calculate_greeks_vectorized(spot, strike, time_to_expiry, option_price, option_type):\n",
    "            norm_dist = norm.cdf\n",
    "            rate = 0.065\n",
    "            dividend = 0.015\n",
    "            is_call_option = np.where(option_type == 'CE', True, False)\n",
    "            is_put_option = np.where(option_type == 'PE', True, False)\n",
    "            target_option = np.where(is_call_option, option_price, 0)\n",
    "            upper = np.where(is_call_option, 5.0, 0.1)\n",
    "            lower = np.where(is_call_option, 0.0, 0.0)\n",
    "            while np.any((upper - lower) > 0.00001):\n",
    "                d_one = (np.log(spot / strike) + ((rate - dividend + (0.5 * (((upper + lower) / 2) ** 2))) * time_to_expiry)) / (((upper + lower) / 2) * (time_to_expiry ** 0.5))\n",
    "                d_two = d_one - ((upper + lower) / 2) * time_to_expiry ** 0.5\n",
    "                nd_one = norm_dist(d_one)\n",
    "                nd_two = norm_dist(d_two)\n",
    "                call_premium = (np.exp(-dividend * time_to_expiry) * (spot * nd_one)) - (strike * np.exp(-rate * time_to_expiry) * nd_two)\n",
    "                mask = call_premium > target_option\n",
    "                upper = np.where(mask, (upper + lower) / 2, upper)\n",
    "                lower = np.where(mask, lower, (upper + lower) / 2)\n",
    "            calldelta1=np.where(is_call_option,(nd_one) * np.exp(-dividend * time_to_expiry),0)\n",
    "            call_delta=np.where((is_call_option)&(time_to_expiry==0)&(spot > strike), 1.0, calldelta1)\n",
    "            call_iv = np.where(is_call_option, (upper + lower) / 2, 0.0)\n",
    "            ndash_one = 1 / (2 * np.pi) ** 0.5 * (np.exp(-(d_one ** 2) / 2))\n",
    "            call_vega = np.where(is_call_option, spot * ((time_to_expiry ** (1 / 2)) * ndash_one * np.exp(-dividend * time_to_expiry)) / 100, 0.0)\n",
    "            call_gamma = np.where(is_call_option, ((((1 / np.sqrt((2 * np.pi))) * np.exp(((-1 * (d_one ** 2)) / 2))) * np.exp(((-1 * time_to_expiry) * dividend))) / ((spot * call_iv) * np.sqrt(time_to_expiry))), 0.0)\n",
    "            call_theta =np.where(is_call_option,((((-1 * ((((spot * ((1 / np.sqrt((2 * np.pi))) * np.exp(((-1 * (d_one ** 2)) / 2)))) * call_iv) * np.exp(((-1 * time_to_expiry) * dividend))) / (2 * np.sqrt(time_to_expiry)))) + ((dividend * spot) * call_delta)) - (((rate * strike) * np.exp(((-1 * rate) * time_to_expiry))) * norm_dist(d_two)))) / 365,0)\n",
    "            target_option1 = np.where(is_put_option, option_price, 0)\n",
    "            upper1 = np.where(is_put_option, 5.0, 0.1)\n",
    "            lower1 = np.where(is_put_option, 0.0, 0.0)\n",
    "            while np.any((upper1 - lower1) > 0.00001):\n",
    "                d_one1 = (np.log(spot / strike) + ((rate - dividend + (0.5 * (((upper1 + lower1) / 2) ** 2))) * time_to_expiry)) / (((upper1 + lower1) / 2) * (time_to_expiry ** 0.5))\n",
    "                d_two1 = d_one1 - ((upper1 + lower1) / 2) * time_to_expiry ** 0.5\n",
    "                nd_one1 = norm_dist(d_one1)\n",
    "                nd_two1 = norm_dist(d_two1)\n",
    "                put_premium =  np.exp(-rate * time_to_expiry) * strike * (norm_dist(-d_two1)) -np.exp(-dividend * time_to_expiry) *  spot* (norm_dist( -d_one1))\n",
    "                mask1 = put_premium > target_option1\n",
    "                upper1 = np.where(mask1, (upper1 + lower1) / 2, upper1)\n",
    "                lower1 = np.where(mask1, lower1, (upper1 + lower1) / 2)\n",
    "            put_delta1 = np.where(is_put_option, (nd_one1 - 1) * np.exp(-dividend * time_to_expiry), 0.0)\n",
    "            put_delta=np.where((is_put_option)&(time_to_expiry==0)&(spot > strike), 1.0, put_delta1)\n",
    "            put_iv = np.where(is_put_option, (upper1 + lower1) / 2, 0.0)\n",
    "            ndash_one1 = 1 / (2 * np.pi) ** 0.5 * (np.exp(-(d_one1 ** 2) / 2))\n",
    "            put_vega = np.where(is_put_option, spot * ((time_to_expiry ** (1 / 2)) * ndash_one1 * np.exp(-dividend * time_to_expiry)) / 100, 0.0)\n",
    "            put_gamma = np.where(is_put_option, ((((1 / np.sqrt((2 * np.pi))) * np.exp(((-1 * (d_one1 ** 2)) / 2))) * np.exp(((-1 * time_to_expiry) * dividend))) / ((spot * put_iv) * np.sqrt(time_to_expiry))), 0.0)\n",
    "            put_theta =  np.where(is_put_option,(((((-1 * ((((spot * ((1 / np.sqrt((2 * np.pi))) * np.exp(((-1 * d_one1 ** 2) / 2)))) * put_iv) * np.exp(((-1 * time_to_expiry) * dividend)))))/ (2 * np.sqrt(time_to_expiry))) - (((dividend * spot) * norm_dist((-1 * d_one1))) * np.exp(((-1 * time_to_expiry) * dividend)))) + (((rate * strike) * np.exp(((-1 * rate) * time_to_expiry))) * norm_dist((-1 * d_two1))))) / 365,0.0)\n",
    "            iv= np.where(is_call_option,call_iv,put_iv)\n",
    "            delta= np.where(is_call_option,call_delta,put_delta)\n",
    "            gamma= np.where(is_call_option,call_gamma,put_gamma)\n",
    "            theta= np.where(is_call_option,call_theta,put_theta)\n",
    "            vega=np.where(is_call_option,call_vega,put_vega)\n",
    "            return iv, delta, gamma, theta, vega\n",
    "        \n",
    "        time1 = datetime.strptime('15:29:59', '%H:%M:%S').time()\n",
    "        st_g = time.time()\n",
    "        ################## EQUITY DATA\n",
    "        eq_df = pd.read_csv(rf\"C:\\\\users\\\\admin\\\\desktop\\\\{index}_EqData\\\\{index}_{conversion}min.csv\")\n",
    "        eq_df = eq_df.rename(columns={' Time' : 'Time','Open' : 'EQ_Open','High' : 'EQ_High','Low' : 'EQ_Low','Close' : 'EQ_Close'})\n",
    "        eq_df = eq_df[['Date', 'Time', 'EQ_Open', 'EQ_High', 'EQ_Low', 'EQ_Close']]\n",
    "        eq_df['Date'] = pd.to_datetime(eq_df['Date'], format = 'mixed',dayfirst=True)\n",
    "        eq_df['Time'] = pd.to_datetime(eq_df['Time']).dt.time\n",
    "        \n",
    "        ################## OPTIONS DATA\n",
    "        opt_df = pd.read_csv(rf\"C:\\\\users\\\\admin\\\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_Opt_{conversion}min.csv\")\n",
    "        opt_df = opt_df.rename(columns={'date' : 'Date','ticker' : 'Ticker','time' : 'Time','open' : 'Open','high' : 'High','low' : 'Low','close' : 'Close','volume' : 'Volume','Open Int' : 'OpenInterest'})\n",
    "        opt_df = opt_df.rename(columns={'Open' : 'Adj_Open','High' : 'Adj_High','Low' : 'Adj_Low','Close' : 'Adj_Close'})\n",
    "        opt_df['Date'] = pd.to_datetime(opt_df['Date'], dayfirst=True , format = '%Y-%m-%d')\n",
    "        opt_df['Year'] = opt_df['Date'].dt.year\n",
    "        opt_df = opt_df.drop(['Year'], axis=1)\n",
    "        opt_df['Time'] = pd.to_datetime(opt_df['Time']).dt.time\n",
    "        opt_df = opt_df[opt_df['Time'] <= time1]\n",
    "        opt_df = opt_df.merge(eq_df, on=['Date', 'Time'], how='left')\n",
    "        ################# EXPIRY SHEET\n",
    "        if index != 'FinNifty':\n",
    "            engine = pg.connect(\"dbname='ExpiryDates' user='postgres' host='swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com' port='5432' password='swancap123'\")\n",
    "            exp_df = pd.read_sql(f'select * from \"public\".\"{schema[:schema.find(\"y\")+1]}Expiry\"', con=engine)\n",
    "            engine.close()\n",
    "        elif index == 'FinNifty':\n",
    "            engine = pg.connect(\"dbname='ExpiryDates' user='postgres' host='swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com' port='5432' password='swancap123'\")\n",
    "            exp_df = pd.read_sql(f'select * from \"public\".\"{index}{schema[:schema.find(\"y\")+1]}Expiry\"', con=engine)\n",
    "            engine.close()\n",
    "        exp_df['Date'] = pd.to_datetime(exp_df['Date'], format='mixed',dayfirst=True)\n",
    "        if schema[schema.find('y')+1:] == 'I':\n",
    "            opt_df = opt_df.merge(exp_df[['Date', 'E1']], on=['Date'], how='left')\n",
    "            opt_df = opt_df.rename(columns={'E1' : 'Expiry_Date'})\n",
    "        elif schema[schema.find('y')+1:] == 'II':\n",
    "            opt_df = opt_df.merge(exp_df[['Date', 'E2']], on=['Date'], how='left')\n",
    "            opt_df = opt_df.rename(columns={'E2' : 'Expiry_Date'})\n",
    "        elif schema[schema.find('y')+1:] == 'III':\n",
    "            opt_df = opt_df.merge(exp_df[['Date', 'E3']], on=['Date'], how='left')\n",
    "            opt_df = opt_df.rename(columns={'E3' : 'Expiry_Date'})\n",
    "        opt_df['Date'] = opt_df['Date'].astype(str)\n",
    "        opt_df['Time'] = opt_df['Time'].astype(str)\n",
    "        opt_df['Expiry_Date'] = opt_df['Expiry_Date'].astype(str)\n",
    "        opt_df['Datetime'] = pd.to_datetime(opt_df['Date'] + ' ' + opt_df['Time'], dayfirst=True,format = '%Y-%m-%d %H:%M:%S')\n",
    "        opt_df['Expiry_Datetime'] = pd.to_datetime(opt_df['Expiry_Date'] + ' ' + '15:30:00', dayfirst=True)\n",
    "        opt_df['MTE'] = opt_df['Expiry_Datetime'] - opt_df['Datetime']\n",
    "        opt_df['MTE'] = opt_df['MTE'].dt.total_seconds()/60\n",
    "        opt_df['MTE'] = opt_df['MTE']/(365 * 24 * 60)\n",
    "        opt_df['Final_strike'] = opt_df['Ticker'].str.replace(f'{index.upper()}{schema[:schema.find(\"y\")+1].upper()}-{schema[schema.find(\"y\")+1:]}',\"\").str[:-2].astype(int)\n",
    "        opt_df['Option_Type'] = opt_df['Ticker'].str[-2:]\n",
    "        \n",
    "        greeks=calculate_greeks_vectorized(opt_df['EQ_Close'], opt_df['Final_strike'], opt_df['MTE'], opt_df['Adj_Close'], opt_df['Option_Type'])\n",
    "        opt_df['IV'], opt_df['Delta'], opt_df['Gamma'], opt_df['Theta'], opt_df['Vega'] = greeks[0], greeks[1], greeks[2], greeks[3], greeks[4]\n",
    "        opt_df = opt_df.sort_values(by=['Date', 'Time', 'Option_Type', 'Final_strike'])\n",
    "        opt_df.rename(columns={'Adj_Open':'Open','Adj_High':'High','Adj_Low':'Low','Adj_Close':'Close'},inplace=True)\n",
    "        opt_df = opt_df[['Ticker','Date', 'Time', 'Open','High','Low','Close','Volume','Open_Interest','EQ_Open','EQ_High','EQ_Low','EQ_Close','Expiry_Date','IV', 'Delta', 'Gamma', 'Theta', 'Vega',\"Option_Type\",'Final_strike']]\n",
    "        opt_df=opt_df.reset_index(drop=True)\n",
    "        opt_df.to_csv(rf'C:\\\\users\\\\admin\\\\desktop\\\\{index}_{schema}_Greeks_{conversion}min.csv',index=False)\n",
    "        print(\"\\nGreeks Generated!\")\n",
    "        et_g = time.time()\n",
    "        print(\"Time taken to generate greeks\",et_g-st_g)\n",
    "        \n",
    "        opt_df = opt_df.sort_values(by=['Date', 'Time', 'Option_Type', 'Final_strike']).reset_index(drop=True)\n",
    "        output_path = r\"C:\\\\users\\\\admin\\\\desktop\\\\\"\n",
    "        delta_list = [0.05, 0.10, 0.15, 0.20, 0.25,\n",
    "                      0.30, 0.35, 0.40, 0.45, 0.50, \n",
    "                      0.55, 0.60, 0.65, 0.70, 0.75,\n",
    "                      0.80, 0.85, 0.90, 0.95]\n",
    "        # delta_list = [0.50]\n",
    "        \n",
    "        print('Start time : ', datetime.now())\n",
    "        # change date column to datetime format\n",
    "        \n",
    "        opt_df['Old_Delta'] = opt_df['Delta'].copy()\n",
    "        if opt_df['Delta'].dtype == object:\n",
    "            print('Delta column is in string format.')\n",
    "            opt_df['Delta'] = opt_df['Delta'].str.replace('\\(|\\)', '')\n",
    "            opt_df['Delta'] = opt_df['Delta'].str.replace('\\+0j', '')\n",
    "            opt_df['Delta'] = opt_df['Delta'].str.replace('0j', '0')\n",
    "            opt_df['Delta'] = opt_df['Delta'].astype(float)\n",
    "        \n",
    "        opt_df.rename(columns={\n",
    "                           'Open' : 'OPT_Open',\n",
    "                           'High' : 'OPT_High',\n",
    "                           'Low' : 'OPT_Low',\n",
    "                           'Close' : 'OPT_Close',\n",
    "                           # 'Volume' : 'OPT_Contracts',\n",
    "                           'Open_Interest' : 'OPT_OI',\n",
    "                           'Final_strike' : 'Strike'\n",
    "                                                }, inplace=True)\n",
    "        # extract Strike and Option Type from the Ticker if it's not there in the input file already.\n",
    "        \n",
    "        #     df['Strike'] = df['Ticker'].str.extract('([0-9]+[./]*[0-9]*)').astype(float)\n",
    "        \n",
    "        #     df['Option_Type'] = df[\"Ticker\"].str.split('-').str[0].str[-2:]\n",
    "        \n",
    "        #     df['Option_Type'] = np.where((df['Option_Type'] == 'CE') | (df['Option_Type'] == 'PE'),\n",
    "        #                                  df['Option_Type'], 'XX')\n",
    "        # get the symbol from filename\n",
    "        symbolFilename = index.upper()+schema.upper()\n",
    "        print('symbolFilename :', symbolFilename)\n",
    "        \n",
    "        # remove '-I'/'-II'/'-III' from filename\n",
    "        symbol = symbolFilename.replace('-III', '').replace('III','')\n",
    "        symbol = symbol.replace('-II', '').replace('II', '')\n",
    "        symbol = symbol.replace('-I', '').replace('I', '')\n",
    "        print('symbol :', symbol)\n",
    "        \n",
    "        # substitute any special characters ('-', '&', '_') in Dispersion file names with empty string ('_')\n",
    "        charactersDroppedSymbol = re.sub('\\ |\\_|\\.|\\-|\\&|\\;|\\:', '', symbol)\n",
    "        \n",
    "        df2 = opt_df.copy()\n",
    "        df2['Date'] = pd.to_datetime(df2['Date'],format='mixed',dayfirst=True)\n",
    "        # calculate difference between 'EQ_Close' and 'Strike' and get the minimum difference for a group\n",
    "        if schema[schema.find('y')+1:] == 'I':\n",
    "            df2 = df2.merge(exp_df[['Date', 'E1']], on=['Date'], how='left')\n",
    "            df2 = df2.rename(columns={'E1' : 'Expiry_Date'})\n",
    "        elif schema[schema.find('y')+1:] == 'II':\n",
    "            df2 = df2.merge(exp_df[['Date', 'E2']], on=['Date'], how='left')\n",
    "            df2 = df2.rename(columns={'E2' : 'Expiry_Date'})\n",
    "        elif schema[schema.find('y')+1:] == 'III':\n",
    "            df2 = df2.merge(exp_df[['Date', 'E3']], on=['Date'], how='left')\n",
    "            df2 = df2.rename(columns={'E3' : 'Expiry_Date'})\n",
    "        df2['Difference'] = abs(df2['EQ_Close'] - df2['Strike'].astype(float))\n",
    "        dfg = df2.groupby(['Date', 'Time', 'Option_Type'])['Difference']\n",
    "        df2['Min'] = dfg.transform('min')\n",
    "        \n",
    "        # delete output file if it already exists\n",
    "        try:\n",
    "            os.remove(output_path + symbolFilename + '.csv')\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "        # get 'At The Money' for each group\n",
    "        dfg = df2.groupby(['Date', 'Time', 'Option_Type'])\n",
    "        for name, group in tqdm(dfg):\n",
    "            # get 'At The Money' for each group\n",
    "            try:\n",
    "                atTheMoney = max(group[(group['Difference'] == group['Min'])]['Strike'])\n",
    "                group['At_The_Money'] = atTheMoney\n",
    "            \n",
    "            except Exception as e:\n",
    "                group['At_The_Money'] = np.nan\n",
    "            \n",
    "            group = group[['Date', 'Time', 'Ticker', 'OPT_Open', 'OPT_High', 'OPT_Low', 'OPT_Close', 'Volume', 'OPT_OI','EQ_Open',\n",
    "                       'EQ_High','EQ_Low','EQ_Close', 'Expiry_Date','Strike', 'Option_Type', 'IV', 'Delta', 'Theta', 'Gamma', 'Vega',  \n",
    "                        'At_The_Money']]  \n",
    "            # loop through different delta values\n",
    "            for delta in delta_list:\n",
    "                \n",
    "                if delta == 0.50:\n",
    "                    group.rename(columns={'Min' : f'Delta_{delta*100:.0f}_Diff_Min',\n",
    "                                          'Difference' : f'Delta_{delta*100:.0f}_Diff'}, \n",
    "                                 inplace=True)\n",
    "                    group[f'Delta_{delta*100:.0f}_Strike'] = group['At_The_Money']\n",
    "                else:\n",
    "                    try:\n",
    "                        if group['Option_Type'].iloc[0] == 'CE':\n",
    "                            group[f'Delta_{delta*100:.0f}_Diff'] = abs(group['Delta'] - delta)\n",
    "                        elif group['Option_Type'].iloc[0] == 'PE':\n",
    "                            group[f'Delta_{delta*100:.0f}_Diff'] = abs(group['Delta'] - (-delta))\n",
    "                        elif group['Option_Type'].iloc[0] == 'XX':\n",
    "                            group[f'Delta_{delta*100:.0f}_Diff'] = np.nan\n",
    "        \n",
    "                        group[f'Delta_{delta*100:.0f}_Diff_Min'] = group[f'Delta_{delta*100:.0f}_Diff'].min()        \n",
    "        \n",
    "                        try:\n",
    "                            deltaStrike = max(group[group[f'Delta_{delta*100:.0f}_Diff'] == group[f'Delta_{delta*100:.0f}_Diff_Min']]['Strike'])\n",
    "                            group[f'Delta_{delta*100:.0f}_Strike'] = deltaStrike\n",
    "                        except Exception as e:\n",
    "                            group[f'Delta_{delta*100:.0f}_Strike'] = np.nan\n",
    "                        # dropping unnecessary columns\n",
    "                        group = group.drop([f'Delta_{delta*100:.0f}_Diff_Min', f'Delta_{delta*100:.0f}_Diff'], axis=1)\n",
    "                        \n",
    "                    except Exception as e1:\n",
    "                        print('e1 : ', e1)\n",
    "            # write output to csv\n",
    "            group.to_csv(output_path + symbolFilename + '.csv', mode='a', header=not os.path.exists(output_path + symbolFilename + '.csv'), index=False)\n",
    "        \n",
    "        del opt_df,eq_df\n",
    "        \n",
    "end_time = time.time()\n",
    "print(\"\\nCOMPLETED.\")\n",
    "print(\"Total time taken \",end_time-start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c29102ea-31e0-4ed4-a240-986ee50ec8e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open_Interest</th>\n",
       "      <th>EQ_Open</th>\n",
       "      <th>...</th>\n",
       "      <th>EQ_Low</th>\n",
       "      <th>EQ_Close</th>\n",
       "      <th>Expiry_Date</th>\n",
       "      <th>IV</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Vega</th>\n",
       "      <th>Option_Type</th>\n",
       "      <th>Final_strike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BANKNIFTYMONTHLY-III43000CE</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>09:15:00</td>\n",
       "      <td>1715.80</td>\n",
       "      <td>1715.80</td>\n",
       "      <td>1663.60</td>\n",
       "      <td>1663.60</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>43079.1016</td>\n",
       "      <td>...</td>\n",
       "      <td>43025.25</td>\n",
       "      <td>43030.0508</td>\n",
       "      <td>2023-03-29</td>\n",
       "      <td>0.167108</td>\n",
       "      <td>0.575133</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>-10.997512</td>\n",
       "      <td>81.596679</td>\n",
       "      <td>CE</td>\n",
       "      <td>43000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BANKNIFTYMONTHLY-III43500CE</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>09:15:00</td>\n",
       "      <td>1376.95</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>1376.95</td>\n",
       "      <td>1380.00</td>\n",
       "      <td>150.0</td>\n",
       "      <td>15950.0</td>\n",
       "      <td>43079.1016</td>\n",
       "      <td>...</td>\n",
       "      <td>43025.25</td>\n",
       "      <td>43030.0508</td>\n",
       "      <td>2023-03-29</td>\n",
       "      <td>0.163598</td>\n",
       "      <td>0.518800</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>-10.687429</td>\n",
       "      <td>83.046214</td>\n",
       "      <td>CE</td>\n",
       "      <td>43500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BANKNIFTYMONTHLY-III45000CE</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>09:15:00</td>\n",
       "      <td>707.50</td>\n",
       "      <td>707.55</td>\n",
       "      <td>707.50</td>\n",
       "      <td>707.55</td>\n",
       "      <td>75.0</td>\n",
       "      <td>29100.0</td>\n",
       "      <td>43079.1016</td>\n",
       "      <td>...</td>\n",
       "      <td>43025.25</td>\n",
       "      <td>43030.0508</td>\n",
       "      <td>2023-03-29</td>\n",
       "      <td>0.153985</td>\n",
       "      <td>0.342373</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>-8.736389</td>\n",
       "      <td>76.681365</td>\n",
       "      <td>CE</td>\n",
       "      <td>45000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANKNIFTYMONTHLY-III48000CE</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>09:15:00</td>\n",
       "      <td>141.20</td>\n",
       "      <td>149.85</td>\n",
       "      <td>141.20</td>\n",
       "      <td>143.60</td>\n",
       "      <td>100.0</td>\n",
       "      <td>28550.0</td>\n",
       "      <td>43079.1016</td>\n",
       "      <td>...</td>\n",
       "      <td>43025.25</td>\n",
       "      <td>43030.0508</td>\n",
       "      <td>2023-03-29</td>\n",
       "      <td>0.151534</td>\n",
       "      <td>0.098775</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>-3.749274</td>\n",
       "      <td>36.347715</td>\n",
       "      <td>CE</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BANKNIFTYMONTHLY-III36000PE</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>09:15:00</td>\n",
       "      <td>63.00</td>\n",
       "      <td>63.00</td>\n",
       "      <td>63.00</td>\n",
       "      <td>63.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6575.0</td>\n",
       "      <td>43079.1016</td>\n",
       "      <td>...</td>\n",
       "      <td>43025.25</td>\n",
       "      <td>43030.0508</td>\n",
       "      <td>2023-03-29</td>\n",
       "      <td>0.220141</td>\n",
       "      <td>-0.033449</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-1.777477</td>\n",
       "      <td>15.562829</td>\n",
       "      <td>PE</td>\n",
       "      <td>36000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118336</th>\n",
       "      <td>BANKNIFTYMONTHLY-III51000CE</td>\n",
       "      <td>2023-08-09</td>\n",
       "      <td>15:25:00</td>\n",
       "      <td>68.00</td>\n",
       "      <td>68.00</td>\n",
       "      <td>68.00</td>\n",
       "      <td>68.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>44880.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>44822.35</td>\n",
       "      <td>44878.6000</td>\n",
       "      <td>2023-10-26</td>\n",
       "      <td>0.152955</td>\n",
       "      <td>0.052256</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-2.480552</td>\n",
       "      <td>22.147340</td>\n",
       "      <td>CE</td>\n",
       "      <td>51000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118337</th>\n",
       "      <td>BANKNIFTYMONTHLY-III42000PE</td>\n",
       "      <td>2023-08-09</td>\n",
       "      <td>15:25:00</td>\n",
       "      <td>162.95</td>\n",
       "      <td>163.00</td>\n",
       "      <td>161.00</td>\n",
       "      <td>163.00</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>3975.0</td>\n",
       "      <td>44880.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>44822.35</td>\n",
       "      <td>44878.6000</td>\n",
       "      <td>2023-10-26</td>\n",
       "      <td>0.140843</td>\n",
       "      <td>-0.111867</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>-2.844638</td>\n",
       "      <td>39.448226</td>\n",
       "      <td>PE</td>\n",
       "      <td>42000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118338</th>\n",
       "      <td>BANKNIFTYMONTHLY-III43500PE</td>\n",
       "      <td>2023-08-09</td>\n",
       "      <td>15:25:00</td>\n",
       "      <td>355.95</td>\n",
       "      <td>355.95</td>\n",
       "      <td>355.00</td>\n",
       "      <td>355.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2895.0</td>\n",
       "      <td>44880.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>44822.35</td>\n",
       "      <td>44878.6000</td>\n",
       "      <td>2023-10-26</td>\n",
       "      <td>0.126348</td>\n",
       "      <td>-0.227017</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-3.598797</td>\n",
       "      <td>62.449338</td>\n",
       "      <td>PE</td>\n",
       "      <td>43500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118339</th>\n",
       "      <td>BANKNIFTYMONTHLY-III44000PE</td>\n",
       "      <td>2023-08-09</td>\n",
       "      <td>15:25:00</td>\n",
       "      <td>497.65</td>\n",
       "      <td>497.65</td>\n",
       "      <td>495.00</td>\n",
       "      <td>495.00</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6045.0</td>\n",
       "      <td>44880.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>44822.35</td>\n",
       "      <td>44878.6000</td>\n",
       "      <td>2023-10-26</td>\n",
       "      <td>0.126758</td>\n",
       "      <td>-0.290544</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>-3.891092</td>\n",
       "      <td>70.958034</td>\n",
       "      <td>PE</td>\n",
       "      <td>44000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118340</th>\n",
       "      <td>BANKNIFTYMONTHLY-III45000PE</td>\n",
       "      <td>2023-08-09</td>\n",
       "      <td>15:25:00</td>\n",
       "      <td>815.00</td>\n",
       "      <td>822.00</td>\n",
       "      <td>815.00</td>\n",
       "      <td>822.00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2340.0</td>\n",
       "      <td>44880.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>44822.35</td>\n",
       "      <td>44878.6000</td>\n",
       "      <td>2023-10-26</td>\n",
       "      <td>0.120454</td>\n",
       "      <td>-0.430644</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>-3.483505</td>\n",
       "      <td>81.302136</td>\n",
       "      <td>PE</td>\n",
       "      <td>45000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118341 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Ticker        Date      Time     Open     High  \\\n",
       "0       BANKNIFTYMONTHLY-III43000CE  2023-01-02  09:15:00  1715.80  1715.80   \n",
       "1       BANKNIFTYMONTHLY-III43500CE  2023-01-02  09:15:00  1376.95  1500.00   \n",
       "2       BANKNIFTYMONTHLY-III45000CE  2023-01-02  09:15:00   707.50   707.55   \n",
       "3       BANKNIFTYMONTHLY-III48000CE  2023-01-02  09:15:00   141.20   149.85   \n",
       "4       BANKNIFTYMONTHLY-III36000PE  2023-01-02  09:15:00    63.00    63.00   \n",
       "...                             ...         ...       ...      ...      ...   \n",
       "118336  BANKNIFTYMONTHLY-III51000CE  2023-08-09  15:25:00    68.00    68.00   \n",
       "118337  BANKNIFTYMONTHLY-III42000PE  2023-08-09  15:25:00   162.95   163.00   \n",
       "118338  BANKNIFTYMONTHLY-III43500PE  2023-08-09  15:25:00   355.95   355.95   \n",
       "118339  BANKNIFTYMONTHLY-III44000PE  2023-08-09  15:25:00   497.65   497.65   \n",
       "118340  BANKNIFTYMONTHLY-III45000PE  2023-08-09  15:25:00   815.00   822.00   \n",
       "\n",
       "            Low    Close  Volume  Open_Interest     EQ_Open  ...    EQ_Low  \\\n",
       "0       1663.60  1663.60    75.0         1025.0  43079.1016  ...  43025.25   \n",
       "1       1376.95  1380.00   150.0        15950.0  43079.1016  ...  43025.25   \n",
       "2        707.50   707.55    75.0        29100.0  43079.1016  ...  43025.25   \n",
       "3        141.20   143.60   100.0        28550.0  43079.1016  ...  43025.25   \n",
       "4         63.00    63.00    25.0         6575.0  43079.1016  ...  43025.25   \n",
       "...         ...      ...     ...            ...         ...  ...       ...   \n",
       "118336    68.00    68.00    15.0           90.0  44880.0500  ...  44822.35   \n",
       "118337   161.00   163.00  1185.0         3975.0  44880.0500  ...  44822.35   \n",
       "118338   355.00   355.00    30.0         2895.0  44880.0500  ...  44822.35   \n",
       "118339   495.00   495.00   105.0         6045.0  44880.0500  ...  44822.35   \n",
       "118340   815.00   822.00    90.0         2340.0  44880.0500  ...  44822.35   \n",
       "\n",
       "          EQ_Close  Expiry_Date        IV     Delta     Gamma      Theta  \\\n",
       "0       43030.0508   2023-03-29  0.167108  0.575133  0.000112 -10.997512   \n",
       "1       43030.0508   2023-03-29  0.163598  0.518800  0.000116 -10.687429   \n",
       "2       43030.0508   2023-03-29  0.153985  0.342373  0.000114  -8.736389   \n",
       "3       43030.0508   2023-03-29  0.151534  0.098775  0.000055  -3.749274   \n",
       "4       43030.0508   2023-03-29  0.220141 -0.033449  0.000016  -1.777477   \n",
       "...            ...          ...       ...       ...       ...        ...   \n",
       "118336  44878.6000   2023-10-26  0.152955  0.052256  0.000034  -2.480552   \n",
       "118337  44878.6000   2023-10-26  0.140843 -0.111867  0.000065  -2.844638   \n",
       "118338  44878.6000   2023-10-26  0.126348 -0.227017  0.000115  -3.598797   \n",
       "118339  44878.6000   2023-10-26  0.126758 -0.290544  0.000130  -3.891092   \n",
       "118340  44878.6000   2023-10-26  0.120454 -0.430644  0.000157  -3.483505   \n",
       "\n",
       "             Vega  Option_Type Final_strike  \n",
       "0       81.596679           CE        43000  \n",
       "1       83.046214           CE        43500  \n",
       "2       76.681365           CE        45000  \n",
       "3       36.347715           CE        48000  \n",
       "4       15.562829           PE        36000  \n",
       "...           ...          ...          ...  \n",
       "118336  22.147340           CE        51000  \n",
       "118337  39.448226           PE        42000  \n",
       "118338  62.449338           PE        43500  \n",
       "118339  70.958034           PE        44000  \n",
       "118340  81.302136           PE        45000  \n",
       "\n",
       "[118341 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time :  2023-08-10 13:01:44.781637\n",
      "symbolFilename : BANKNIFTYMONTHLYIII\n",
      "symbol : BANKNFTYMONTHLY\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abe61f56b834fca96a8622d9efacdff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20471 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "index = 'BankNifty'\n",
    "conversion = '5'\n",
    "schema = 'MonthlyIII'\n",
    "eq_df = pd.read_csv(rf\"C:\\\\users\\\\admin\\\\desktop\\\\{index}_EqData\\\\{index}_{conversion}min.csv\")\n",
    "eq_df = eq_df.rename(columns={' Time' : 'Time','Open' : 'EQ_Open','High' : 'EQ_High','Low' : 'EQ_Low','Close' : 'EQ_Close'})\n",
    "eq_df = eq_df[['Date', 'Time', 'EQ_Open', 'EQ_High', 'EQ_Low', 'EQ_Close']]\n",
    "eq_df['Date'] = pd.to_datetime(eq_df['Date'], format = 'mixed',dayfirst=True)\n",
    "eq_df['Time'] = pd.to_datetime(eq_df['Time']).dt.time\n",
    "################## OPTIONS DATA\n",
    "opt_df = pd.read_csv(rf\"C:\\\\users\\\\admin\\\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_Opt_{conversion}min.csv\")\n",
    "opt_df = opt_df.rename(columns={'date' : 'Date','ticker' : 'Ticker','time' : 'Time','open' : 'Open','high' : 'High','low' : 'Low','close' : 'Close','volume' : 'Volume','Open Int' : 'OpenInterest'})\n",
    "opt_df = opt_df.rename(columns={'Open' : 'Adj_Open','High' : 'Adj_High','Low' : 'Adj_Low','Close' : 'Adj_Close'})\n",
    "opt_df['Date'] = pd.to_datetime(opt_df['Date'], dayfirst=True , format = '%Y-%m-%d')\n",
    "opt_df['Year'] = opt_df['Date'].dt.year\n",
    "opt_df = opt_df.drop(['Year'], axis=1)\n",
    "opt_df['Time'] = pd.to_datetime(opt_df['Time']).dt.time\n",
    "opt_df = opt_df[opt_df['Time'] <= time1]\n",
    "opt_df = opt_df.merge(eq_df, on=['Date', 'Time'], how='left')\n",
    "# display(opt_df)\n",
    "########### EXPIRY DATA\n",
    "if index != 'FinNifty':\n",
    "    engine = pg.connect(\"dbname='ExpiryDates' user='postgres' host='swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com' port='5432' password='swancap123'\")\n",
    "    exp_df = pd.read_sql(f'select * from \"public\".\"{schema[:schema.find(\"y\")+1]}Expiry\"', con=engine)\n",
    "    engine.close()\n",
    "elif index == 'FinNifty':\n",
    "    engine = pg.connect(\"dbname='ExpiryDates' user='postgres' host='swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com' port='5432' password='swancap123'\")\n",
    "    exp_df = pd.read_sql(f'select * from \"public\".\"{index}{schema[:schema.find(\"y\")+1]}Expiry\"', con=engine)\n",
    "    engine.close()\n",
    "exp_df['Date'] = pd.to_datetime(exp_df['Date'], format='mixed',dayfirst=True)\n",
    "if schema[schema.find('y')+1:] == 'I':\n",
    "    opt_df = opt_df.merge(exp_df[['Date', 'E1']], on=['Date'], how='left')\n",
    "    opt_df = opt_df.rename(columns={'E1' : 'Expiry_Date'})\n",
    "elif schema[schema.find('y')+1:] == 'II':\n",
    "    opt_df = opt_df.merge(exp_df[['Date', 'E2']], on=['Date'], how='left')\n",
    "    opt_df = opt_df.rename(columns={'E2' : 'Expiry_Date'})\n",
    "elif schema[schema.find('y')+1:] == 'III':\n",
    "    opt_df = opt_df.merge(exp_df[['Date', 'E3']], on=['Date'], how='left')\n",
    "    opt_df = opt_df.rename(columns={'E3' : 'Expiry_Date'})\n",
    "# opt_df = opt_df.merge(exp_df[['Date', 'far_exp']], on=['Date'], how='left')\n",
    "opt_df['Date'] = opt_df['Date'].astype(str)\n",
    "opt_df['Time'] = opt_df['Time'].astype(str)\n",
    "opt_df['Expiry_Date'] = opt_df['Expiry_Date'].astype(str)\n",
    "opt_df['Datetime'] = pd.to_datetime(opt_df['Date'] + ' ' + opt_df['Time'], dayfirst=True,format = '%Y-%m-%d %H:%M:%S')\n",
    "opt_df['Expiry_Datetime'] = pd.to_datetime(opt_df['Expiry_Date'] + ' ' + '15:30:00', dayfirst=True)\n",
    "opt_df['MTE'] = opt_df['Expiry_Datetime'] - opt_df['Datetime']\n",
    "opt_df['MTE'] = opt_df['MTE'].dt.total_seconds()/60\n",
    "opt_df['MTE'] = opt_df['MTE']/(365 * 24 * 60)\n",
    "opt_df['Final_strike'] = opt_df['Ticker'].str.replace(f'{index.upper()}{schema[:schema.find(\"y\")+1].upper()}-{schema[schema.find(\"y\")+1:]}',\"\").str[:-2].astype(int)\n",
    "opt_df['Option_Type'] = opt_df['Ticker'].str[-2:]\n",
    "\n",
    "greeks=calculate_greeks_vectorized(opt_df['EQ_Close'], opt_df['Final_strike'], opt_df['MTE'], opt_df['Adj_Close'], opt_df['Option_Type'])\n",
    "#df = df.drop(['Delta'], axis=1)\n",
    "opt_df['IV'], opt_df['Delta'], opt_df['Gamma'], opt_df['Theta'], opt_df['Vega'] = greeks[0], greeks[1], greeks[2], greeks[3], greeks[4]\n",
    "opt_df = opt_df.sort_values(by=['Date', 'Time', 'Option_Type', 'Final_strike'])\n",
    "opt_df.rename(columns={'Adj_Open':'Open','Adj_High':'High','Adj_Low':'Low','Adj_Close':'Close'},inplace=True)\n",
    "opt_df = opt_df[['Ticker','Date', 'Time', 'Open','High','Low','Close','Volume','Open_Interest','EQ_Open','EQ_High','EQ_Low','EQ_Close','Expiry_Date','IV', 'Delta', 'Gamma', 'Theta', 'Vega',\"Option_Type\",'Final_strike']]\n",
    "opt_df=opt_df.reset_index(drop=True)\n",
    "opt_df.to_csv(r'C:\\\\users\\\\admin\\\\desktop\\\\greekstest.csv',index=False)\n",
    "display(opt_df)\n",
    "\n",
    "opt_df = opt_df.sort_values(by=['Date', 'Time', 'Option_Type', 'Final_strike']).reset_index(drop=True)\n",
    "output_path = r\"C:\\\\users\\\\admin\\\\desktop\\\\\"\n",
    "delta_list = [0.05, 0.10, 0.15, 0.20, 0.25,\n",
    "              0.30, 0.35, 0.40, 0.45, 0.50, \n",
    "              0.55, 0.60, 0.65, 0.70, 0.75,\n",
    "              0.80, 0.85, 0.90, 0.95]\n",
    "# delta_list = [0.50]\n",
    "\n",
    "print('Start time : ', datetime.now())\n",
    "# change date column to datetime format\n",
    "\n",
    "opt_df['Old_Delta'] = opt_df['Delta'].copy()\n",
    "if opt_df['Delta'].dtype == object:\n",
    "    print('Delta column is in string format.')\n",
    "    opt_df['Delta'] = opt_df['Delta'].str.replace('\\(|\\)', '')\n",
    "    opt_df['Delta'] = opt_df['Delta'].str.replace('\\+0j', '')\n",
    "    opt_df['Delta'] = opt_df['Delta'].str.replace('0j', '0')\n",
    "    opt_df['Delta'] = opt_df['Delta'].astype(float)\n",
    "\n",
    "opt_df.rename(columns={\n",
    "                   'Open' : 'OPT_Open',\n",
    "                   'High' : 'OPT_High',\n",
    "                   'Low' : 'OPT_Low',\n",
    "                   'Close' : 'OPT_Close',\n",
    "                   'Volume' : 'OPT_Contracts',\n",
    "                   'Open_Interest' : 'OPT_OI',\n",
    "                   'Final_strike' : 'Strike'\n",
    "                                        }, inplace=True)\n",
    "# extract Strike and Option Type from the Ticker if it's not there in the input file already.\n",
    "\n",
    "#     df['Strike'] = df['Ticker'].str.extract('([0-9]+[./]*[0-9]*)').astype(float)\n",
    "\n",
    "#     df['Option_Type'] = df[\"Ticker\"].str.split('-').str[0].str[-2:]\n",
    "\n",
    "#     df['Option_Type'] = np.where((df['Option_Type'] == 'CE') | (df['Option_Type'] == 'PE'),\n",
    "#                                  df['Option_Type'], 'XX')\n",
    "# get the symbol from filename\n",
    "symbolFilename = index.upper()+schema.upper()\n",
    "print('symbolFilename :', symbolFilename)\n",
    "\n",
    "# remove '-I'/'-II'/'-III' from filename\n",
    "symbol = symbolFilename.replace('-III', '').replace('III','')\n",
    "symbol = symbol.replace('-II', '').replace('II', '')\n",
    "symbol = symbol.replace('-I', '').replace('I', '')\n",
    "print('symbol :', symbol)\n",
    "\n",
    "# substitute any special characters ('-', '&', '_') in Dispersion file names with empty string ('_')\n",
    "charactersDroppedSymbol = re.sub('\\ |\\_|\\.|\\-|\\&|\\;|\\:', '', symbol)\n",
    "\n",
    "df2 = opt_df.copy()\n",
    "df2['Date'] = pd.to_datetime(df2['Date'],format='mixed',dayfirst=True)\n",
    "# calculate difference between 'EQ_Close' and 'Strike' and get the minimum difference for a group\n",
    "if schema[schema.find('y')+1:] == 'I':\n",
    "    df2 = df2.merge(exp_df[['Date', 'E1']], on=['Date'], how='left')\n",
    "    df2 = df2.rename(columns={'E1' : 'Expiry_Date'})\n",
    "elif schema[schema.find('y')+1:] == 'II':\n",
    "    df2 = df2.merge(exp_df[['Date', 'E2']], on=['Date'], how='left')\n",
    "    df2 = df2.rename(columns={'E2' : 'Expiry_Date'})\n",
    "elif schema[schema.find('y')+1:] == 'III':\n",
    "    df2 = df2.merge(exp_df[['Date', 'E3']], on=['Date'], how='left')\n",
    "    df2 = df2.rename(columns={'E3' : 'Expiry_Date'})\n",
    "df2['Difference'] = abs(df2['EQ_Close'] - df2['Strike'].astype(float))\n",
    "dfg = df2.groupby(['Date', 'Time', 'Option_Type'])['Difference']\n",
    "df2['Min'] = dfg.transform('min')\n",
    "\n",
    "# delete output file if it already exists\n",
    "try:\n",
    "    os.remove(output_path + symbolFilename + '.csv')\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "# get 'At The Money' for each group\n",
    "dfg = df2.groupby(['Date', 'Time', 'Option_Type'])\n",
    "for name, group in tqdm(dfg):\n",
    "    # get 'At The Money' for each group\n",
    "    try:\n",
    "        atTheMoney = max(group[(group['Difference'] == group['Min'])]['Strike'])\n",
    "        group['At_The_Money'] = atTheMoney\n",
    "    \n",
    "    except Exception as e:\n",
    "        #print('e3 : ', e)\n",
    "        group['At_The_Money'] = np.nan\n",
    "    \n",
    "    group = group[['Date', 'Time', 'Ticker', 'OPT_Open', 'OPT_High', 'OPT_Low', 'OPT_Close', 'OPT_Contracts', 'OPT_OI',\n",
    "               'Strike', 'Option_Type', 'Expiry_Date', 'IV', 'Delta', 'Theta', 'Gamma', 'Vega', 'EQ_Open', \n",
    "               'EQ_High', 'EQ_Low', 'EQ_Close', 'At_The_Money']]  \n",
    "    # loop through different delta values\n",
    "    for delta in delta_list:\n",
    "        \n",
    "        if delta == 0.50:\n",
    "            group.rename(columns={'Min' : f'Delta_{delta*100:.0f}_Diff_Min',\n",
    "                                  'Difference' : f'Delta_{delta*100:.0f}_Diff'}, \n",
    "                         inplace=True)\n",
    "            group[f'Delta_{delta*100:.0f}_Strike'] = group['At_The_Money']\n",
    "        else:\n",
    "            try:\n",
    "                if group['Option_Type'].iloc[0] == 'CE':\n",
    "                    group[f'Delta_{delta*100:.0f}_Diff'] = abs(group['Delta'] - delta)\n",
    "                elif group['Option_Type'].iloc[0] == 'PE':\n",
    "                    group[f'Delta_{delta*100:.0f}_Diff'] = abs(group['Delta'] - (-delta))\n",
    "                elif group['Option_Type'].iloc[0] == 'XX':\n",
    "                    group[f'Delta_{delta*100:.0f}_Diff'] = np.nan\n",
    "\n",
    "                group[f'Delta_{delta*100:.0f}_Diff_Min'] = group[f'Delta_{delta*100:.0f}_Diff'].min()        \n",
    "\n",
    "                try:\n",
    "                    deltaStrike = max(group[group[f'Delta_{delta*100:.0f}_Diff'] == group[f'Delta_{delta*100:.0f}_Diff_Min']]['Strike'])\n",
    "                    group[f'Delta_{delta*100:.0f}_Strike'] = deltaStrike\n",
    "                except Exception as e:\n",
    "                    #print('e2 : ', e)\n",
    "                    group[f'Delta_{delta*100:.0f}_Strike'] = np.nan\n",
    "                # dropping unnecessary columns\n",
    "                group = group.drop([f'Delta_{delta*100:.0f}_Diff_Min', f'Delta_{delta*100:.0f}_Diff'], axis=1)\n",
    "                \n",
    "            except Exception as e1:\n",
    "                print('e1 : ', e1)\n",
    "    # write output to csv\n",
    "    group.to_csv(output_path + symbolFilename + '.csv', mode='a', header=not os.path.exists(output_path + symbolFilename + '.csv'), index=False)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "120015ab-bd20-486a-a654-d87dfeccc2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinNifty WeeklyII 5\n",
      "5\n",
      "Weekly II\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Day_name</th>\n",
       "      <th>Week_number</th>\n",
       "      <th>Weekly_Expiry_Date</th>\n",
       "      <th>Expiry_Week_number</th>\n",
       "      <th>Week2</th>\n",
       "      <th>Week3</th>\n",
       "      <th>Week4</th>\n",
       "      <th>Week5</th>\n",
       "      <th>Week6</th>\n",
       "      <th>Week7</th>\n",
       "      <th>Week8</th>\n",
       "      <th>Week9</th>\n",
       "      <th>Week10</th>\n",
       "      <th>Week11</th>\n",
       "      <th>Week12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Fri</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>2021-01-21</td>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>2021-02-11</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>2021-03-10</td>\n",
       "      <td>2021-03-18</td>\n",
       "      <td>2021-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>Sat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>2021-01-21</td>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>2021-02-11</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>2021-03-10</td>\n",
       "      <td>2021-03-18</td>\n",
       "      <td>2021-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>Sun</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>2021-01-21</td>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>2021-02-11</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>2021-03-10</td>\n",
       "      <td>2021-03-18</td>\n",
       "      <td>2021-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>Mon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>2021-01-21</td>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>2021-02-11</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>2021-03-10</td>\n",
       "      <td>2021-03-18</td>\n",
       "      <td>2021-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>Tue</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>2021-01-21</td>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>2021-02-11</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>2021-03-10</td>\n",
       "      <td>2021-03-18</td>\n",
       "      <td>2021-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>Fri</td>\n",
       "      <td>156.0</td>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>156.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>2023-12-23</td>\n",
       "      <td>Sat</td>\n",
       "      <td>156.0</td>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>156.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>2023-12-24</td>\n",
       "      <td>Sun</td>\n",
       "      <td>156.0</td>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>156.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>2023-12-25</td>\n",
       "      <td>Mon</td>\n",
       "      <td>156.0</td>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>156.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>Tue</td>\n",
       "      <td>156.0</td>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>156.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1090 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date Day_name  Week_number Weekly_Expiry_Date  Expiry_Week_number  \\\n",
       "0     2021-01-01      Fri          1.0         2021-01-07                 1.0   \n",
       "1     2021-01-02      Sat          1.0         2021-01-07                 1.0   \n",
       "2     2021-01-03      Sun          1.0         2021-01-07                 1.0   \n",
       "3     2021-01-04      Mon          1.0         2021-01-07                 1.0   \n",
       "4     2021-01-05      Tue          1.0         2021-01-07                 1.0   \n",
       "...          ...      ...          ...                ...                 ...   \n",
       "1085  2023-12-22      Fri        156.0         2023-12-26               156.0   \n",
       "1086  2023-12-23      Sat        156.0         2023-12-26               156.0   \n",
       "1087  2023-12-24      Sun        156.0         2023-12-26               156.0   \n",
       "1088  2023-12-25      Mon        156.0         2023-12-26               156.0   \n",
       "1089  2023-12-26      Tue        156.0         2023-12-26               156.0   \n",
       "\n",
       "           Week2       Week3       Week4       Week5       Week6       Week7  \\\n",
       "0     2021-01-14  2021-01-21  2021-01-28  2021-02-04  2021-02-11  2021-02-18   \n",
       "1     2021-01-14  2021-01-21  2021-01-28  2021-02-04  2021-02-11  2021-02-18   \n",
       "2     2021-01-14  2021-01-21  2021-01-28  2021-02-04  2021-02-11  2021-02-18   \n",
       "3     2021-01-14  2021-01-21  2021-01-28  2021-02-04  2021-02-11  2021-02-18   \n",
       "4     2021-01-14  2021-01-21  2021-01-28  2021-02-04  2021-02-11  2021-02-18   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1085        None        None        None        None        None        None   \n",
       "1086        None        None        None        None        None        None   \n",
       "1087        None        None        None        None        None        None   \n",
       "1088        None        None        None        None        None        None   \n",
       "1089        None        None        None        None        None        None   \n",
       "\n",
       "           Week8       Week9      Week10      Week11      Week12  \n",
       "0     2021-02-25  2021-03-04  2021-03-10  2021-03-18  2021-03-25  \n",
       "1     2021-02-25  2021-03-04  2021-03-10  2021-03-18  2021-03-25  \n",
       "2     2021-02-25  2021-03-04  2021-03-10  2021-03-18  2021-03-25  \n",
       "3     2021-02-25  2021-03-04  2021-03-10  2021-03-18  2021-03-25  \n",
       "4     2021-02-25  2021-03-04  2021-03-10  2021-03-18  2021-03-25  \n",
       "...          ...         ...         ...         ...         ...  \n",
       "1085        None        None        None        None        None  \n",
       "1086        None        None        None        None        None  \n",
       "1087        None        None        None        None        None  \n",
       "1088        None        None        None        None        None  \n",
       "1089        None        None        None        None        None  \n",
       "\n",
       "[1090 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_test = 'FinNifty'\n",
    "schema_test = 'WeeklyII'\n",
    "conversion_test = '5'\n",
    "print(index_test,schema_test,conversion_test)\n",
    "print(schema_test.find('y'))\n",
    "print(schema_test[:schema_test.find('y')+1],schema_test[schema_test.find('y')+1:])\n",
    "if index_test != 'FinNifty':\n",
    "    engine = pg.connect(\"dbname='ExpiryDates' user='postgres' host='swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com' port='5432' password='swancap123'\")\n",
    "    exp_df = pd.read_sql(f'select * from \"public\".\"{schema_test[:schema_test.find(\"y\")+1]}Expiry\"', con=engine)\n",
    "    display(exp_df)\n",
    "    engine.close()\n",
    "elif index_test == 'FinNifty':\n",
    "    engine = pg.connect(\"dbname='ExpiryDates' user='postgres' host='swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com' port='5432' password='swancap123'\")\n",
    "    exp_df = pd.read_sql(f'select * from \"public\".\"{index_test}{schema_test[:schema_test.find(\"y\")+1]}Expiry\"', con=engine)\n",
    "    display(exp_df)\n",
    "    engine.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bf55ad1-a53a-465e-9459-ec9ea658a3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NIFTYMONTHLYII'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.upper()+schema.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3e1354a-ac5e-4dc1-83d8-926581ac57e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj_Open</th>\n",
       "      <th>Adj_High</th>\n",
       "      <th>Adj_Low</th>\n",
       "      <th>Adj_Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>OpenInterest</th>\n",
       "      <th>EQ_Open</th>\n",
       "      <th>EQ_High</th>\n",
       "      <th>EQ_Low</th>\n",
       "      <th>EQ_Close</th>\n",
       "      <th>Expiry_Date</th>\n",
       "      <th>Final_strike</th>\n",
       "      <th>Option_Type</th>\n",
       "      <th>IV</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Vega</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BANKNIFTYMONTHLY-I32000CE</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>11350.00</td>\n",
       "      <td>11350.00</td>\n",
       "      <td>11257.00</td>\n",
       "      <td>11257.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>43079.1016</td>\n",
       "      <td>43382.7500</td>\n",
       "      <td>42961.7500</td>\n",
       "      <td>43234.3008</td>\n",
       "      <td>2023-01-25</td>\n",
       "      <td>32000</td>\n",
       "      <td>CE</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.900263</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANKNIFTYMONTHLY-I33000CE</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>10100.00</td>\n",
       "      <td>10100.00</td>\n",
       "      <td>10100.00</td>\n",
       "      <td>10100.00</td>\n",
       "      <td>500.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>43079.1016</td>\n",
       "      <td>43382.7500</td>\n",
       "      <td>42961.7500</td>\n",
       "      <td>43234.3008</td>\n",
       "      <td>2023-01-25</td>\n",
       "      <td>33000</td>\n",
       "      <td>CE</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.077618</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BANKNIFTYMONTHLY-I35000CE</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>8250.05</td>\n",
       "      <td>8424.80</td>\n",
       "      <td>8120.00</td>\n",
       "      <td>8328.15</td>\n",
       "      <td>750.0</td>\n",
       "      <td>26425.0</td>\n",
       "      <td>43079.1016</td>\n",
       "      <td>43382.7500</td>\n",
       "      <td>42961.7500</td>\n",
       "      <td>43234.3008</td>\n",
       "      <td>2023-01-25</td>\n",
       "      <td>35000</td>\n",
       "      <td>CE</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.432326</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BANKNIFTYMONTHLY-I37000CE</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>6420.00</td>\n",
       "      <td>6420.00</td>\n",
       "      <td>6233.05</td>\n",
       "      <td>6250.00</td>\n",
       "      <td>500.0</td>\n",
       "      <td>26100.0</td>\n",
       "      <td>43079.1016</td>\n",
       "      <td>43382.7500</td>\n",
       "      <td>42961.7500</td>\n",
       "      <td>43234.3008</td>\n",
       "      <td>2023-01-25</td>\n",
       "      <td>37000</td>\n",
       "      <td>CE</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.787035</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BANKNIFTYMONTHLY-I37500CE</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>5684.50</td>\n",
       "      <td>5716.85</td>\n",
       "      <td>5684.50</td>\n",
       "      <td>5716.85</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2575.0</td>\n",
       "      <td>43079.1016</td>\n",
       "      <td>43382.7500</td>\n",
       "      <td>42961.7500</td>\n",
       "      <td>43234.3008</td>\n",
       "      <td>2023-01-25</td>\n",
       "      <td>37500</td>\n",
       "      <td>CE</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.875712</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>BANKNIFTYMONTHLY-I47500PE</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>4038.70</td>\n",
       "      <td>4064.30</td>\n",
       "      <td>3843.40</td>\n",
       "      <td>3843.40</td>\n",
       "      <td>700.0</td>\n",
       "      <td>12575.0</td>\n",
       "      <td>43148.4492</td>\n",
       "      <td>43482.8008</td>\n",
       "      <td>43148.4492</td>\n",
       "      <td>43448.3516</td>\n",
       "      <td>2023-01-25</td>\n",
       "      <td>47500</td>\n",
       "      <td>PE</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.999096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.641893</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>BANKNIFTYMONTHLY-I48000PE</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>4413.95</td>\n",
       "      <td>4550.00</td>\n",
       "      <td>4379.35</td>\n",
       "      <td>4379.35</td>\n",
       "      <td>1275.0</td>\n",
       "      <td>10425.0</td>\n",
       "      <td>43148.4492</td>\n",
       "      <td>43482.8008</td>\n",
       "      <td>43148.4492</td>\n",
       "      <td>43448.3516</td>\n",
       "      <td>2023-01-25</td>\n",
       "      <td>48000</td>\n",
       "      <td>PE</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.999096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.730586</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>BANKNIFTYMONTHLY-I48500PE</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>5007.00</td>\n",
       "      <td>5007.00</td>\n",
       "      <td>5006.95</td>\n",
       "      <td>5006.95</td>\n",
       "      <td>50.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>43148.4492</td>\n",
       "      <td>43482.8008</td>\n",
       "      <td>43148.4492</td>\n",
       "      <td>43448.3516</td>\n",
       "      <td>2023-01-25</td>\n",
       "      <td>48500</td>\n",
       "      <td>PE</td>\n",
       "      <td>0.297198</td>\n",
       "      <td>-0.922763</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-3.950806</td>\n",
       "      <td>15.300278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>BANKNIFTYMONTHLY-I49000PE</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>5505.00</td>\n",
       "      <td>5517.10</td>\n",
       "      <td>5505.00</td>\n",
       "      <td>5517.10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>43148.4492</td>\n",
       "      <td>43482.8008</td>\n",
       "      <td>43148.4492</td>\n",
       "      <td>43448.3516</td>\n",
       "      <td>2023-01-25</td>\n",
       "      <td>49000</td>\n",
       "      <td>PE</td>\n",
       "      <td>0.326591</td>\n",
       "      <td>-0.921661</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>-5.013016</td>\n",
       "      <td>15.467918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>BANKNIFTYMONTHLY-I49500PE</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>6000.00</td>\n",
       "      <td>6070.00</td>\n",
       "      <td>5805.25</td>\n",
       "      <td>5807.00</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3875.0</td>\n",
       "      <td>43148.4492</td>\n",
       "      <td>43482.8008</td>\n",
       "      <td>43148.4492</td>\n",
       "      <td>43448.3516</td>\n",
       "      <td>2023-01-25</td>\n",
       "      <td>49500</td>\n",
       "      <td>PE</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.999096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.996665</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Ticker       Date  Adj_Open  Adj_High   Adj_Low  \\\n",
       "1    BANKNIFTYMONTHLY-I32000CE 2023-01-02  11350.00  11350.00  11257.00   \n",
       "3    BANKNIFTYMONTHLY-I33000CE 2023-01-02  10100.00  10100.00  10100.00   \n",
       "5    BANKNIFTYMONTHLY-I35000CE 2023-01-02   8250.05   8424.80   8120.00   \n",
       "10   BANKNIFTYMONTHLY-I37000CE 2023-01-02   6420.00   6420.00   6233.05   \n",
       "13   BANKNIFTYMONTHLY-I37500CE 2023-01-02   5684.50   5716.85   5684.50   \n",
       "..                         ...        ...       ...       ...       ...   \n",
       "279  BANKNIFTYMONTHLY-I47500PE 2023-01-03   4038.70   4064.30   3843.40   \n",
       "281  BANKNIFTYMONTHLY-I48000PE 2023-01-03   4413.95   4550.00   4379.35   \n",
       "283  BANKNIFTYMONTHLY-I48500PE 2023-01-03   5007.00   5007.00   5006.95   \n",
       "285  BANKNIFTYMONTHLY-I49000PE 2023-01-03   5505.00   5517.10   5505.00   \n",
       "287  BANKNIFTYMONTHLY-I49500PE 2023-01-03   6000.00   6070.00   5805.25   \n",
       "\n",
       "     Adj_Close  Volume  OpenInterest     EQ_Open     EQ_High      EQ_Low  \\\n",
       "1     11257.00    75.0        1500.0  43079.1016  43382.7500  42961.7500   \n",
       "3     10100.00   500.0         675.0  43079.1016  43382.7500  42961.7500   \n",
       "5      8328.15   750.0       26425.0  43079.1016  43382.7500  42961.7500   \n",
       "10     6250.00   500.0       26100.0  43079.1016  43382.7500  42961.7500   \n",
       "13     5716.85   100.0        2575.0  43079.1016  43382.7500  42961.7500   \n",
       "..         ...     ...           ...         ...         ...         ...   \n",
       "279    3843.40   700.0       12575.0  43148.4492  43482.8008  43148.4492   \n",
       "281    4379.35  1275.0       10425.0  43148.4492  43482.8008  43148.4492   \n",
       "283    5006.95    50.0         900.0  43148.4492  43482.8008  43148.4492   \n",
       "285    5517.10   100.0         300.0  43148.4492  43482.8008  43148.4492   \n",
       "287    5807.00   700.0        3875.0  43148.4492  43482.8008  43148.4492   \n",
       "\n",
       "       EQ_Close Expiry_Date  Final_strike Option_Type        IV     Delta  \\\n",
       "1    43234.3008  2023-01-25         32000          CE  0.000005  0.999055   \n",
       "3    43234.3008  2023-01-25         33000          CE  0.000005  0.999055   \n",
       "5    43234.3008  2023-01-25         35000          CE  0.000005  0.999055   \n",
       "10   43234.3008  2023-01-25         37000          CE  0.000005  0.999055   \n",
       "13   43234.3008  2023-01-25         37500          CE  0.000005  0.999055   \n",
       "..          ...         ...           ...         ...       ...       ...   \n",
       "279  43448.3516  2023-01-25         47500          PE  0.000005 -0.999096   \n",
       "281  43448.3516  2023-01-25         48000          PE  0.000005 -0.999096   \n",
       "283  43448.3516  2023-01-25         48500          PE  0.297198 -0.922763   \n",
       "285  43448.3516  2023-01-25         49000          PE  0.326591 -0.921661   \n",
       "287  43448.3516  2023-01-25         49500          PE  0.000005 -0.999096   \n",
       "\n",
       "        Gamma     Theta       Vega  \n",
       "1    0.000000 -3.900263   0.000000  \n",
       "3    0.000000 -4.077618   0.000000  \n",
       "5    0.000000 -4.432326   0.000000  \n",
       "10   0.000000 -4.787035   0.000000  \n",
       "13   0.000000 -4.875712   0.000000  \n",
       "..        ...       ...        ...  \n",
       "279  0.000000  6.641893   0.000000  \n",
       "281  0.000000  6.730586   0.000000  \n",
       "283  0.000045 -3.950806  15.300278  \n",
       "285  0.000042 -5.013016  15.467918  \n",
       "287  0.000000  6.996665   0.000000  \n",
       "\n",
       "[288 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time :  2023-08-10 16:05:54.609854\n",
      "symbolFilename : BANKNIFTYMONTHLYI\n",
      "symbol : BANKNIFTYMONTHLYI\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f625e697e4e4e8d960544b443cef6a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 'BankNifty'\n",
    "conversion = 'EOD'\n",
    "schema = 'MonthlyI'\n",
    "\n",
    "eq_df = pd.read_csv(rf\"C:\\\\users\\\\admin\\\\desktop\\\\{index}_EqData\\\\{index}_{conversion}.csv\",parse_dates=['Date'])\n",
    "opt_df = pd.read_csv(fr\"C:\\Users\\admin\\Desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_Opt_EOD.csv\",parse_dates=['Date'])\n",
    "eq_df = eq_df.rename(columns={' Time' : 'Time','Open' : 'EQ_Open','High' : 'EQ_High','Low' : 'EQ_Low','Close' : 'EQ_Close'})\n",
    "eq_df['Date'] = pd.to_datetime(eq_df['Date'],format='mixed',dayfirst=True)\n",
    "opt_df = opt_df.rename(columns={'date' : 'Date',\n",
    "                        'ticker' : 'Ticker',\n",
    "                        'time' : 'Time',\n",
    "                        'open' : 'Open',\n",
    "                        'high' : 'High',\n",
    "                        'low' : 'Low',\n",
    "                        'close' : 'Close',\n",
    "                        'volume' : 'Volume',\n",
    "                        'Open_Interest' : 'OpenInterest'})\n",
    "opt_df = opt_df.rename(columns={'Open' : 'Adj_Open','High' : 'Adj_High','Low' : 'Adj_Low','Close' : 'Adj_Close'})\n",
    "\n",
    "opt_df['Date'] = pd.to_datetime(opt_df['Date'], format='mixed',dayfirst=True)\n",
    "opt_df['Year'] = opt_df['Date'].dt.year\n",
    "opt_df = opt_df.drop(['Year'], axis=1)\n",
    "opt_df = opt_df.merge(eq_df[['Date','EQ_Open','EQ_High','EQ_Low','EQ_Close']], on=['Date'], how='left')\n",
    "\n",
    "exp_df['Date'] = pd.to_datetime(exp_df['Date'], format='mixed',dayfirst=True)\n",
    "if schema[schema.find('y')+1:] == 'I':\n",
    "    opt_df = opt_df.merge(exp_df[['Date', 'E1']], on=['Date'], how='left')\n",
    "    opt_df = opt_df.rename(columns={'E1' : 'Expiry_Date'})\n",
    "elif schema[schema.find('y')+1:] == 'II':\n",
    "    opt_df = opt_df.merge(exp_df[['Date', 'E2']], on=['Date'], how='left')\n",
    "    opt_df = opt_df.rename(columns={'E2' : 'Expiry_Date'})\n",
    "elif schema[schema.find('y')+1:] == 'III':\n",
    "    opt_df = opt_df.merge(exp_df[['Date', 'E3']], on=['Date'], how='left')\n",
    "    opt_df = opt_df.rename(columns={'E3' : 'Expiry_Date'})\n",
    "\n",
    "opt_df = opt_df.rename(columns={'E1' : 'Expiry_Date'})\n",
    "\n",
    "opt_df['Date'] = pd.to_datetime(opt_df['Date'],dayfirst=True)\n",
    "opt_df['Expiry_Date'] = pd.to_datetime(opt_df['Expiry_Date'], dayfirst=True)\n",
    "opt_df['YTE'] = (opt_df['Expiry_Date'] - opt_df['Date']).dt.days\n",
    "opt_df['YTE/365'] = opt_df['YTE']/365\n",
    "\n",
    "opt_df['Final_strike'] = opt_df['Ticker'].str.replace(f'{index.upper()}{schema[:schema.find(\"y\")+1].upper()}-{schema[schema.find(\"y\")+1:]}',\"\").str[:-2].astype(int)    \n",
    "# opt_df['Final_strike'] = opt_df['Ticker'].str.replace(f'{stock_name}-I','').str[:-2].astype(float)#.str.replace(f'{schema_name+hyphens[k]}', '').str.replace(f'{index[i].upper()+hyphens[k]}','').str.replace(f'{index[i].upper()+schema_name+hyphens[k]}','').str.replace(f'{index[i].upper()}','')\n",
    "opt_df['Option_Type'] = opt_df['Ticker'].str[-2:]\n",
    "\n",
    "greeks_series = opt_df.apply(lambda x: greeks(x['EQ_Close'], x['Final_strike'], x['YTE/365'], x['Adj_Close'], x['Option_Type']), axis=1)\n",
    "#df = df.drop(['Delta'], axis=1)\n",
    "try:\n",
    "    opt_df[['IV', 'Delta', 'Gamma', 'Theta', 'Vega']] = pd.DataFrame(list(greeks_series))\n",
    "except:\n",
    "    print(opt_df)\n",
    "    print(opt_df)\n",
    "opt_df = opt_df.drop(['YTE', 'YTE/365'], axis=1)\n",
    "opt_df = opt_df.sort_values(by=['Date', 'Option_Type', 'Final_strike'])\n",
    "# df[['IV', 'Delta', 'Gamma', 'Theta', 'Vega']] = pd.DataFrame(list(greeks_series))\n",
    "# df = df.sort_values(by=['Date', 'Time', 'Option_Type', 'Final_strike'])\n",
    "# df = df[['Date', 'Time', 'Ticker','IV', 'Delta', 'Gamma', 'Theta', 'Vega']]\n",
    "display(opt_df)\n",
    "\n",
    "# opt_df.to_csv(fr'C:\\\\users\\admin\\\\desktop\\\\greeksEOD.csv',index=False)\n",
    "# file paths\n",
    "output_path = r\"C:\\\\users\\\\admin\\\\desktop\\\\\"\n",
    "# select delta values\n",
    "delta_list = [0.05, 0.10, 0.15, 0.20, 0.25,\n",
    "              0.30, 0.35, 0.40, 0.45, 0.50, \n",
    "              0.55, 0.60, 0.65, 0.70, 0.75, \n",
    "              0.80, 0.85, 0.90, 0.95]\n",
    "\n",
    "# load main csv\n",
    "print('Start time : ', datetime.now())\n",
    "\n",
    "opt_df.rename(columns={\n",
    "                   'Adj_Open' : 'OPT_Open',\n",
    "                   'Adj_High' : 'OPT_High',\n",
    "                   'Adj_Low' : 'OPT_Low',\n",
    "                   'Adj_Close' : 'OPT_Close',\n",
    "                   'Adj_Volume' : 'OPT_Contracts',\n",
    "                   'Volume' : 'OPT_Contracts',\n",
    "                    #'New_OI' : 'OPT_OI',\n",
    "                   'Last_OI' : 'OPT_OI',\n",
    "                   'OpenInterest' : 'OPT_OI',\n",
    "                   'Final_strike' : 'Strike',\n",
    "                   'CONTRACTS' : 'OPT_Contracts',\n",
    "                   'OPEN_INT' : 'OPT_OI'}, inplace=True)\n",
    "\n",
    "# extract Strike and Option Type from the Ticker if it's not there in the input file already.\n",
    "\n",
    "# df['Strike'] = df['Ticker'].str.extract('([0-9]+[./]*[0-9]*)').astype(float)\n",
    "\n",
    "# df['Option_Type'] = df[\"Ticker\"].str[-2:]\n",
    "\n",
    "# df['Option_Type'] = np.where((df['Option_Type'] == 'CE') | (df['Option_Type'] == 'PE'),\n",
    "#                              df['Option_Type'], 'XX')\n",
    "# get the symbol from filename\n",
    "symbolFilename = index.upper()+schema.upper()\n",
    "print('symbolFilename :', symbolFilename)\n",
    "\n",
    "# remove '-I'/'-II'/'-III' from filename\n",
    "symbol = symbolFilename.replace('-III', '')\n",
    "symbol = symbol.replace('-VIII', '')\n",
    "symbol = symbol.replace('-VII', '')\n",
    "symbol = symbol.replace('-VI', '')\n",
    "symbol = symbol.replace('-V', '')\n",
    "symbol = symbol.replace('-IV', '')\n",
    "symbol = symbol.replace('-II', '')\n",
    "symbol = symbol.replace('-I', '')\n",
    "print('symbol :', symbol)\n",
    "\n",
    "# substitute any special characters ('-', '&', '_') in Dispersion file names with empty string ('_')\n",
    "charactersDroppedSymbol = re.sub('\\ |\\_|\\.|\\-|\\&|\\;|\\:', '', symbol)\n",
    "df2 = opt_df.copy()\n",
    "# calculate difference between 'EQ_Close' and 'Strike' and get the minimum difference for a group\n",
    "df2['Difference'] = abs(df2['EQ_Close'] - df2['Strike'].astype(float))\n",
    "dfg = df2.groupby(['Date', 'Option_Type'])['Difference']\n",
    "df2['Min'] = dfg.transform('min')\n",
    "\n",
    "# delete output file if it already exists\n",
    "try:\n",
    "    os.remove(output_path + symbolFilename + '.csv')\n",
    "except Exception as e:\n",
    "    #print('e1 : ', e)\n",
    "    pass\n",
    "\n",
    "# get 'At The Money' for each group\n",
    "dfg = df2.groupby(['Date', 'Option_Type'])\n",
    "for name, group in tqdm(dfg):\n",
    "    # get 'At The Money' for each group\n",
    "    try:\n",
    "        atTheMoney = max(group[(group['Difference'] == group['Min'])]['Strike'])\n",
    "        group['At_The_Money'] = atTheMoney\n",
    "    \n",
    "    except Exception as e:\n",
    "        #print('e3 : ', e)\n",
    "        group['At_The_Money'] = np.nan\n",
    "        \n",
    "    group = group[['Date', 'Ticker', 'OPT_Open', 'OPT_High', 'OPT_Low', 'OPT_Close', 'OPT_Contracts', 'OPT_OI',\n",
    "               'Strike', 'Option_Type', 'Expiry_Date', 'IV', 'Delta', 'Theta', 'Gamma', 'Vega', 'EQ_Open', \n",
    "               'EQ_High', 'EQ_Low', 'EQ_Close', 'At_The_Money']]\n",
    "    \n",
    "    # loop through different delta values\n",
    "    for delta in delta_list:\n",
    "        if delta == 0.50:\n",
    "            group.rename(columns={'Min' : f'Delta_{delta*100:.0f}_Diff_Min',\n",
    "                                  'Difference' : f'Delta_{delta*100:.0f}_Diff'}, \n",
    "                         inplace=True)\n",
    "            group[f'Delta_{delta*100:.0f}_Strike'] = group['At_The_Money']\n",
    "        else:\n",
    "            if group['Option_Type'].iloc[0] == 'CE':\n",
    "                group[f'Delta_{delta*100:.0f}_Diff'] = abs(group['Delta'] - delta)\n",
    "            elif group['Option_Type'].iloc[0] == 'PE':\n",
    "                group[f'Delta_{delta*100:.0f}_Diff'] = abs(group['Delta'] - (-delta))\n",
    "            elif group['Option_Type'].iloc[0] == 'XX':\n",
    "                group[f'Delta_{delta*100:.0f}_Diff'] = np.nan\n",
    "            group[f'Delta_{delta*100:.0f}_Diff_Min'] = group[f'Delta_{delta*100:.0f}_Diff'].min()        \n",
    "\n",
    "            try:\n",
    "                deltaStrike = max(group[group[f'Delta_{delta*100:.0f}_Diff'] == group[f'Delta_{delta*100:.0f}_Diff_Min']]['Strike'])\n",
    "                group[f'Delta_{delta*100:.0f}_Strike'] = deltaStrike\n",
    "            except Exception as e:\n",
    "                #print('e2 : ', e)\n",
    "                group[f'Delta_{delta*100:.0f}_Strike'] = np.nan\n",
    "            # dropping unnecessary columns\n",
    "            group = group.drop([f'Delta_{delta*100:.0f}_Diff_Min', f'Delta_{delta*100:.0f}_Diff'], axis=1)\n",
    "    # write output to csv\n",
    "    group.to_csv(output_path + symbolFilename + conversion + '.csv', mode='a', header=not os.path.exists(output_path + symbolFilename + conversion + '.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c70624c-aea5-4226-a132-e6203ce35f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # file paths\n",
    "# output_path = r\"C:\\\\users\\\\admin\\\\desktop\\\\\"\n",
    "# # select delta values\n",
    "# delta_list = [0.05, 0.10, 0.15, 0.20, 0.25,\n",
    "#               0.30, 0.35, 0.40, 0.45, 0.50, \n",
    "#               0.55, 0.60, 0.65, 0.70, 0.75, \n",
    "#               0.80, 0.85, 0.90, 0.95]\n",
    "\n",
    "# # load main csv\n",
    "# print('Start time : ', datetime.now())\n",
    "# df = opt_df.copy()\n",
    "# df.rename(columns={\n",
    "#                    'Adj_Open' : 'OPT_Open',\n",
    "#                    'Adj_High' : 'OPT_High',\n",
    "#                    'Adj_Low' : 'OPT_Low',\n",
    "#                    'Adj_Close' : 'OPT_Close',\n",
    "#                    'Adj_Volume' : 'OPT_Contracts',\n",
    "#                    'Volume' : 'OPT_Contracts',\n",
    "#                     #'New_OI' : 'OPT_OI',\n",
    "#                    'Last_OI' : 'OPT_OI',\n",
    "#                    'OpenInterest' : 'OPT_OI',\n",
    "#                    'Final_strike' : 'Strike',\n",
    "#                    'CONTRACTS' : 'OPT_Contracts',\n",
    "#                    'OPEN_INT' : 'OPT_OI'}, inplace=True)\n",
    "\n",
    "# # extract Strike and Option Type from the Ticker if it's not there in the input file already.\n",
    "\n",
    "# # df['Strike'] = df['Ticker'].str.extract('([0-9]+[./]*[0-9]*)').astype(float)\n",
    "\n",
    "# # df['Option_Type'] = df[\"Ticker\"].str[-2:]\n",
    "\n",
    "# # df['Option_Type'] = np.where((df['Option_Type'] == 'CE') | (df['Option_Type'] == 'PE'),\n",
    "# #                              df['Option_Type'], 'XX')\n",
    "# # get the symbol from filename\n",
    "# symbolFilename = index.upper()+schema.upper()\n",
    "# print('symbolFilename :', symbolFilename)\n",
    "\n",
    "# # remove '-I'/'-II'/'-III' from filename\n",
    "# symbol = symbolFilename.replace('-III', '')\n",
    "# symbol = symbol.replace('-VIII', '')\n",
    "# symbol = symbol.replace('-VII', '')\n",
    "# symbol = symbol.replace('-VI', '')\n",
    "# symbol = symbol.replace('-V', '')\n",
    "# symbol = symbol.replace('-IV', '')\n",
    "# symbol = symbol.replace('-II', '')\n",
    "# symbol = symbol.replace('-I', '')\n",
    "# print('symbol :', symbol)\n",
    "\n",
    "# # substitute any special characters ('-', '&', '_') in Dispersion file names with empty string ('_')\n",
    "# charactersDroppedSymbol = re.sub('\\ |\\_|\\.|\\-|\\&|\\;|\\:', '', symbol)\n",
    "# df2 = df.copy()\n",
    "# # calculate difference between 'EQ_Close' and 'Strike' and get the minimum difference for a group\n",
    "# df2['Difference'] = abs(df2['EQ_Close'] - df2['Strike'].astype(float))\n",
    "# dfg = df2.groupby(['Date', 'Option_Type'])['Difference']\n",
    "# df2['Min'] = dfg.transform('min')\n",
    "\n",
    "# # delete output file if it already exists\n",
    "# try:\n",
    "#     os.remove(output_path + symbolFilename + '.csv')\n",
    "# except Exception as e:\n",
    "#     #print('e1 : ', e)\n",
    "#     pass\n",
    "\n",
    "# print(df2.shape[0])\n",
    "# #print(df2.columns)\n",
    "\n",
    "# # get 'At The Money' for each group\n",
    "# dfg = df2.groupby(['Date', 'Option_Type'])\n",
    "# for name, group in tqdm(dfg):\n",
    "    \n",
    "#     # get 'At The Money' for each group\n",
    "#     try:\n",
    "#         atTheMoney = max(group[(group['Difference'] == group['Min'])]['Strike'])\n",
    "#         group['At_The_Money'] = atTheMoney\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         #print('e3 : ', e)\n",
    "#         group['At_The_Money'] = np.nan\n",
    "\n",
    "#     group = group[['Date', 'Ticker', 'OPT_Open', 'OPT_High', 'OPT_Low', 'OPT_Close', 'OPT_Contracts', 'OPT_OI',\n",
    "#                'Strike', 'Option_Type', 'Expiry_Date', 'IV', 'Delta', 'Theta', 'Gamma', 'Vega', 'EQ_Open', \n",
    "#                'EQ_High', 'EQ_Low', 'EQ_Close', 'At_The_Money']]\n",
    "    \n",
    "#     # loop through different delta values\n",
    "#     for delta in delta_list:\n",
    "#         if delta == 0.50:\n",
    "#             group.rename(columns={'Min' : f'Delta_{delta*100:.0f}_Diff_Min',\n",
    "#                                   'Difference' : f'Delta_{delta*100:.0f}_Diff'}, \n",
    "#                          inplace=True)\n",
    "#             group[f'Delta_{delta*100:.0f}_Strike'] = group['At_The_Money']\n",
    "#         else:\n",
    "#             if group['Option_Type'].iloc[0] == 'CE':\n",
    "#                 group[f'Delta_{delta*100:.0f}_Diff'] = abs(group['Delta'] - delta)\n",
    "#             elif group['Option_Type'].iloc[0] == 'PE':\n",
    "#                 group[f'Delta_{delta*100:.0f}_Diff'] = abs(group['Delta'] - (-delta))\n",
    "#             elif group['Option_Type'].iloc[0] == 'XX':\n",
    "#                 group[f'Delta_{delta*100:.0f}_Diff'] = np.nan\n",
    "#             group[f'Delta_{delta*100:.0f}_Diff_Min'] = group[f'Delta_{delta*100:.0f}_Diff'].min()        \n",
    "\n",
    "#             try:\n",
    "#                 deltaStrike = max(group[group[f'Delta_{delta*100:.0f}_Diff'] == group[f'Delta_{delta*100:.0f}_Diff_Min']]['Strike'])\n",
    "#                 group[f'Delta_{delta*100:.0f}_Strike'] = deltaStrike\n",
    "#             except Exception as e:\n",
    "#                 #print('e2 : ', e)\n",
    "#                 group[f'Delta_{delta*100:.0f}_Strike'] = np.nan\n",
    "#             # dropping unnecessary columns\n",
    "#             group = group.drop([f'Delta_{delta*100:.0f}_Diff_Min', f'Delta_{delta*100:.0f}_Diff'], axis=1)\n",
    "#     # write output to csv\n",
    "#     group.to_csv(output_path + symbolFilename + conversion + '.csv', mode='a', header=not os.path.exists(output_path + symbolFilename + conversion + '.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20541074-a20d-42e2-926a-7304616da2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
