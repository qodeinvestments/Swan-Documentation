{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63af3b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r27022023\n",
      "BANKNIFTY CONTRACTS BEING CREATED\n",
      "0 I\n",
      "1 II\n",
      "2 III\n",
      "3 IV\n",
      "BANKNIFTY YEARLY-I CREATED\n",
      "BANKNIFTY YEARLY CONTRACTS CREATED\n",
      "\n",
      "BANKNIFTY CONTRACTS CREATED\n",
      "ELAPSED TIME 0.3246302604675293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12476\\1608901573.py:673: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  final_df = final_df.append(temp)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12476\\1608901573.py:673: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  final_df = final_df.append(temp)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12476\\1608901573.py:673: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  final_df = final_df.append(temp)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12476\\1608901573.py:673: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  final_df = final_df.append(temp)\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import walk\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import array_contains\n",
    "from pyspark.sql.functions import *\n",
    "import time\n",
    "from pyspark.sql.functions import date_format\n",
    "from datetime import date\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "date = date(2023,2,27)                                     ## TO BE CHANGED DAILY AS PER UPDATION DATE\n",
    "day = date.strftime('%d')\n",
    "nummonth=date.strftime(\"%m\")\n",
    "year=date.strftime('%Y')\n",
    "tablename=\"r\"+str(day)+str(nummonth)+str(year)\n",
    "print(tablename)\n",
    "\n",
    "st=time.time()\n",
    "\n",
    "def banknifty_data():\n",
    "    spark = SparkSession.builder.config(\"spark.jars\", \"C:\\\\Users\\\\admin\\\\Downloads\\\\postgresql-42.5.0.jar\") \\\n",
    "    .master(\"local\").appName(\"PySpark_Postgres_test\").getOrCreate()\n",
    "    \n",
    "    df = spark.read.format(\"jdbc\").option(\"url\", \"jdbc:postgresql://swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com/RawDataBase\").option(\"user\",\"postgres\").option(\"password\",\"swancap123\")\\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\").option(\"dbtable\", tablename)\\\n",
    "        .option(\"user\", \"postgres\").option(\"password\", \"swancap123\").load()\n",
    "\n",
    "    ## GETTING ONLY TIME IN TIME COLUMN\n",
    "    q = df.withColumn('time',date_format('time', 'HH:mm:ss'))\n",
    "    bndata = q.filter(q.ticker.contains('BANKNIFTY') & ((q.ticker.endswith('E.NFO'))| (q.ticker.endswith('E'))))\n",
    "    ## REPLACING .NFO IN ticker\n",
    "    bndata = bndata.withColumn('ticker',regexp_replace('ticker','.NFO',''))\n",
    "\n",
    "    ## CONVERTING PYSPARK DATAFRAME TO PANDAS DATAFRAME\n",
    "    bndata = bndata.toPandas()\n",
    "    return bndata\n",
    "\n",
    "def banknifty_monthly():\n",
    "    folpath = r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\Monthly_data\\\\\"\n",
    "    sym = 'BANKNIFTY'\n",
    "    start_time = datetime.strptime('09:15:00', '%H:%M:%S').time()\n",
    "    end_time = datetime.strptime('15:30:00', '%H:%M:%S').time()\n",
    "    \n",
    "    def add(stri):\n",
    "        obj = datetime.strptime(stri, \"%b\")\n",
    "        month_number = obj.month\n",
    "        return month_number\n",
    "\n",
    "    ## READING THE EXPIRY SHEET\n",
    "    exp_file_path = r\"C:\\Users\\admin\\Downloads\\MonthlyExpiry.csv\"\n",
    "    exp_df = pd.read_csv(exp_file_path,parse_dates=[\"curr_exp_date\",\"curr_date\"],dayfirst=True).dropna()\n",
    "    ## CONVERTING TO PANDAS DATAFRAME\n",
    "    exp_df.rename({'curr_date': 'New_date'}, axis=1, inplace=True)\n",
    "    exp_df['New_date'] = pd.to_datetime(exp_df['New_date'],dayfirst=True)\n",
    "    exp_date = pd.read_excel(r'C:\\users\\admin\\desktop\\Expiry_DT.xlsx')\n",
    "    \n",
    "    ## CALLING FUNCTION BANKNIFTY_DATA TO GENERATE ONLY BANKNIFTY TICKERS\n",
    "    ddf = banknifty_data()\n",
    "    ddf = ddf.loc[:, ~ddf.columns.str.contains('^Unnamed')]\n",
    "    ddf['date'] = pd.to_datetime(ddf['date'],dayfirst=True)\n",
    "    ddf['Optiontype'] = ddf['ticker'].str[-2:]\n",
    "    ddf['Temp'] = ddf['ticker'].str.replace('BANKNIFTY','')\n",
    "    ddf['Temp'] = ddf['Temp'].str[:-2]\n",
    "    ddf['Length_of_temp'] = np.where(ddf['Temp'].str.len()==12,12,ddf['Temp'].str.len())\n",
    "    ddf['Strike'] = np.where((ddf['Temp'].str.len()==12)|(ddf['Temp'].str.len()==10),ddf['Temp'].str[-5:],\n",
    "                             ddf['Temp'].str[-4:])\n",
    "    ddf['Exp_year'] = np.where(ddf['Temp'].str.len()==12,ddf['Temp'].str[5:7],ddf['Temp'].str[:2])\n",
    "    ddf['Exp_month'] = ddf['Temp'].str[2:5]\n",
    "    ddf['Exp_year'] = ddf['Exp_year'].astype('str')\n",
    "    ddf['MonthYear'] = ddf['Exp_month'] + ddf['Exp_year']\n",
    "    merged_df = pd.merge(ddf,exp_date,on='MonthYear')\n",
    "    merged_df = merged_df.drop(['MonthYear','Month','Year'],axis=1)\n",
    "    merged_df['Length_of_temp'] = merged_df['Length_of_temp'].astype('int64')\n",
    "    df_10 = merged_df[(merged_df['Length_of_temp']==10) | (merged_df['Length_of_temp']==9)]\n",
    "    df_12 = merged_df[merged_df['Length_of_temp']==12]\n",
    "    df_12['DateDate'] = df_12['Temp'].str[:2]\n",
    "    df_12['DateDate'] = df_12['DateDate'].astype('int64')\n",
    "    df_12['Exp_DT'] = pd.to_datetime(merged_df['Exp_DT'],dayfirst=True)\n",
    "    df_12['Exp_Day'] = df_12['Exp_DT'].dt.day\n",
    "    df_12 = df_12[df_12['Exp_Day']==df_12['DateDate']]\n",
    "    df_12 = df_12.drop(['DateDate','Exp_Day'],axis=1)\n",
    "\n",
    "    ddf = df_10.append(df_12,ignore_index=True)\n",
    "    ddf['time'] = ddf['time'].str.replace(' 15:00:59','15:00:59')\n",
    "    ddf['time'] = ddf['time'].str.replace(' 9:','09:',regex=True)\n",
    "    ddf['time'] = pd.to_datetime(ddf['time'], format='%H:%M:%S').dt.time\n",
    "    ddf = ddf[(ddf['time']>=start_time) & (ddf['time']<=end_time)]\n",
    "    ddf['exp_month_number'] = ddf.apply(lambda row : add(row[\"Exp_month\"]), axis = 1)\n",
    "    ddf['New_date'] = ddf['date']\n",
    "    ddf[\"New_date\"] = pd.to_datetime(ddf[\"New_date\"],dayfirst=True)\n",
    "    ddf[\"current_month_number\"] = ddf['New_date'].dt.month\n",
    "    ddf[\"difference\"] = ddf['exp_month_number'].astype(int) - ddf[\"current_month_number\"].astype(int)\n",
    "    df1 = pd.merge(ddf, \n",
    "                     exp_df, \n",
    "                     on ='New_date', \n",
    "                     how ='left')\n",
    "    df1.drop(df1.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "    df1[\"current_exp_month_number\"] = df1['curr_exp_date'].dt.month\n",
    "    df1[\"Diff_months\"] = df1[\"current_exp_month_number\"] - df1[\"current_month_number\"]\n",
    "    df1[\"Diff_months\"] = df1[\"Diff_months\"].astype(int) \n",
    "    bdf = df1[df1[\"Diff_months\"] == 0]\n",
    "    adf = df1[(df1[\"Diff_months\"] == 1) | (df1[\"Diff_months\"] == -11)]\n",
    "    if bdf.shape[0] + adf.shape[0] == df1.shape[0]:\n",
    "        print(\"Sanity Check Success\")\n",
    "    else:\n",
    "        print(\"Error1\")\n",
    "    agb = adf.groupby([\"difference\"])\n",
    "    unique_val_list_a = list(adf[\"difference\"].unique())\n",
    "    bgb = bdf.groupby([\"difference\"])\n",
    "    unique_val_list_b = list(bdf[\"difference\"].unique())\n",
    "    \n",
    "    ## REMOVING YESTERDAY'S CREATED FILE\n",
    "    if os.path.exists(folpath+sym+'-I.csv'):\n",
    "        os.remove(folpath+sym+'-I.csv')\n",
    "    if os.path.exists(folpath+sym+'-II.csv'):\n",
    "        os.remove(folpath+sym+'-II.csv')\n",
    "    if os.path.exists(folpath+sym+'-III.csv'):\n",
    "        os.remove(folpath+sym+'-III.csv')\n",
    "    if os.path.exists(folpath+sym+'misc.csv'):\n",
    "        os.remove(folpath+sym+'misc.csv')\n",
    "        \n",
    "    for i in unique_val_list_b:\n",
    "        temp_df_new = bgb.get_group(i)\n",
    "        temp_df_new = temp_df_new.drop(temp_df_new.columns[9:],axis=1)\n",
    "        if i == 0:\n",
    "            temp_df_new.to_csv(folpath + sym + '-I.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "        if i == 1 or i == -11:\n",
    "            temp_df_new.to_csv(folpath + sym + '-II.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "        if i == 2 or i == -10:\n",
    "            temp_df_new.to_csv(folpath + sym + '-III.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "        \n",
    "    for i in unique_val_list_a:\n",
    "        temp_df_new = agb.get_group(i)\n",
    "        temp_df_new = temp_df_new.drop(temp_df_new.columns[9:],axis=1)\n",
    "        if i == 1 or i == -11:\n",
    "            temp_df_new.to_csv(folpath + sym + '-I.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "        if i == 2 or i == -10:\n",
    "            temp_df_new.to_csv(folpath + sym + '-II.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "        if i == 3 or i == -9:\n",
    "            temp_df_new.to_csv(folpath + sym + '-III.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "    \n",
    "    ##########################CREATING LABEL IN STANDARD FORM#####################\n",
    "    for i in range(3):\n",
    "        if i == 0:\n",
    "            file='I'\n",
    "        elif i == 1:\n",
    "            file='II'\n",
    "        elif i == 2:\n",
    "            file='III'\n",
    "        \n",
    "        if os.path.exists(r'C:\\users\\admin\\desktop\\Pyspark\\BankNifty\\Monthly\\Banknifty-'+file+\".csv\"):\n",
    "            os.remove(r'C:\\users\\admin\\desktop\\Pyspark\\BankNifty\\Monthly\\Banknifty-'+file+\".csv\")\n",
    "    \n",
    "        if os.path.exists(r'C:\\users\\admin\\desktop\\Pyspark_Contracts\\BankNifty\\Monthly_Data\\BANKNIFTY-'+file+'.csv'):\n",
    "            ddf = pd.read_csv(r'C:\\users\\admin\\desktop\\Pyspark_Contracts\\BankNifty\\Monthly_Data\\BANKNIFTY-'+file+'.csv')\n",
    "            ddf['Option_Type'] = ddf['ticker'].str[-2:]\n",
    "            ddf['Strike'] = np.where((ddf['ticker'].str.len()==20) | (ddf['ticker'].str.len()==22) , ddf['ticker'].str[-6:-2] , ddf['ticker'].str[-7:-2])\n",
    "            ddf['Symbol'] = 'BANKNIFTY' + 'MONTHLY-' + file + ddf['Strike'].astype(int).astype(str) + ddf['Option_Type']\n",
    "            ddf['ticker'] = ddf['Symbol']\n",
    "            ddf = ddf.drop(ddf.columns[9:],axis=1)\n",
    "            ddf = ddf.rename(columns = {\"ticker\":\"Ticker\"})\n",
    "            ddf.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\Monthly\\\\Banknifty-\"+file+\".csv\",index=False)\n",
    "    print(\"BANKNIFTY MONTHLY CONTRACTS CREATED\")\n",
    "\n",
    "def banknifty_weekly():\n",
    "    folpath = r\"C:\\users\\admin\\desktop\\\\Pyspark_Contracts\\\\BankNifty\\\\Weekly_Data\\\\\"\n",
    "    sym = 'BANKNIFTY'\n",
    "    s = 'BANKNIFTY'\n",
    "    expiry_time = datetime.strptime('15:29:59', '%H:%M:%S').time()\n",
    "    \n",
    "    ## CALLING FUNCTION NIFTY_DATA TO GENERATE ONLY NIFTY TICKERS\n",
    "    df=banknifty_data()\n",
    "    \n",
    "    ## READING WEEKLY EXPIRY FILES\n",
    "    exp_df = pd.read_csv(r\"C:\\Users\\admin\\Downloads\\WeeklyExpiry.csv\",parse_dates = [\"date\"],dayfirst =True,usecols= ['date', 'Week_number'])\n",
    "    exp_date = pd.read_excel(r'C:\\users\\admin\\desktop\\Expiry_DT.xlsx',parse_dates = ['Exp_DT'],usecols = ['MonthYear','Exp_DT'])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['time'] = df['time'].str.replace(' 15:00:59','15:00:59')\n",
    "    df['time'] = df['time'].str.replace(' 9:','09:',regex=True)\n",
    "    df['time'] = pd.to_datetime(df['time']).dt.time\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    df = df[df['time'] <= expiry_time]\n",
    "    df['EXPIRY_DT'] = df['ticker'].str[9:16]\n",
    "    df['EXPIRY_DT'] = pd.to_datetime(df['EXPIRY_DT'],dayfirst=True)\n",
    "    df['OPTION_TYP'] = df['ticker'].str[-2:]\n",
    "    df['STRIKE_PR'] = np.where(df['ticker'].str.len()==23,df['ticker'].str[-7:-2],df['ticker'].str[-7:-2])\n",
    "    df['Month'] = df['ticker'].str[11:14]\n",
    "    df['Year'] = np.where(df['ticker'].str.len()==23,df['ticker'].str[14:16],df['ticker'].str[9:11])\n",
    "    df['MonthYear'] = df['Month'] + df['Year']\n",
    "    df = df.rename(columns={'EXPIRY_DT' : 'expiry_date'})\n",
    "\n",
    "    ## MERGING WITH EXPIRY SHEET TO GET EXPIRY DATE\n",
    "    df1 = pd.merge(df,exp_df,on='date',how='left')\n",
    "    df1 = df1.drop_duplicates()\n",
    "    df1 = pd.merge(df1,exp_date,on='MonthYear',how='left')\n",
    "    df1 = df1.drop(['Month','Year','MonthYear'],axis=1)\n",
    "\n",
    "    ## GETTING THE EXPIRY DATES FOR MONTHLY CONTRACTS\n",
    "    df1['expiry_date'] = np.where(df1['ticker'].str.len()>21,df1['expiry_date'],df1['Exp_DT'])\n",
    "    df1 = df1.drop(['Exp_DT'],axis=1)\n",
    "    exp_df = pd.read_csv(r\"C:\\Users\\admin\\Downloads\\WeeklyExpiry.csv\",parse_dates = [\"Weekly_Expiry_Date\"],dayfirst =True,usecols= ['Weekly_Expiry_Date', 'Expiry_Week_number'])\n",
    "    exp_df = exp_df.dropna()\n",
    "    exp_df = exp_df.rename(columns = {'Weekly_Expiry_Date': 'expiry_date'})\n",
    "    df2 = pd.merge(df1, exp_df, on ='expiry_date', how ='left')\n",
    "    df2 = df2.drop_duplicates()\n",
    "    df2['week_diff'] = df2['Expiry_Week_number'] - df2['Week_number']\n",
    "\n",
    "    final_df = df2[(df2[\"OPTION_TYP\"] == \"CE\") | (df2[\"OPTION_TYP\"] == \"PE\") ]\n",
    "    final_df[\"week_diff\"] = final_df['week_diff'].replace(np.nan,10000)\n",
    "\n",
    "    agb = final_df.groupby([\"week_diff\"])\n",
    "    unique_val_list_a = list(final_df[\"week_diff\"].unique())\n",
    "    unique_val_list_a = sorted([a for a in unique_val_list_a if a>=0])[0:12]\n",
    "    print(unique_val_list_a)\n",
    "\n",
    "    ## CREATING -I,-II AND SO ON BASED ON THE WEEK DIFFERENCES\n",
    "\n",
    "    if os.path.exists(folpath+sym+'_Weekly-I.csv'):\n",
    "        os.remove(folpath+sym+'_Weekly-I.csv')\n",
    "    if os.path.exists(folpath+sym+'_Weekly-II.csv'):\n",
    "        os.remove(folpath+sym+'_Weekly-II.csv')\n",
    "    if os.path.exists(folpath+sym+'_Weekly-III.csv'):\n",
    "        os.remove(folpath+sym+'_Weekly-III.csv')\n",
    "    if os.path.exists(folpath+sym+'_Weekly-IV.csv'):\n",
    "        os.remove(folpath+sym+'_Weekly-IV.csv')\n",
    "    if os.path.exists(folpath+sym+'_Weekly-V.csv'):\n",
    "        os.remove(folpath+sym+'_Weekly-V.csv')\n",
    "    if os.path.exists(folpath+sym+'_Weekly-VI.csv'):\n",
    "        os.remove(folpath+sym+'_Weekly-VI.csv')\n",
    "    if os.path.exists(folpath+sym+'_Weekly-VII.csv'):\n",
    "        os.remove(folpath+sym+'_Weekly-VII.csv')\n",
    "    if os.path.exists(folpath+sym+'_Weekly-VIII.csv'):\n",
    "        os.remove(folpath+sym+'_Weekly-VIII.csv')\n",
    "    if os.path.exists(folpath+sym+'_Weekly-IX.csv'):\n",
    "        os.remove(folpath+sym+'_Weekly-IX.csv')\n",
    "    if os.path.exists(folpath+sym+'_Weekly-X.csv'):\n",
    "        os.remove(folpath+sym+'_Weekly-X.csv')\n",
    "    if os.path.exists(folpath+sym+'_Weekly-XI.csv'):\n",
    "        os.remove(folpath+sym+'_Weekly-XI.csv')\n",
    "    if os.path.exists(folpath+sym+'_Weekly-XII.csv'):\n",
    "        os.remove(folpath+sym+'_Weekly-XII.csv')  \n",
    "    if os.path.exists(folpath+sym+'_Weekly-XIII.csv'):\n",
    "        os.remove(folpath+sym+'_Weekly-XIII.csv')  \n",
    "    if os.path.exists(folpath+sym+'_Weekly-XIV.csv'):\n",
    "        os.remove(folpath+sym+'_Weekly-XIV.csv')  \n",
    "        \n",
    "    for i in sorted(unique_val_list_a):\n",
    "        temp_df = agb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        temp_df = temp_df.drop_duplicates()\n",
    "        if i == 0:\n",
    "            temp_df.to_csv(folpath + s + '-I.csv', mode = 'a', header = not os.path.exists(folpath + s + '-I.csv'), index=False)\n",
    "        if i == 1:\n",
    "            temp_df.to_csv(folpath + s + '-II.csv', mode = 'a', header = not os.path.exists(folpath + s + '-II.csv'), index=False)\n",
    "        if i == 2:\n",
    "            temp_df.to_csv(folpath + s + '-III.csv', mode = 'a', header = not os.path.exists(folpath + s + '-III.csv'), index=False)\n",
    "        if i == 3:\n",
    "            temp_df.to_csv(folpath + s + '-IV.csv', mode = 'a', header = not os.path.exists(folpath + s + '-IV.csv'), index=False)\n",
    "        if i == 4:\n",
    "            temp_df.to_csv(folpath + s + '-V.csv', mode = 'a', header = not os.path.exists(folpath + s + '-V.csv'), index=False)\n",
    "        if i == 5:\n",
    "            temp_df.to_csv(folpath + s + '-VI.csv', mode = 'a', header = not os.path.exists(folpath + s + '-VI.csv'), index=False)\n",
    "        if i == 6:\n",
    "            temp_df.to_csv(folpath + s + '-VII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-VII.csv'), index=False)\n",
    "        if i == 7:\n",
    "            temp_df.to_csv(folpath + s + '-VIII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-VIII.csv'), index=False)\n",
    "        if i == 8:\n",
    "            temp_df.to_csv(folpath + s + '-IX.csv', mode = 'a', header = not os.path.exists(folpath + s + '-IX.csv'), index=False)\n",
    "        if i == 9:\n",
    "            temp_df.to_csv(folpath + s + '-X.csv', mode = 'a', header = not os.path.exists(folpath + s + '-X.csv'), index=False)\n",
    "        if i == 10:\n",
    "            temp_df.to_csv(folpath + s + '-XI.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XI.csv'), index=False)\n",
    "        if i == 11:\n",
    "            temp_df.to_csv(folpath + s + '-XII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XII.csv'), index=False)\n",
    "        if i == 12:\n",
    "            temp_df.to_csv(folpath + s + '-XIII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XIII.csv'), index=False)\n",
    "        if i == 13:\n",
    "            temp_df.to_csv(folpath + s + '-XIV.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XIV.csv'), index=False)\n",
    "    \n",
    "    #################LABELLING FILES IN STANDARD FORM######################\n",
    "    for i in range(15):\n",
    "        if i==0:\n",
    "            file='I'\n",
    "        elif i==1:\n",
    "            file='II'\n",
    "        elif i==2:\n",
    "            file='III'\n",
    "        elif i==3:\n",
    "            file='IV'\n",
    "        elif i==4:\n",
    "            file='V'\n",
    "        elif i==5:\n",
    "            file='VI'\n",
    "        elif i==6:\n",
    "            file='VII'\n",
    "        elif i==7:\n",
    "            file='VIII'\n",
    "        elif i==8:\n",
    "            file='IX'\n",
    "        elif i==9:\n",
    "            file='X'\n",
    "        elif i==10:\n",
    "            file='XI'\n",
    "        elif i==11:\n",
    "            file='XII'\n",
    "        elif i==12:\n",
    "            file='XIII'\n",
    "        elif i==13:\n",
    "            file='XIV'\n",
    "        if os.path.exists(r'C:\\users\\admin\\desktop\\Pyspark\\BankNifty\\Weekly\\BANKNIFTY-'+file+'.csv'):\n",
    "            os.remove(r'C:\\users\\admin\\desktop\\Pyspark\\BankNifty\\Weekly\\BANKNIFTY-'+file+'.csv')\n",
    "        if os.path.exists(r'C:\\users\\admin\\desktop\\Pyspark_Contracts\\BankNifty\\Weekly_Data\\BANKNIFTY-'+file+'.csv'):\n",
    "            ddf = pd.read_csv(r'C:\\users\\admin\\desktop\\Pyspark_Contracts\\BankNifty\\Weekly_Data\\BANKNIFTY-'+file+'.csv')\n",
    "            ddf['Option_Type'] = ddf['ticker'].str[-2:]\n",
    "            ddf['Strike'] = np.where((ddf['ticker'].str.len()==20) | (ddf['ticker'].str.len()==22) , ddf['ticker'].str[-6:-2] , ddf['ticker'].str[-7:-2])\n",
    "            ddf['Symbol'] = 'BANKNIFTY' + 'WEEKLY-' + file + + ddf['Strike'].astype(int).astype(str) + ddf['Option_Type']\n",
    "            ddf['ticker'] = ddf['Symbol']\n",
    "            ddf = ddf.drop(ddf.columns[9:],axis=1)\n",
    "            ddf = ddf.rename(columns = {'date':'Date','ticker':'Ticker'})\n",
    "            ddf = ddf.drop_duplicates()\n",
    "            ddf.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\Weekly\\BANKNIFTY-\"+file+\".csv\",index=False)\n",
    "    print(\"BANKNIFTY WEEKLY CONTRACTS CREATED\")\n",
    "    \n",
    "def banknifty_quarterly():\n",
    "    folpath = r\"C:\\users\\admin\\desktop\\\\Pyspark_Contracts\\\\BankNifty\\\\Quarterly_Data\\\\\"\n",
    "    sym = 'BANKNIFTY'\n",
    "    start_time = datetime.strptime('09:15:00', '%H:%M:%S').time()\n",
    "    end_time = datetime.strptime('15:30:00', '%H:%M:%S').time()\n",
    "\n",
    "    ## CALLING FUNCTION BANKNIFTY_DATA TO GENERATE ONLY BANKNIFTY TICKERS\n",
    "    temp = banknifty_data()\n",
    "    \n",
    "    def add(stri):\n",
    "        obj = datetime.strptime(stri, \"%b\")\n",
    "        month_number = obj.month\n",
    "        return month_number\n",
    "\n",
    "    exp_date = pd.read_excel(r'C:\\users\\admin\\desktop\\Expiry_DT.xlsx')    ## reading the expiry sheet file\n",
    "    exp_file_path = r\"C:\\Users\\admin\\Downloads\\MonthlyExpiry.csv\"\n",
    "    exp_df = pd.read_csv(exp_file_path,parse_dates = [\"curr_exp_date\",\"curr_date\"],dayfirst =True,usecols = [\"curr_exp_date\",\"curr_date\"]).dropna()\n",
    "    exp_df.rename({'curr_date': 'New_date'}, axis=1, inplace=True)\n",
    "    temp['time'] = temp['time'].astype(str).str.replace(' 15:00:59','15:00:59')\n",
    "    temp['time'] = temp['time'].str.replace(' 9:','09:',regex=True)\n",
    "    temp['ticker'] = temp['ticker'].str.replace('30MAR23','29MAR23',regex=True)\n",
    "    temp['time'] = pd.to_datetime(temp['time']).dt.time\n",
    "    temp['date'] = pd.to_datetime(temp['date'])\n",
    "    temp = temp[(temp['time']>=start_time) & (temp['time']<=end_time)]\n",
    "    temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "    temp['Option_type'] = temp['ticker'].str[-2:]\n",
    "    temp[\"Temp\"] = temp[\"ticker\"].str.replace('BANKNIFTY',\"\")\n",
    "    temp[\"Temp\"] = temp[\"Temp\"].str[:-2]\n",
    "    temp[\"Strike\"] = np.where((temp['Temp'].str.len()==12) | (temp['Temp'].str.len()==10),\n",
    "                                temp['Temp'].str[-5:],\n",
    "                                temp['Temp'].str[-4:])\n",
    "    temp['Current_Year'] = temp['date'].dt.year\n",
    "    temp['Current_Year'] = temp['Current_Year'].astype(str).str[-2:]\n",
    "    temp[\"Exp_year\"] = np.where(temp['Temp'].str.len()==12,temp[\"Temp\"].str[5:7],temp['Temp'].str[:2])\n",
    "    temp[\"Exp_month\"] = temp[\"Temp\"].str[2:5]\n",
    "    temp['Length_of_Temp'] = np.where(temp['Temp'].str.len()==12,12,temp['Temp'].str.len())\n",
    "    temp['Exp_year'] = temp['Exp_year'].astype('str')\n",
    "    temp['MonthYear'] = temp['Exp_month']+temp['Exp_year']\n",
    "    temp = pd.merge(temp,exp_date,on='MonthYear')\n",
    "    temp = temp.drop(['MonthYear','Month','Year'],axis=1)\n",
    "\n",
    "    temp['Length_of_Temp'] = temp['Length_of_Temp'].astype('int64')\n",
    "    temp_10 = temp[(temp['Length_of_Temp']==10) | (temp['Length_of_Temp']==9)]\n",
    "    temp_12 = temp[temp['Length_of_Temp']==12]\n",
    "    temp_12['datedate'] = temp_12['Temp'].str[:2]\n",
    "    temp_12['datedate'] = temp_12['datedate'].astype('int64')\n",
    "    temp_12['Exp_DT'] = pd.to_datetime(temp['Exp_DT'],dayfirst=True)\n",
    "    temp_12['Exp_Day'] = temp_12['Exp_DT'].dt.day\n",
    "    temp_12 = temp_12[temp_12['Exp_Day']==temp_12['datedate']]\n",
    "\n",
    "    temp_12 = temp_12.drop(['datedate','Exp_Day'],axis=1)\n",
    "    temp = temp_10.append(temp_12,ignore_index=True)\n",
    "\n",
    "    temp['exp_month_number'] = temp.apply(lambda row : add(row[\"Exp_month\"]), axis = 1)\n",
    "    temp['New_date'] = temp['date']\n",
    "    temp[\"New_date\"] = pd.to_datetime(temp[\"New_date\"])\n",
    "    temp[\"current_month_number\"] = temp['New_date'].dt.month\n",
    "    temp[\"difference\"] = temp['exp_month_number'].astype(int) - temp[\"current_month_number\"].astype(int)\n",
    "    temp['Year_difference'] = temp['Exp_year'].astype(int) - temp['Current_Year'].astype(int)\n",
    "    temp = temp[(temp['exp_month_number']==3) | (temp['exp_month_number']==6) | (temp['exp_month_number']==9) | (temp['exp_month_number']==12)]\n",
    "\n",
    "    temp1 = pd.merge(temp, \n",
    "                         exp_df, \n",
    "                         on ='New_date', \n",
    "                         how ='left')\n",
    "\n",
    "    temp1.drop(temp1.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "    temp1[\"current_exp_month_number\"] = temp1['curr_exp_date'].dt.month\n",
    "    temp1[\"Diff_months\"] = temp1[\"current_exp_month_number\"] - temp1[\"current_month_number\"]\n",
    "    temp1[\"Diff_months\"] = temp1[\"Diff_months\"].astype(int) \n",
    "\n",
    "    temp1 = temp1[temp1['Exp_DT']>=temp1['curr_exp_date']]                 ## to filter out dates which have wrong ticker\n",
    "\n",
    "    ## creating groups for generating contracts\n",
    "    atemp = temp1[(temp1['Diff_months']==0) & (temp1['Year_difference']==0)]\n",
    "    agb = atemp.groupby(['difference'])\n",
    "    unique_a = list(atemp['difference'].unique())\n",
    "\n",
    "    if os.path.exists(folpath+sym+'-I.csv'):\n",
    "        os.remove(folpath+sym+'-I.csv')\n",
    "    if os.path.exists(folpath+sym+'-II.csv'):\n",
    "        os.remove(folpath+sym+'-II.csv')\n",
    "    if os.path.exists(folpath+sym+'-III.csv'):\n",
    "        os.remove(folpath+sym+'-III.csv')\n",
    "    if os.path.exists(folpath+sym+'-IV.csv'):\n",
    "        os.remove(folpath+sym+'-IV.csv')\n",
    "    if os.path.exists(folpath+sym+'-V.csv'):\n",
    "        os.remove(folpath+sym+'-V.csv')\n",
    "    if os.path.exists(folpath+sym+'-VI.csv'):\n",
    "        os.remove(folpath+sym+'-VI.csv')\n",
    "    if os.path.exists(folpath+sym+'-VII.csv'):\n",
    "        os.remove(folpath+sym+'-VII.csv')\n",
    "    if os.path.exists(folpath+sym+'-VIII.csv'):\n",
    "        os.remove(folpath+sym+'-VIII.csv')    \n",
    "\n",
    "    for i in unique_a:\n",
    "        temp_df = agb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==0 or i==1 or i==2:\n",
    "            temp_df.to_csv(folpath + sym + '-I.csv', mode='a', header=not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "        if i==3 or i==4 or i==5:\n",
    "            temp_df.to_csv(folpath + sym + '-II.csv', mode='a', header=not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "        if i==6 or i==7 or i==8:\n",
    "            temp_df.to_csv(folpath + sym + '-III.csv', mode='a', header=not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "        if i==9 or i==10 or i==11:\n",
    "            temp_df.to_csv(folpath + sym + '-IV.csv', mode='a', header=not os.path.exists(folpath + sym + '-IV.csv'), index=False)\n",
    "\n",
    "    btemp = temp1[(temp1['Diff_months']==0) & (temp1['Year_difference']==1)]\n",
    "    bgb = btemp.groupby(['difference'])\n",
    "    unique_b = list(btemp['difference'].unique())        \n",
    "\n",
    "    for i in unique_b:\n",
    "        temp_df = bgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-7 or i==-8 or i==-9:\n",
    "            temp_df.to_csv(folpath + sym + '-II.csv', mode='a', header=not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "        if i==-4 or i==-5 or i==-6:\n",
    "            temp_df.to_csv(folpath + sym + '-III.csv', mode='a', header=not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "        if i==-1 or i==-2 or i==-3:\n",
    "            temp_df.to_csv(folpath + sym + '-IV.csv', mode='a', header=not os.path.exists(folpath + sym + '-IV.csv'), index=False)\n",
    "        if i==0 or i==1 or i==2:\n",
    "            temp_df.to_csv(folpath + sym + '-V.csv', mode='a', header=not os.path.exists(folpath + sym + '-V.csv'), index=False)\n",
    "        if i==3 or i==4 or i==5:\n",
    "            temp_df.to_csv(folpath + sym + '-VI.csv', mode='a', header=not os.path.exists(folpath + sym + '-VI.csv'), index=False)\n",
    "        if i==6 or i==7 or i==8:\n",
    "            temp_df.to_csv(folpath + sym + '-VII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VII.csv'), index=False)\n",
    "        if i==9 or i==10 or i==11:\n",
    "            temp_df.to_csv(folpath + sym + '-VIII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VIII.csv'), index=False)\n",
    "\n",
    "    ctemp = temp1[(temp1['Diff_months']==0) & (temp1['Year_difference']==2)]\n",
    "    cgb = ctemp.groupby(['difference'])\n",
    "    unique_c = list(ctemp['difference'].unique())        \n",
    "\n",
    "    for i in unique_c:\n",
    "        temp_df = cgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-7 or i==-8 or i==-9:\n",
    "            temp_df.to_csv(folpath + sym + '-VI.csv', mode='a', header=not os.path.exists(folpath + sym + '-VI.csv'), index=False)\n",
    "        if i==-4 or i==-5 or i==-6:\n",
    "            temp_df.to_csv(folpath + sym + '-VII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VII.csv'), index=False)\n",
    "        if i==-1 or i==-2 or i==-3:\n",
    "            temp_df.to_csv(folpath + sym + '-VIII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VIII.csv'), index=False)\n",
    "\n",
    "    dtemp = temp1[((temp1['Diff_months']==1) | (temp1['Diff_months']==-11)) & (temp1['Year_difference']==0)]\n",
    "    dgb = dtemp.groupby(['difference'])\n",
    "    unique_d = list(dtemp['difference'].unique())\n",
    "\n",
    "    for i in unique_d:\n",
    "        temp_df = dgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==1 or i==2 or i==3:\n",
    "            temp_df.to_csv(folpath + sym + '-I.csv', mode='a', header=not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "        if i==4 or i==5 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-II.csv', mode='a', header=not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "        if i==7 or i==8 or i==9:\n",
    "            temp_df.to_csv(folpath + sym + '-III.csv', mode='a', header=not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "        if i==10 or i==11:\n",
    "            temp_df.to_csv(folpath + sym + '-IV.csv', mode='a', header=not os.path.exists(folpath + sym + '-IV.csv'), index=False)\n",
    "\n",
    "    etemp = temp1[((temp1['Diff_months']==1) | (temp1['Diff_months']==-11)) & (temp1['Year_difference']==1)]\n",
    "    egb = etemp.groupby(['difference'])\n",
    "    unique_e = list(etemp['difference'].unique())\n",
    "\n",
    "    for i in unique_e:\n",
    "        temp_df = egb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-9:\n",
    "            temp_df.to_csv(folpath + sym + '-I.csv', mode='a', header=not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "        if i==-6 or i==-7:\n",
    "            temp_df.to_csv(folpath + sym + '-II.csv', mode='a', header=not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "        if i==-3 or i==-4:\n",
    "            temp_df.to_csv(folpath + sym + '-III.csv', mode='a', header=not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "        if i==0 or i==-1 or i==-2:\n",
    "            temp_df.to_csv(folpath + sym + '-IV.csv', mode='a', header=not os.path.exists(folpath + sym + '-IV.csv'), index=False)\n",
    "        if i==1 or i==2 or i==3:\n",
    "            temp_df.to_csv(folpath + sym + '-V.csv', mode='a', header=not os.path.exists(folpath + sym + '-V.csv'), index=False)\n",
    "        if i==4 or i==5 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-VI.csv', mode='a', header=not os.path.exists(folpath + sym + '-VI.csv'), index=False)\n",
    "        if i==7 or i==8 or i==9:\n",
    "            temp_df.to_csv(folpath + sym + '-VII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VII.csv'), index=False)\n",
    "        if i==10 or i==11:\n",
    "            temp_df.to_csv(folpath + sym + '-VIII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VIII.csv'), index=False)\n",
    "\n",
    "    ftemp = temp1[((temp1['Diff_months']==1) | (temp1['Diff_months']==-11)) & (temp1['Year_difference']==2)]\n",
    "    fgb = ftemp.groupby(['difference'])\n",
    "    unique_f = list(ftemp['difference'].unique())\n",
    "\n",
    "    for i in unique_f:\n",
    "        temp_df = fgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-9:\n",
    "            temp_df.to_csv(folpath + sym + '-V.csv', mode='a', header=not os.path.exists(folpath + sym + '-V.csv'), index=False)\n",
    "        if i==-6 or i==-7:\n",
    "            temp_df.to_csv(folpath + sym + '-VI.csv', mode='a', header=not os.path.exists(folpath + sym + '-VI.csv'), index=False)\n",
    "        if i==-3 or i==-4:\n",
    "            temp_df.to_csv(folpath + sym + '-VII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VII.csv'), index=False)\n",
    "        if i==0 or i==-1 or i==-2:\n",
    "            temp_df.to_csv(folpath + sym + '-VIII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VIII.csv'), index=False)\n",
    "    \n",
    "    ## CREATING THE TICKER AND REMOVING ADDITIONAL COLUMNS\n",
    "    for i in range(4):\n",
    "        if i==0:\n",
    "            file='I'\n",
    "        elif i==1:\n",
    "            file='II'\n",
    "        elif i==2:\n",
    "            file='III'\n",
    "        elif i==3:\n",
    "            file='IV'\n",
    "        if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\Quarterly\\Banknifty-\"+file+\".csv\"):\n",
    "            os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\Quarterly\\Banknifty-\"+file+\".csv\")\n",
    "        if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\Quarterly_data\\BANKNIFTY-\"+file+\".csv\"):\n",
    "            ddf = pd.read_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\Quarterly_data\\BANKNIFTY-\"+file+\".csv\")\n",
    "            ddf['Option_Type'] = ddf['ticker'].str[-2:]\n",
    "            ddf['Strike'] = np.where((ddf['ticker'].str.len()==20) | (ddf['ticker'].str.len()==22) , ddf['ticker'].str[-6:-2] , ddf['ticker'].str[-7:-2])\n",
    "            ddf['Symbol'] = 'BANKNIFTY' + 'QUARTERLY-' + file + + ddf['Strike'].astype(int).astype(str) + ddf['Option_Type']\n",
    "            ddf['ticker'] = ddf['Symbol']\n",
    "            ddf = ddf.drop(ddf.columns[9:],axis=1)\n",
    "            ddf = ddf.rename(columns = {'date':'Date','ticker':'Ticker'})\n",
    "            ddf = ddf.drop_duplicates()\n",
    "            ddf.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\Quarterly\\Banknifty-\"+file+\".csv\",index=False)\n",
    "    print(\"BANKNIFTY QUARTERLY CONTRACTS CREATED\")\n",
    "    \n",
    "def banknifty_halfyearly():\n",
    "    \n",
    "    if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\\\Half_Yearly\\\\Banknifty-I.csv\"):\n",
    "        os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\\\Half_Yearly\\\\Banknifty-I.csv\")\n",
    "\n",
    "    if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\\\Half_Yearly\\\\Banknifty-II.csv\"):\n",
    "        os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\\\Half_Yearly\\\\Banknifty-II.csv\")\n",
    "        \n",
    "    final_df = pd.DataFrame()\n",
    "    file = 'I'\n",
    "    for i in range(2):\n",
    "        df = pd.read_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\\\Quarterly_Data\\BANKNIFTY-\"+str(file)+\".csv\")\n",
    "        temp = df.copy()\n",
    "        temp = temp.rename(columns = {'ticker':'Ticker','date':'Date','time':'Time','open':'Open','low':'Low','high':'High','close':'Close','volume':'Volume'})\n",
    "        temp['Time'] = pd.to_datetime(temp['Time']).dt.time\n",
    "        temp['Date'] = pd.to_datetime(temp['Date'])\n",
    "        temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "        temp['Option_type'] = temp['Ticker'].str[-2:]\n",
    "        temp[\"Temp\"] = temp[\"Ticker\"].str.replace('BANKNIFTY',\"\")\n",
    "        temp[\"Temp\"] = temp[\"Temp\"].str[:-2]\n",
    "        temp[\"Strike\"] = np.where((temp['Temp'].str.len()==12) | (temp['Temp'].str.len()==10),\n",
    "                                    temp['Temp'].str[-5:],\n",
    "                                    temp['Temp'].str[-4:])\n",
    "        temp['Current_Year'] = temp['Date'].dt.year\n",
    "        temp['Current_Year'] = temp['Current_Year'].astype(str).str[-2:]\n",
    "        temp[\"Exp_year\"] = np.where(temp['Temp'].str.len()==12,temp[\"Temp\"].str[5:7],temp['Temp'].str[:2])\n",
    "        temp[\"Exp_month\"] = temp[\"Temp\"].str[2:5]\n",
    "        temp['Length_of_Temp'] = np.where(temp['Temp'].str.len()==12,12,temp['Temp'].str.len())\n",
    "        temp = temp[(temp['Exp_month']=='JUN') | (temp['Exp_month']=='DEC')]\n",
    "        temp = temp.reset_index(drop=True)\n",
    "        final_df = final_df.append(temp)\n",
    "        final_df = final_df.reset_index(drop=True)\n",
    "        final_df = final_df.drop(final_df.columns[9:],axis=1)\n",
    "        file+=file\n",
    "\n",
    "    if final_df.empty==False:    \n",
    "        test = final_df.copy()\n",
    "        test['Option_Type'] = test['Ticker'].str[-2:]\n",
    "        test['Last'] = test['Ticker'].str[-7:]\n",
    "        test['Strike'] = test['Last'].astype('str').str.extractall('(\\d+)').unstack().fillna('').sum(axis=1).astype(int)\n",
    "        test['Symbol'] = test['Ticker'].str[:9] + '-I' + test['Strike'].astype(str) + test['Option_Type'].astype(str)\n",
    "        test['Ticker'] = test['Symbol']\n",
    "        test = test.drop(test.columns[9:13],axis=1)\n",
    "        print(\"BANKNIFTY HALF-YEARLY-I CREATED\")\n",
    "        test.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\\\Half_Yearly\\\\Banknifty-I.csv\",index=False)\n",
    "\n",
    "\n",
    "    final_df = pd.DataFrame()\n",
    "    file = 'III'\n",
    "    for i in range(2):\n",
    "        if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\\\Quarterly_Data\\BANKNIFTY-\"+str(file)+\".csv\"):\n",
    "            df = pd.read_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\\\Quarterly_Data\\BANKNIFTY-\"+str(file)+\".csv\")\n",
    "            temp = df.copy()\n",
    "            temp = temp.rename(columns = {'ticker':'Ticker','date':'Date','time':'Time','open':'Open','low':'Low','high':'High','close':'Close','volume':'Volume'})\n",
    "            temp['Time'] = pd.to_datetime(temp['Time']).dt.time\n",
    "            temp['Date'] = pd.to_datetime(temp['Date'])\n",
    "            temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "            temp['Option_type'] = temp['Ticker'].str[-2:]\n",
    "            temp[\"Temp\"] = temp[\"Ticker\"].str.replace('BANKNIFTY',\"\")\n",
    "            temp[\"Temp\"] = temp[\"Temp\"].str[:-2]\n",
    "            temp[\"Strike\"] = np.where((temp['Temp'].str.len()==12) | (temp['Temp'].str.len()==10),\n",
    "                                        temp['Temp'].str[-5:],\n",
    "                                        temp['Temp'].str[-4:])\n",
    "            temp['Current_Year'] = temp['Date'].dt.year\n",
    "            temp['Current_Year'] = temp['Current_Year'].astype(str).str[-2:]\n",
    "            temp[\"Exp_year\"] = np.where(temp['Temp'].str.len()==12,temp[\"Temp\"].str[5:7],temp['Temp'].str[:2])\n",
    "            temp[\"Exp_month\"] = temp[\"Temp\"].str[2:5]\n",
    "            temp['Length_of_Temp'] = np.where(temp['Temp'].str.len()==12,12,temp['Temp'].str.len())\n",
    "            temp = temp[(temp['Exp_month']=='JUN') | (temp['Exp_month']=='DEC')]\n",
    "            temp = temp.reset_index(drop=True)\n",
    "            final_df = final_df.append(temp)\n",
    "            final_df = final_df.reset_index(drop=True)\n",
    "            final_df = final_df.drop(final_df.columns[9:],axis=1)\n",
    "            file='IV'\n",
    "        else:\n",
    "            print(\"BANKNIFTY-QUARTERLY-\"+str(file)+' not found')\n",
    "            file='IV'\n",
    "\n",
    "    if final_df.empty==False:\n",
    "        test = final_df.copy()\n",
    "        test['Option_Type'] = test['Ticker'].str[-2:]\n",
    "        test['Last'] = test['Ticker'].str[-7:]\n",
    "        test['Strike'] = test['Last'].astype('str').str.extractall('(\\d+)').unstack().fillna('').sum(axis=1).astype(int)\n",
    "        test['Symbol'] = test['Ticker'].str[:9] + '-II' + test['Strike'].astype(str) + test['Option_Type'].astype(str)\n",
    "        test['Ticker'] = test['Symbol']\n",
    "        test = test.drop(test.columns[9:13],axis=1)\n",
    "        print(\"BANKNIFTY HALF-YEARLY-II CREATED\")\n",
    "        test.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\\\Half_Yearly\\\\Banknifty-II.csv\",index=False)\n",
    "    print(\"BANKNIFTY HALFYEARLY CONTRACTS CREATED\")\n",
    "\n",
    "def banknifty_yearly():\n",
    "    if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\\\Yearly\\\\Banknifty-I.csv\"):\n",
    "        os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\\\Yearly\\\\Banknifty-I.csv\")\n",
    "\n",
    "    final_df = pd.DataFrame()\n",
    "    file = 'I'\n",
    "    add_file = 'I'\n",
    "    for i in range(4):\n",
    "        print(i,file)\n",
    "        if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\\\Quarterly_Data\\BANKNIFTY-\"+str(file)+\".csv\"):  \n",
    "            df = pd.read_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\BankNifty\\\\Quarterly_Data\\BANKNIFTY-\"+str(file)+\".csv\")\n",
    "            temp = df.copy()\n",
    "            temp = temp.rename(columns = {'ticker':'Ticker','date':'Date','time':'Time','open':'Open','low':'Low','high':'High','close':'Close','volume':'Volume'})\n",
    "            temp['Time'] = pd.to_datetime(temp['Time']).dt.time\n",
    "            temp['Date'] = pd.to_datetime(temp['Date'])\n",
    "            temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "            temp['Option_type'] = temp['Ticker'].str[-2:]\n",
    "            temp[\"Temp\"] = temp[\"Ticker\"].str.replace('BANKNIFTY',\"\")\n",
    "            temp[\"Temp\"] = temp[\"Temp\"].str[:-2]\n",
    "            temp[\"Strike\"] = np.where((temp['Temp'].str.len()==12) | (temp['Temp'].str.len()==10),\n",
    "                                        temp['Temp'].str[-5:],\n",
    "                                        temp['Temp'].str[-4:])\n",
    "            temp['Current_Year'] = temp['Date'].dt.year\n",
    "            temp['Current_Year'] = temp['Current_Year'].astype(str).str[-2:]\n",
    "            temp[\"Exp_year\"] = np.where(temp['Temp'].str.len()==12,temp[\"Temp\"].str[5:7],temp['Temp'].str[:2])\n",
    "            temp[\"Exp_month\"] = temp[\"Temp\"].str[2:5]\n",
    "            temp['Length_of_Temp'] = np.where(temp['Temp'].str.len()==12,12,temp['Temp'].str.len())\n",
    "            temp = temp[(temp['Exp_month']=='DEC')]\n",
    "            temp = temp.reset_index(drop=True)\n",
    "            final_df = final_df.append(temp)\n",
    "            final_df = final_df.reset_index(drop=True)\n",
    "            final_df = final_df.drop(final_df.columns[9:],axis=1)\n",
    "            if i==2:\n",
    "                file='IV'\n",
    "            else:\n",
    "                file+=add_file\n",
    "\n",
    "        else:\n",
    "            print(\"BANKNIFTY QUARTERLY-\"+str(file)+\" does not exist\")\n",
    "\n",
    "    if final_df.empty==False:\n",
    "        test = final_df.copy()\n",
    "        test['Option_Type'] = test['Ticker'].str[-2:]\n",
    "        test['Last'] = test['Ticker'].str[-7:]\n",
    "        test['Strike'] = test['Last'].astype('str').str.extractall('(\\d+)').unstack().fillna('').sum(axis=1).astype(int)\n",
    "        test['Symbol'] = test['Ticker'].str[:9] + '-I' + test['Strike'].astype(str) + test['Option_Type'].astype(str)\n",
    "        test['Ticker'] = test['Symbol']\n",
    "        test = test.drop(test.columns[9:13],axis=1)\n",
    "        print(\"BANKNIFTY YEARLY-I CREATED\")\n",
    "        test.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\BankNifty\\\\Yearly\\\\Banknifty-I.csv\",index=False)\n",
    "\n",
    "    else:\n",
    "        print(\"Dataframe is empty!!!\")\n",
    "    print(\"BANKNIFTY YEARLY CONTRACTS CREATED\")\n",
    "    \n",
    "print(\"BANKNIFTY CONTRACTS BEING CREATED\")\n",
    "banknifty_monthly()\n",
    "banknifty_weekly()\n",
    "banknifty_quarterly()\n",
    "banknifty_halfyearly()\n",
    "banknifty_yearly()\n",
    "\n",
    "et = time.time()\n",
    "print(\"\\nBANKNIFTY CONTRACTS CREATED\")\n",
    "print(\"ELAPSED TIME\",et-st)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f86806b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
