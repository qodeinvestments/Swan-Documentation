{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f623ff-6b48-43ad-97d8-802bb9d9f69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter O for Options data, U for Underlying data, B for Both the data, E for Exiting  B\n",
      "Enter the index you want in the format below - \n",
      "BankNifty\n",
      "Nifty\n",
      "FinNifty  BankNifty\n",
      "Enter schema (MonthlyI, MonthlyII , WeeklyI , QuarterlyI and so on) -  WeeklyI\n",
      "Enter start date as YYYY-MM-DD  2023-01-02\n",
      "Enter end date as YYYY-MM-DD  2023-01-02\n",
      "Enter 1 for 1 minute, 5 for 5 minutes, 15 for 15 minutes, E for EOD, A for All timeframes\n",
      " 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATING OPTIONS DATA\n",
      "Generating data from  2023-01-02  to  2023-01-02\n",
      "OPTIONS DATA GENERATED!\n",
      "elapsed_time: 49.31162357330322\n",
      "\n",
      "GENERATING UNDERLYING DATA\n",
      "UNDERLYING DATA GENERATED!\n",
      "elapsed_time: 0.6285817623138428\n",
      "\n",
      "COMPLETED.\n",
      "Total time taken  49.940205335617065\n"
     ]
    }
   ],
   "source": [
    "#import the modules\n",
    "import psycopg2 as pg\n",
    "import time\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pyspark\n",
    "import calendar\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from datetime import timedelta\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import array_contains\n",
    "from pyspark.sql.functions import date_format\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "########################################################## CONVERTING 1-min to DIFFERENT TIMEFRAMES - UNDERLYING ######################################\n",
    "\n",
    "def EOD_underlying(ddf,index):\n",
    "    print(\"CONVERTING TO EOD\")\n",
    "    final_df = ddf.copy()\n",
    "    final_df['Date'] = pd.to_datetime(final_df['Date'], format='mixed',dayfirst=True)\n",
    "    final_df = final_df[(final_df['Time']>=time1) & (final_df['Time']<=time2)]\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    final_df = final_df.sort_values(by=['Date'])\n",
    "    final_df = final_df.rename(columns={'Time' : 'Timestamp',\n",
    "                                        'Open' : 'Adj_Open',\n",
    "                                        'High' : 'Adj_High',\n",
    "                                        'Low' : 'Adj_Low',\n",
    "                                        'Close' : 'Adj_Close',\n",
    "                                        'Volume' : 'Adj_Volume'})\n",
    "    final_df['Date'] = pd.to_datetime(final_df['Date'],dayfirst=True).dt.date\n",
    "    final_df = final_df.sort_values(by=['Date', 'Timestamp'])\n",
    "    final_df['Date'] = final_df['Date'].astype(str)\n",
    "    final_df['Timestamp'] = final_df['Timestamp'].astype(str)\n",
    "    final_df['Datetime'] = pd.to_datetime(final_df['Date'] + ' ' + final_df['Timestamp'], format='mixed',dayfirst=True)\n",
    "\n",
    "    final_df = final_df.set_index(\"Datetime\")\n",
    "\n",
    "    ddf = final_df.groupby(['Date', pd.Grouper(freq='B')]).agg({\"Adj_Open\" : \"first\", \n",
    "                                                          \"Adj_High\" : \"max\",\n",
    "                                                          \"Adj_Low\" : \"min\",\n",
    "                                                          \"Adj_Close\" : \"last\", \n",
    "                                                          'Adj_Volume' : 'sum'})\n",
    "    ddf.columns = [\"Adj_Open\", \"Adj_High\", \"Adj_Low\", \"Adj_Close\", 'Adj_Volume']\n",
    "    ddf = ddf.reset_index()\n",
    "    ddf['Ticker'] = f\"{index}\".upper()+'.EQ-NSE'\n",
    "\n",
    "    ddf = ddf.sort_values(by=['Datetime'])\n",
    "    ddf.reset_index(drop=True,inplace=True)\n",
    "    ddf = ddf.rename(columns={'Adj_Open':'EQ_Open','Adj_High':'EQ_High','Adj_Low':'EQ_Low','Adj_Close':'EQ_Close','Adj_Volume':'EQ_Volume'})\n",
    "    ddf = ddf[['Ticker','Date','EQ_Open','EQ_High','EQ_Low','EQ_Close','EQ_Volume']]\n",
    "    ddf.to_csv(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_EqData\\\\{index}_EOD.csv\",index=False)\n",
    "    \n",
    "def fifteen_underlying(ddf,index):\n",
    "    print(\"CONVERTING TO 15min\")\n",
    "    final_df = ddf.copy()\n",
    "    final_df['Date'] = pd.to_datetime(final_df['Date'], format='mixed',dayfirst=True)\n",
    "    final_df = final_df[(final_df['Time']>=time1) & (final_df['Time']<=time2)]\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    final_df = final_df.sort_values(by=['Date'])\n",
    "    final_df = final_df.rename(columns={'Time' : 'Timestamp',\n",
    "                                        'Open' : 'Adj_Open',\n",
    "                                        'High' : 'Adj_High',\n",
    "                                        'Low' : 'Adj_Low',\n",
    "                                        'Close' : 'Adj_Close',\n",
    "                                        'Volume' : 'Adj_Volume'})\n",
    "    final_df['Date'] = pd.to_datetime(final_df['Date'],dayfirst=True).dt.date\n",
    "    final_df = final_df.sort_values(by=['Date', 'Timestamp'])\n",
    "    final_df['Date'] = final_df['Date'].astype(str)\n",
    "    final_df['Timestamp'] = final_df['Timestamp'].astype(str)\n",
    "    final_df['Datetime'] = pd.to_datetime(final_df['Date'] + ' ' + final_df['Timestamp'], format='mixed',dayfirst=True)\n",
    "\n",
    "    final_df = final_df.set_index(\"Datetime\")\n",
    "\n",
    "    ddf = final_df.groupby(['Date', pd.Grouper(freq='15min')]).agg({\"Adj_Open\" : \"first\", \n",
    "                                                          \"Adj_High\" : \"max\",\n",
    "                                                          \"Adj_Low\" : \"min\",\n",
    "                                                          \"Adj_Close\" : \"last\", \n",
    "                                                          'Adj_Volume' : 'sum'})\n",
    "    ddf.columns = [\"Adj_Open\", \"Adj_High\", \"Adj_Low\", \"Adj_Close\", 'Adj_Volume']\n",
    "    ddf = ddf.reset_index()\n",
    "    ddf['Ticker'] = f\"{index}\".upper()+'.EQ-NSE'\n",
    "\n",
    "    ddf = ddf.sort_values(by=['Datetime'])\n",
    "    ddf['Time'] = pd.to_datetime(ddf['Datetime']).dt.time\n",
    "    ddf.reset_index(drop=True,inplace=True)\n",
    "    ddf = ddf.rename(columns={'Adj_Open':'EQ_Open','Adj_High':'EQ_High','Adj_Low':'EQ_Low','Adj_Close':'EQ_Close','Adj_Volume':'EQ_Volume'})\n",
    "    ddf = ddf[['Ticker','Date','Time','EQ_Open','EQ_High','EQ_Low','EQ_Close','EQ_Volume']]\n",
    "    ddf.to_csv(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_EqData\\\\{index}_15min.csv\",index=False)\n",
    "\n",
    "def five_underlying(ddf,index):\n",
    "    print(\"CONVERTING TO 5min\")\n",
    "    final_df = ddf.copy()\n",
    "    final_df['Date'] = pd.to_datetime(final_df['Date'], format='mixed',dayfirst=True)\n",
    "    final_df = final_df[(final_df['Time']>=time1) & (final_df['Time']<=time2)]\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    final_df = final_df.sort_values(by=['Date'])\n",
    "    final_df = final_df.rename(columns={'Time' : 'Timestamp',\n",
    "                                        'Open' : 'Adj_Open',\n",
    "                                        'High' : 'Adj_High',\n",
    "                                        'Low' : 'Adj_Low',\n",
    "                                        'Close' : 'Adj_Close',\n",
    "                                        'Volume' : 'Adj_Volume'})\n",
    "    final_df['Date'] = pd.to_datetime(final_df['Date'],dayfirst=True).dt.date\n",
    "    final_df = final_df.sort_values(by=['Date', 'Timestamp'])\n",
    "    final_df['Date'] = final_df['Date'].astype(str)\n",
    "    final_df['Timestamp'] = final_df['Timestamp'].astype(str)\n",
    "    final_df['Datetime'] = pd.to_datetime(final_df['Date'] + ' ' + final_df['Timestamp'], format='mixed',dayfirst=True)\n",
    "\n",
    "    final_df = final_df.set_index(\"Datetime\")\n",
    "\n",
    "    ddf = final_df.groupby(['Date', pd.Grouper(freq='5min')]).agg({\"Adj_Open\" : \"first\", \n",
    "                                                          \"Adj_High\" : \"max\",\n",
    "                                                          \"Adj_Low\" : \"min\",\n",
    "                                                          \"Adj_Close\" : \"last\", \n",
    "                                                          'Adj_Volume' : 'sum'})\n",
    "    ddf.columns = [\"Adj_Open\", \"Adj_High\", \"Adj_Low\", \"Adj_Close\", 'Adj_Volume']\n",
    "    ddf = ddf.reset_index()\n",
    "    ddf['Ticker'] = f\"{index}\".upper()+'.EQ-NSE'\n",
    "\n",
    "    ddf = ddf.sort_values(by=['Datetime'])\n",
    "    ddf['Time'] = pd.to_datetime(ddf['Datetime']).dt.time\n",
    "    ddf.reset_index(drop=True,inplace=True)\n",
    "    ddf = ddf.rename(columns={'Adj_Open':'EQ_Open','Adj_High':'EQ_High','Adj_Low':'EQ_Low','Adj_Close':'EQ_Close','Adj_Volume':'EQ_Volume'})\n",
    "    ddf = ddf[['Ticker','Date','Time','EQ_Open','EQ_High','EQ_Low','EQ_Close','EQ_Volume']]\n",
    "    ddf.to_csv(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_EqData\\\\{index}_5min.csv\",index=False)\n",
    "\n",
    "def one_underlying(ddf,index):\n",
    "    final_df = ddf.copy()\n",
    "    final_df['Date'] = pd.to_datetime(final_df['Date'], format= 'mixed', dayfirst=True)\n",
    "    final_df = final_df[(final_df['Time']>=time1) & (final_df['Time']<=time2)]\n",
    "    final_df = final_df.sort_values(by=['Date','Time'])\n",
    "    final_df.reset_index(drop=True,inplace=True)\n",
    "    final_df = final_df[['Ticker','Date','Time','Open','High','Low','Close','Volume']]\n",
    "    final_df.to_csv(fr\"C:\\\\Users\\\\admin\\\\desktop\\\\{index}_EqData\\\\{index}_1min.csv\",index=False)\n",
    "    \n",
    "###################################################### CONVERTING 1-min to DIFFERENT TIMEFRAMES - OPTIONS DATA ##########################################\n",
    "\n",
    "def EOD(ddf,index,schema,hyphen_index):\n",
    "    print(\"CONVERTING TO EOD\")\n",
    "    ddf = ddf.rename(columns={'ticker' : 'Ticker',\n",
    "                            'date' : 'Date',\n",
    "                            'time' : 'Time',\n",
    "                            'open' : 'Open',\n",
    "                            'high' : 'High', \n",
    "                            'low' : 'Low',\n",
    "                            'close' : 'Close',\n",
    "                            'volume' : 'Volume', \n",
    "                            'Open Int' : 'Open Interest'})\n",
    "    ddf['Date'] = pd.to_datetime(ddf['Date'], dayfirst=True)\n",
    "    ddf = ddf.sort_values(by=['Date'])\n",
    "    \n",
    "    symbol = index.upper()\n",
    "    j='-' + schema[hyphen_index:]\n",
    "    schema_find = schema[:hyphen_index].upper()\n",
    "    \n",
    "    final_df = ddf.copy()\n",
    "    final_df['Final_strike'] = final_df['Ticker'].str.replace(j, '')\n",
    "    final_df['Final_strike'] = final_df['Final_strike'].str.replace(f'{index.upper()}'+schema_find, '').str.replace(f'{index.upper()}','').str.replace('CE', '').str.replace('PE', '')\n",
    "    final_df['Final_strike'] = final_df['Final_strike'].astype(float)\n",
    "    final_df['Option_Type'] = final_df['Ticker'].str[-2:]\n",
    "    \n",
    "    final_df = final_df.rename(columns={'Time' : 'Timestamp',\n",
    "                                        'Open' : 'Adj_Open',\n",
    "                                        'High' : 'Adj_High',\n",
    "                                        'Low' : 'Adj_Low',\n",
    "                                        'Close' : 'Adj_Close',\n",
    "                                        'Volume' : 'Adj_Volume',\n",
    "                                        'Open Interest' : 'Adj_OI',        \n",
    "                                        'Option_type' : 'Option_Type'})\n",
    "    final_df['Date'] = pd.to_datetime(final_df['Date'],dayfirst=True).dt.date\n",
    "    final_df = final_df.sort_values(by=['Date', 'Timestamp'])\n",
    "    final_df['Date'] = final_df['Date'].astype(str)\n",
    "    final_df['Timestamp'] = final_df['Timestamp'].astype(str)\n",
    "    final_df['Datetime'] = pd.to_datetime(final_df['Date'] + ' ' + final_df['Timestamp'], format = 'mixed',dayfirst=True)\n",
    "\n",
    "    final_df = final_df.set_index(\"Datetime\")\n",
    "    final_df['Adj_OI_1'] = final_df['Adj_OI']\n",
    "\n",
    "    df_eod = final_df.groupby(['Final_strike', 'Option_Type', pd.Grouper(freq='B')]).agg({\"Adj_Open\" : \"first\", \n",
    "                                                          \"Adj_High\" : \"max\",\n",
    "                                                          \"Adj_Low\" : \"min\",\n",
    "                                                          \"Adj_Close\" : \"last\", \n",
    "                                                          'Adj_Volume' : 'sum',\n",
    "                                                          'Adj_OI' : 'first',\n",
    "                                                          'Adj_OI_1' : 'last'})\n",
    "    df_eod.columns = [\"Adj_Open\", \"Adj_High\", \"Adj_Low\", \"Adj_Close\", 'Adj_Volume', 'First_OI', 'Last_OI']\n",
    "    df_eod = df_eod.reset_index()\n",
    "    df_eod['rem'] = df_eod['Final_strike']%df_eod['Final_strike'].astype(int)\n",
    "    df_eod.loc[df_eod['rem'] == 0, 'Ticker'] = symbol + schema_find + j +  df_eod['Final_strike'].astype(int).astype(str) + df_eod['Option_Type']\n",
    "    df_eod.loc[df_eod['rem'] != 0, 'Ticker'] = symbol + schema_find + j + df_eod['Final_strike'].round(2).astype(str) + df_eod['Option_Type']\n",
    "\n",
    "    df_eod = df_eod.sort_values(by=['Datetime', 'Final_strike'])\n",
    "    df_eod = df_eod.rename(columns={'Datetime' : 'Date'})\n",
    "    df_eod['Date'] = pd.to_datetime(df_eod['Date'],dayfirst=True)\n",
    "    ## CHECKING IF NULL VALUES\n",
    "    df_eod['New_OI'] = df_eod['Last_OI']\n",
    "    df_eod = df_eod.rename(columns={'Adj_Open':'Open','Adj_High':'High','Adj_Low':'Low','Adj_Close':'Close','Adj_Volume':'Volume','New_OI':'Open_Interest'})\n",
    "    df_eod = df_eod.drop(['First_OI','Last_OI','Option_Type','Final_strike','rem'],axis=1)\n",
    "    df_eod = df_eod[['Ticker','Date','Open','High','Low','Close','Volume','Open_Interest']]\n",
    "    df_eod.reset_index(drop=True,inplace=True)\n",
    "    df_eod.to_csv(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_Opt_EOD.csv\", mode='a', header = not os.path.exists(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_Opt_EOD.csv\"), index=False)\n",
    "\n",
    "def fifteen_min(ddf,index,schema,hyphen_index):\n",
    "    print(\"CONVERTING TO 15Min\")\n",
    "    ddf = ddf.rename(columns={'ticker' : 'Ticker',\n",
    "                            'date' : 'Date',\n",
    "                            'time' : 'Time',\n",
    "                            'open' : 'Open',\n",
    "                            'high' : 'High', \n",
    "                            'low' : 'Low',\n",
    "                            'close' : 'Close',\n",
    "                            'volume' : 'Volume', \n",
    "                            'Open Int' : 'Open Interest'})\n",
    "    ddf['Date'] = pd.to_datetime(ddf['Date'], dayfirst=True)\n",
    "    ddf = ddf.sort_values(by=['Date'])\n",
    "    \n",
    "    symbol = index.upper()\n",
    "    j='-' + schema[hyphen_index:]\n",
    "    schema_find = schema[:hyphen_index].upper()\n",
    "\n",
    "    final_df = ddf.copy()\n",
    "    final_df['Final_strike'] = final_df['Ticker'].str.replace(j, '')\n",
    "    final_df['Final_strike'] = final_df['Final_strike'].str.replace(f'{index.upper()}'+schema_find, '').str.replace(f'{index.upper()}','').str.replace('CE', '').str.replace('PE', '')\n",
    "    final_df['Final_strike'] = final_df['Final_strike'].astype(float)\n",
    "    final_df['Option_Type'] = final_df['Ticker'].str[-2:]\n",
    "    \n",
    "    final_df = final_df.rename(columns={'Time' : 'Timestamp',\n",
    "                                        'Open' : 'Adj_Open',\n",
    "                                        'High' : 'Adj_High',\n",
    "                                        'Low' : 'Adj_Low',\n",
    "                                        'Close' : 'Adj_Close',\n",
    "                                        'Volume' : 'Adj_Volume',\n",
    "                                        'Open Interest' : 'Adj_OI',        \n",
    "                                        'Option_type' : 'Option_Type'})\n",
    "    final_df['Date'] = pd.to_datetime(final_df['Date'],dayfirst=True).dt.date\n",
    "    final_df = final_df.sort_values(by=['Date', 'Timestamp'])\n",
    "    final_df['Date'] = final_df['Date'].astype(str)\n",
    "    final_df['Timestamp'] = final_df['Timestamp'].astype(str)\n",
    "    final_df['Datetime'] = pd.to_datetime(final_df['Date'] + ' ' + final_df['Timestamp'], format='mixed',dayfirst=True)\n",
    "\n",
    "    final_df = final_df.set_index(\"Datetime\")\n",
    "    final_df['Adj_OI_1'] = final_df['Adj_OI']\n",
    "\n",
    "    df_eod = final_df.groupby(['Final_strike', 'Option_Type', pd.Grouper(freq='15min')]).agg({\"Adj_Open\" : \"first\", \n",
    "                                                          \"Adj_High\" : \"max\",\n",
    "                                                          \"Adj_Low\" : \"min\",\n",
    "                                                          \"Adj_Close\" : \"last\", \n",
    "                                                          'Adj_Volume' : 'sum',\n",
    "                                                          'Adj_OI' : 'first',\n",
    "                                                          'Adj_OI_1' : 'last'})\n",
    "    df_eod.columns = [\"Adj_Open\", \"Adj_High\", \"Adj_Low\", \"Adj_Close\", 'Adj_Volume', 'First_OI', 'Last_OI']\n",
    "    df_eod = df_eod.reset_index()\n",
    "    df_eod['rem'] = df_eod['Final_strike']%df_eod['Final_strike'].astype(int)\n",
    "    df_eod.loc[df_eod['rem'] == 0, 'Ticker'] = symbol + schema_find + j +  df_eod['Final_strike'].astype(int).astype(str) + df_eod['Option_Type']\n",
    "    df_eod.loc[df_eod['rem'] != 0, 'Ticker'] = symbol + schema_find + j + df_eod['Final_strike'].round(2).astype(str) + df_eod['Option_Type'] \n",
    "\n",
    "    df_eod = df_eod.sort_values(by=['Datetime', 'Final_strike'])\n",
    "    df_eod = df_eod.rename(columns={'Datetime' : 'Date'})\n",
    "    df_eod['Time'] = pd.to_datetime(df_eod['Date']).dt.time\n",
    "    df_eod['Date'] = pd.to_datetime(df_eod['Date'],dayfirst=True).dt.date\n",
    "    ## CHECKING IF NULL VALUES\n",
    "    df_eod['New_OI'] = df_eod['Last_OI']\n",
    "    df_eod = df_eod.rename(columns={'Adj_Open':'Open','Adj_High':'High','Adj_Low':'Low','Adj_Close':'Close','Adj_Volume':'Volume','New_OI':'Open_Interest'})\n",
    "    df_eod = df_eod.drop(['First_OI','Last_OI','Option_Type','Final_strike','rem'],axis=1)\n",
    "    df_eod = df_eod[['Ticker','Date','Time','Open','High','Low','Close','Volume','Open_Interest']]\n",
    "    df_eod.reset_index(drop=True,inplace=True)\n",
    "    df_eod.to_csv(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_Opt_15min.csv\", mode='a', header = not os.path.exists(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_Opt_15min.csv\"), index=False)\n",
    "    \n",
    "def five_min(ddf,index,schema,hyphen_index):\n",
    "    print(\"CONVERTING TO 5Min\")\n",
    "    ddf = ddf.rename(columns={'ticker' : 'Ticker',\n",
    "                            'date' : 'Date',\n",
    "                            'time' : 'Time',\n",
    "                            'open' : 'Open',\n",
    "                            'high' : 'High', \n",
    "                            'low' : 'Low',\n",
    "                            'close' : 'Close',\n",
    "                            'volume' : 'Volume', \n",
    "                            'Open Int' : 'Open Interest'})\n",
    "    ddf['Date'] = pd.to_datetime(ddf['Date'], dayfirst=True)\n",
    "    ddf = ddf.sort_values(by=['Date'])\n",
    "    \n",
    "    symbol = index.upper()\n",
    "    j='-' + schema[hyphen_index:]\n",
    "    schema_find = schema[:hyphen_index].upper()\n",
    "\n",
    "    final_df = ddf.copy()\n",
    "    final_df['Final_strike'] = final_df['Ticker'].str.replace(j, '')\n",
    "    final_df['Final_strike'] = final_df['Final_strike'].str.replace(f'{index.upper()}'+schema_find, '').str.replace(f'{index.upper()}','').str.replace('CE', '').str.replace('PE', '')\n",
    "    final_df['Final_strike'] = final_df['Final_strike'].astype(float)\n",
    "    final_df['Option_Type'] = final_df['Ticker'].str[-2:]\n",
    "    \n",
    "    final_df = final_df.rename(columns={'Time' : 'Timestamp',\n",
    "                                        'Open' : 'Adj_Open',\n",
    "                                        'High' : 'Adj_High',\n",
    "                                        'Low' : 'Adj_Low',\n",
    "                                        'Close' : 'Adj_Close',\n",
    "                                        'Volume' : 'Adj_Volume',\n",
    "                                        'Open Interest' : 'Adj_OI',        \n",
    "                                        'Option_type' : 'Option_Type'})\n",
    "    final_df['Date'] = pd.to_datetime(final_df['Date'],dayfirst=True).dt.date\n",
    "    final_df = final_df.sort_values(by=['Date', 'Timestamp'])\n",
    "    final_df['Date'] = final_df['Date'].astype(str)\n",
    "    final_df['Timestamp'] = final_df['Timestamp'].astype(str)\n",
    "    final_df['Datetime'] = pd.to_datetime(final_df['Date'] + ' ' + final_df['Timestamp'], format='mixed',dayfirst=True)\n",
    "\n",
    "    final_df = final_df.set_index(\"Datetime\")\n",
    "    final_df['Adj_OI_1'] = final_df['Adj_OI']\n",
    "\n",
    "    df_eod = final_df.groupby(['Final_strike', 'Option_Type', pd.Grouper(freq='5min')]).agg({\"Adj_Open\" : \"first\", \n",
    "                                                          \"Adj_High\" : \"max\",\n",
    "                                                          \"Adj_Low\" : \"min\",\n",
    "                                                          \"Adj_Close\" : \"last\", \n",
    "                                                          'Adj_Volume' : 'sum',\n",
    "                                                          'Adj_OI' : 'first',\n",
    "                                                          'Adj_OI_1' : 'last'})\n",
    "    df_eod.columns = [\"Adj_Open\", \"Adj_High\", \"Adj_Low\", \"Adj_Close\", 'Adj_Volume', 'First_OI', 'Last_OI']\n",
    "    df_eod = df_eod.reset_index()\n",
    "    df_eod['rem'] = df_eod['Final_strike']%df_eod['Final_strike'].astype(int)\n",
    "    df_eod.loc[df_eod['rem'] == 0, 'Ticker'] = symbol + schema_find + j +  df_eod['Final_strike'].astype(int).astype(str) + df_eod['Option_Type']\n",
    "    df_eod.loc[df_eod['rem'] != 0, 'Ticker'] = symbol + schema_find + j + df_eod['Final_strike'].round(2).astype(str) + df_eod['Option_Type'] \n",
    "\n",
    "    df_eod = df_eod.sort_values(by=['Datetime', 'Final_strike'])\n",
    "    df_eod = df_eod.rename(columns={'Datetime' : 'Date'})\n",
    "    df_eod['Time'] = pd.to_datetime(df_eod['Date']).dt.time\n",
    "    df_eod['Date'] = pd.to_datetime(df_eod['Date'],dayfirst=True).dt.date\n",
    "    \n",
    "    ## CHECKING IF NULL VALUES\n",
    "    df_eod['New_OI'] = df_eod['Last_OI']\n",
    "    df_eod = df_eod.rename(columns={'Adj_Open':'Open','Adj_High':'High','Adj_Low':'Low','Adj_Close':'Close','Adj_Volume':'Volume','New_OI':'Open_Interest'})\n",
    "    df_eod = df_eod.drop(['First_OI','Last_OI','Option_Type','Final_strike','rem'],axis=1)\n",
    "    df_eod = df_eod[['Ticker','Date','Time','Open','High','Low','Close','Volume','Open_Interest']]\n",
    "    df_eod.reset_index(drop=True,inplace=True)\n",
    "    df_eod.to_csv(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_Opt_5min.csv\", mode='a', header = not os.path.exists(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_Opt_5min.csv\"), index=False)\n",
    "\n",
    "def one_min(ddf,index,schema,hyphen_index):\n",
    "    ddf = ddf.rename(columns={'ticker' : 'Ticker',\n",
    "                            'date' : 'Date',\n",
    "                            'time' : 'Time',\n",
    "                            'open' : 'Open',\n",
    "                            'high' : 'High', \n",
    "                            'low' : 'Low',\n",
    "                            'close' : 'Close',\n",
    "                            'volume' : 'Volume', \n",
    "                            'Open Int' : 'Open_Interest'})\n",
    "    ddf['Date'] = pd.to_datetime(ddf['Date'], dayfirst=True)\n",
    "    ddf = ddf.sort_values(by=['Date'])\n",
    "    ddf = ddf[(ddf['Time']>=time1) & ((ddf['Time']<=time2))]\n",
    "    ddf = ddf.sort_values(by=['Date','Time'])\n",
    "    ddf.reset_index(drop=True,inplace=True)\n",
    "    ddf = ddf[['Ticker','Date','Time','Open','High','Low','Close','Volume','Open_Interest']]\n",
    "    ddf.to_csv(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_Opt_1min.csv\", mode='a', header = not os.path.exists(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_Opt_1min.csv\"), index=False)\n",
    "    \n",
    "########################################################## OPTIONS DATA FUNCTION ###############################################################\n",
    "\n",
    "def option_data(index,date1,date2,conversion,schema):\n",
    "    hyphen_index = schema.find(\"I\")\n",
    "\n",
    "    st=time.time()\n",
    "    ## CREATING A DIRECTORY OF THE REQUIRED INDEX AND SCHEMA\n",
    "    if not os.path.exists(rf\"C:\\\\users\\\\admin\\\\desktop\\\\{index}_{schema}_Data\\\\\"):\n",
    "        os.makedirs(rf\"C:\\users\\admin\\desktop\\\\{index}_{schema}_Data\\\\\")\n",
    "\n",
    "    date1 = datetime.strptime(date1, \"%Y-%m-%d\").date()\n",
    "    date2 = datetime.strptime(date2, \"%Y-%m-%d\").date()\n",
    "    year1 = date1.year\n",
    "    year2 = date2.year\n",
    "    print(\"\\nGENERATING OPTIONS DATA\")\n",
    "    for i in range(int(year1),int(year2)+1):\n",
    "        ddate1 = '-01-01'\n",
    "        ddate2 = '-12-31'\n",
    "        year_start = str(str(i)+ddate1)\n",
    "        year_end = str(str(i)+ddate2)\n",
    "        year_start = datetime.strptime(year_start, \"%Y-%m-%d\").date()\n",
    "        year_end = datetime.strptime(year_end, \"%Y-%m-%d\").date()\n",
    "        if date1 > year_start :\n",
    "            year_start = date1\n",
    "        else:\n",
    "            year_start = year_start\n",
    "        if year_end > date2 :\n",
    "            year_end = date2\n",
    "        else:\n",
    "            year_end = year_end\n",
    "\n",
    "        ddf = pd.DataFrame()\n",
    "        engine = pg.connect(f\"dbname='{index}db' user='postgres' host='swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com' port='5432' password='swancap123'\")\n",
    "        print(\"Generating data from \", year_start , \" to \" , year_end)\n",
    "        ddf = pd.read_sql(f'select * from \"{index}{schema}\".select_datewise(\\'{year_start}\\',\\'{year_end}\\')',con=engine)\n",
    "        ddf = ddf.sort_values(by=[\"date\",'time'])\n",
    "        ddf.reset_index(drop=True,inplace=True)\n",
    "        # with open(f\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_\"+str(i)+\".csv\", \"w\") as file:\n",
    "        #     cursor.copy_expert(sql, file)\n",
    "        if conversion == 'E':\n",
    "            EOD(ddf,index,schema,hyphen_index)\n",
    "    \n",
    "        elif conversion == '15':\n",
    "            fifteen_min(ddf,index,schema,hyphen_index)\n",
    "    \n",
    "        elif conversion == '5':\n",
    "            five_min(ddf,index,schema,hyphen_index)\n",
    "    \n",
    "        elif conversion == '1':\n",
    "            one_min(ddf,index,schema,hyphen_index)\n",
    "\n",
    "        elif conversion == 'a' or conversion == 'A':\n",
    "            EOD(ddf,index,schema,hyphen_index)\n",
    "            fifteen_min(ddf,index,schema,hyphen_index)\n",
    "            five_min(ddf,index,schema,hyphen_index)\n",
    "            one_min(ddf,index,schema,hyphen_index)\n",
    "\n",
    "    et=time.time()\n",
    "    elapsed_time=et-st;\n",
    "    print(\"OPTIONS DATA GENERATED!\")\n",
    "    print(\"elapsed_time:\",elapsed_time)\n",
    "\n",
    "########################################################## UNDERLYING DATA FUNCTION ###############################################################\n",
    "\n",
    "def underlying_data(index,date1,date2,conversion):\n",
    "\n",
    "    if not os.path.exists(rf\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_EqData\\\\\"):\n",
    "        os.makedirs(rf\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\{index}_EqData\\\\\")\n",
    "    \n",
    "    start_date = datetime.strptime(date1,\"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(date2,\"%Y-%m-%d\")\n",
    "    start_date=start_date.date()\n",
    "    end_date = end_date.date()\n",
    "    print(\"\\nGENERATING UNDERLYING DATA\")\n",
    "    st = time.time()\n",
    "    \n",
    "    engine = pg.connect(\"dbname='IndexEQ' user='postgres' host='swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com' port='5432' password='swancap123'\")\n",
    "    ddf = pd.read_sql(f'select * from \"{index}\".\"AllData\" where \"Date\" between \\'{date1}\\' and \\'{date2}\\'', con=engine)\n",
    "    ddf['Ticker'] = f'{index.upper()}' + '.EQ-NSE'\n",
    "    ddf = ddf.sort_values(by=[\"Date\",'Time'])\n",
    "\n",
    "    if conversion == 'E':\n",
    "        EOD_underlying(ddf,index)\n",
    "    elif conversion == '15':\n",
    "        fifteen_underlying(ddf,index)\n",
    "    elif conversion == '5':\n",
    "        five_underlying(ddf,index)\n",
    "    elif conversion == '1':\n",
    "        one_underlying(ddf,index)\n",
    "    elif conversion == 'a' or conversion == 'A':\n",
    "        EOD_underlying(ddf,index)\n",
    "        fifteen_underlying(ddf,index)\n",
    "        five_underlying(ddf,index)\n",
    "        one_underlying(ddf,index)\n",
    "\n",
    "    et=time.time()\n",
    "    elapsed_time=et-st;\n",
    "    print(\"UNDERLYING DATA GENERATED!\")\n",
    "    print(\"elapsed_time:\",elapsed_time)\n",
    "    engine.close()\n",
    "\n",
    "######################################################## MAIN CODE STARTS FROM HERE ######################################################################\n",
    "admin_path = 'admin'\n",
    "time1 = datetime.strptime('09:15:00','%H:%M:%S').time()\n",
    "time2 = datetime.strptime('15:30:00','%H:%M:%S').time()\n",
    "\n",
    "data = input(\"Enter O for Options data, U for Underlying data, B for Both the data, E for Exiting \")\n",
    "\n",
    "################################################ TAKING INPUTS FOR INDEX, DATE RANGE AND TIMEFRAME #############################################\n",
    "\n",
    "if data == 'o' or data == 'O' or data == 'b' or data == 'B':\n",
    "    index = input(\"Enter the index you want in the format below - \\nBankNifty\\nNifty\\nFinNifty \")\n",
    "    schema = input(\"Enter schema (MonthlyI, MonthlyII , WeeklyI , QuarterlyI and so on) - \")\n",
    "    date1 = input(\"Enter start date as YYYY-MM-DD \")\n",
    "    date2 = input(\"Enter end date as YYYY-MM-DD \")\n",
    "    conversion = input(\"Enter 1 for 1 minute, 5 for 5 minutes, 15 for 15 minutes, E for EOD, A for All timeframes\\n\")\n",
    "\n",
    "elif data == 'u' or data == 'U':\n",
    "    index = input(\"Enter the index you want in the format below - \\nBankNifty\\nNifty\\nFinNifty\\nIndiaVix \")\n",
    "    date1 = input(\"Enter start date as YYYY-MM-DD \")\n",
    "    date2 = input(\"Enter end date as YYYY-MM-DD \")\n",
    "    conversion = input(\"Enter 1 for 1 minute, 5 for 5 minutes, 15 for 15 minutes, E for EOD, A for All timeframes\\n\")\n",
    "\n",
    "elif data == 'e' or data == 'E':\n",
    "    print(\"Exit!\")\n",
    "\n",
    "else:\n",
    "    print(\"Wrong option\")\n",
    "\n",
    "start_time = time.time()\n",
    "    \n",
    "if data == 'O' or data == 'o':\n",
    "    option_data(index,date1,date2,conversion,schema)\n",
    "\n",
    "elif data == 'U' or data == 'u':\n",
    "    underlying_data(index,date1,date2,conversion)\n",
    "\n",
    "elif data == 'B' or data == 'b':\n",
    "    option_data(index,date1,date2,conversion,schema)\n",
    "    underlying_data(index,date1,date2,conversion)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"\\nCOMPLETED.\")\n",
    "print(\"Total time taken \",end_time-start_time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcde53d3-d89a-43b8-a58c-5efd8d6e8956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import psycopg2 as pg\n",
    "# import time\n",
    "# from io import StringIO\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# from datetime import datetime\n",
    "# from datetime import date\n",
    "# import numpy as np\n",
    "# from tqdm.notebook import tqdm\n",
    "# import pyspark\n",
    "# import calendar\n",
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql import Row\n",
    "# from datetime import timedelta\n",
    "# from pyspark.sql.functions import regexp_replace\n",
    "# from pyspark.sql.functions import array_contains\n",
    "# from pyspark.sql.functions import date_format\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# index = 'BankNifty'\n",
    "# schema = 'MonthlyI'\n",
    "# hyphen_index = schema.find(\"I\")\n",
    "# date1 = '2011-01-01'\n",
    "# date2 = '2011-01-31'\n",
    "# st = time.time()\n",
    "# engine = pg.connect(f\"dbname='{index}db' user='postgres' host='swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com' port='5432' password='swancap123'\")\n",
    "# # ddf = pd.read_sql(f'select * from \"{index}\".\"AllData\" where \"Date\" between \\'{date1}\\' and \\'{date2}\\'', con=engine)\n",
    "# # sql=f\"COPY (select *from \\\"{index}{schema}\\\".select_datewise(\\'{year_start}\\',\\'{year_end}\\')) TO STDOUT WITH DELIMITER ',' CSV HEADER\"\n",
    "# print(f'select * from \"{index}{schema}\".select_datewise(\\'{date1}\\',\\'{date2}\\')')\n",
    "# ddf = pd.read_sql(f'select * from \"{index}{schema}\".select_datewise(\\'{date1}\\',\\'{date2}\\')',con=engine)\n",
    "# display(ddf)\n",
    "# engine.close()\n",
    "# print(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e78c005-1eeb-4897-9a6d-84f7a5242217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #import the modules\n",
    "# import psycopg2\n",
    "# import time\n",
    "# from io import StringIO\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# from datetime import datetime\n",
    "# from datetime import date\n",
    "# import numpy as np\n",
    "# from tqdm.notebook import tqdm\n",
    "# import pyspark\n",
    "# import calendar\n",
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql import Row\n",
    "# from datetime import timedelta\n",
    "# from pyspark.sql.functions import regexp_replace\n",
    "# from pyspark.sql.functions import array_contains\n",
    "# from pyspark.sql.functions import date_format\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# ## DEFINING FUNCTIONS FOR INDEX UNDERLYING\n",
    "\n",
    "# def EOD_underlying(index):\n",
    "#     print(\"CONVERTING TO EOD\")\n",
    "#     df = pd.read_csv(rf\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_EqData\\\\{index}\" + \".csv\")\n",
    "#     df['Date'] = pd.to_datetime(df['Date'], format='mixed',dayfirst=True)\n",
    "#     df = df[(df['Time']>='09:15:00') & (df['Time']<='15:30:00')]\n",
    "\n",
    "#     df = df.sort_values(by=['Date'])\n",
    "\n",
    "#     final_df = df.copy()\n",
    "#     final_df = final_df.rename(columns={'Time' : 'Timestamp',\n",
    "#                                         'Open' : 'Adj_Open',\n",
    "#                                         'High' : 'Adj_High',\n",
    "#                                         'Low' : 'Adj_Low',\n",
    "#                                         'Close' : 'Adj_Close',\n",
    "#                                         'Volume' : 'Adj_Volume'})\n",
    "#     final_df['Date'] = pd.to_datetime(final_df['Date'],dayfirst=True).dt.date\n",
    "#     final_df['Timestamp'] = pd.to_datetime(final_df['Timestamp']).dt.time\n",
    "#     final_df = final_df.sort_values(by=['Date', 'Timestamp'])\n",
    "#     final_df['Date'] = final_df['Date'].astype(str)\n",
    "#     final_df['Timestamp'] = final_df['Timestamp'].astype(str)\n",
    "#     final_df['Datetime'] = pd.to_datetime(final_df['Date'] + ' ' + final_df['Timestamp'], format='mixed',dayfirst=True)\n",
    "\n",
    "#     final_df = final_df.set_index(\"Datetime\")\n",
    "\n",
    "#     ddf = final_df.groupby(['Date', pd.Grouper(freq='B')]).agg({\"Adj_Open\" : \"first\", \n",
    "#                                                           \"Adj_High\" : \"max\",\n",
    "#                                                           \"Adj_Low\" : \"min\",\n",
    "#                                                           \"Adj_Close\" : \"last\", \n",
    "#                                                           'Adj_Volume' : 'sum'})\n",
    "#     ddf.columns = [\"Adj_Open\", \"Adj_High\", \"Adj_Low\", \"Adj_Close\", 'Adj_Volume']\n",
    "#     ddf = ddf.reset_index()\n",
    "#     ddf['Ticker'] = f\"{index}\".upper()+'.EQ-NSE'\n",
    "\n",
    "#     ddf = ddf.sort_values(by=['Datetime'])\n",
    "\n",
    "#     ddf = ddf.rename(columns={'Adj_Open':'Open','Adj_High':'High','Adj_Low':'Low','Adj_Close':'Close','Adj_Volume':'Volume'})\n",
    "#     ddf = ddf[['Ticker','Date','Open','High','Low','Close','Volume']]\n",
    "#     ddf.to_csv(fr\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_EqData\\\\{index}_EOD.csv\",index=False)\n",
    "#     os.remove(rf\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_EqData\\\\{index}\" + \".csv\")\n",
    "    \n",
    "# def fifteen_min_underlying(index):\n",
    "#     print(\"CONVERTING TO 5Min\")\n",
    "#     df = pd.read_csv(rf\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_EqData\\\\{index}\" + \".csv\")\n",
    "#     df['Date'] = pd.to_datetime(df['Date'], format='mixed',dayfirst=True)\n",
    "#     df = df[(df['Time']>='09:15:00') & (df['Time']<='15:30:00')]\n",
    "\n",
    "#     df = df.sort_values(by=['Date'])\n",
    "\n",
    "#     final_df = df.copy()\n",
    "#     final_df = final_df.rename(columns={'Time' : 'Timestamp',\n",
    "#                                         'Open' : 'Adj_Open',\n",
    "#                                         'High' : 'Adj_High',\n",
    "#                                         'Low' : 'Adj_Low',\n",
    "#                                         'Close' : 'Adj_Close',\n",
    "#                                         'Volume' : 'Adj_Volume'})\n",
    "#     final_df['Date'] = pd.to_datetime(final_df['Date'],dayfirst=True).dt.date\n",
    "#     final_df['Timestamp'] = pd.to_datetime(final_df['Timestamp']).dt.time\n",
    "#     final_df = final_df.sort_values(by=['Date', 'Timestamp'])\n",
    "#     final_df['Date'] = final_df['Date'].astype(str)\n",
    "#     final_df['Timestamp'] = final_df['Timestamp'].astype(str)\n",
    "#     final_df['Datetime'] = pd.to_datetime(final_df['Date'] + ' ' + final_df['Timestamp'], format='mixed', dayfirst=True)\n",
    "\n",
    "#     final_df = final_df.set_index(\"Datetime\")\n",
    "\n",
    "#     ddf = final_df.groupby(['Date', pd.Grouper(freq='15min')]).agg({\"Adj_Open\" : \"first\", \n",
    "#                                                           \"Adj_High\" : \"max\",\n",
    "#                                                           \"Adj_Low\" : \"min\",\n",
    "#                                                           \"Adj_Close\" : \"last\", \n",
    "#                                                           'Adj_Volume' : 'sum'})\n",
    "#     ddf.columns = [\"Adj_Open\", \"Adj_High\", \"Adj_Low\", \"Adj_Close\", 'Adj_Volume']\n",
    "#     ddf = ddf.reset_index()\n",
    "#     ddf['Ticker'] = f\"{index}\".upper()+'.EQ-NSE'\n",
    "\n",
    "#     ddf = ddf.sort_values(by=['Datetime'])\n",
    "#     ddf['Time'] = pd.to_datetime(ddf['Datetime']).dt.time\n",
    "\n",
    "#     ddf = ddf.rename(columns={'Adj_Open':'Open','Adj_High':'High','Adj_Low':'Low','Adj_Close':'Close','Adj_Volume':'Volume'})\n",
    "#     ddf = ddf[['Ticker','Date','Time','Open','High','Low','Close','Volume']]\n",
    "#     ddf.to_csv(fr\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_EqData\\\\{index}_15min.csv\",index=False)\n",
    "#     os.remove(rf\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_EqData\\\\{index}\" + \".csv\")\n",
    "\n",
    "# def five_min_underlying(index):\n",
    "#     print(\"CONVERTING TO 5Min\")\n",
    "#     df = pd.read_csv(rf\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_EqData\\\\{index}\" + \".csv\",parse_dates=['Date'])\n",
    "#     df['Date'] = pd.to_datetime(df['Date'], format='mixed',dayfirst=True)\n",
    "#     df = df[(df['Time']>='09:15:00') & (df['Time']<='15:30:00')]\n",
    "\n",
    "#     df = df.sort_values(by=['Date'])\n",
    "\n",
    "#     final_df = df.copy()\n",
    "#     final_df = final_df.rename(columns={'Time' : 'Timestamp',\n",
    "#                                         'Open' : 'Adj_Open',\n",
    "#                                         'High' : 'Adj_High',\n",
    "#                                         'Low' : 'Adj_Low',\n",
    "#                                         'Close' : 'Adj_Close',\n",
    "#                                         'Volume' : 'Adj_Volume'})\n",
    "#     final_df['Date'] = pd.to_datetime(final_df['Date'],dayfirst=True).dt.date\n",
    "#     final_df['Timestamp'] = pd.to_datetime(final_df['Timestamp']).dt.time\n",
    "#     final_df = final_df.sort_values(by=['Date', 'Timestamp'])\n",
    "#     final_df['Date'] = final_df['Date'].astype(str)\n",
    "#     final_df['Timestamp'] = final_df['Timestamp'].astype(str)\n",
    "#     final_df['Datetime'] = pd.to_datetime(final_df['Date'] + ' ' + final_df['Timestamp'], format='mixed',dayfirst=True)\n",
    "\n",
    "#     final_df = final_df.set_index(\"Datetime\")\n",
    "\n",
    "#     ddf = final_df.groupby(['Date', pd.Grouper(freq='5min')]).agg({\"Adj_Open\" : \"first\", \n",
    "#                                                           \"Adj_High\" : \"max\",\n",
    "#                                                           \"Adj_Low\" : \"min\",\n",
    "#                                                           \"Adj_Close\" : \"last\", \n",
    "#                                                           'Adj_Volume' : 'sum'})\n",
    "#     ddf.columns = [\"Adj_Open\", \"Adj_High\", \"Adj_Low\", \"Adj_Close\", 'Adj_Volume']\n",
    "#     ddf = ddf.reset_index()\n",
    "#     ddf['Ticker'] = f\"{index}\".upper()+'.EQ-NSE'\n",
    "\n",
    "#     ddf = ddf.sort_values(by=['Datetime'])\n",
    "#     ddf['Time'] = pd.to_datetime(ddf['Datetime']).dt.time\n",
    "\n",
    "#     ddf = ddf.rename(columns={'Adj_Open':'Open','Adj_High':'High','Adj_Low':'Low','Adj_Close':'Close','Adj_Volume':'Volume'})\n",
    "#     ddf = ddf[['Ticker','Date','Time','Open','High','Low','Close','Volume']]\n",
    "#     ddf.to_csv(fr\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_EqData\\\\{index}_5min.csv\",index=False)\n",
    "#     os.remove(rf\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_EqData\\\\{index}\" + \".csv\")\n",
    "\n",
    "# def one_min_underlying(index):\n",
    "#     df = pd.read_csv(rf\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_EqData\\\\{index}\" + \".csv\")\n",
    "#     df['Date'] = pd.to_datetime(df['Date'], format='mixed',dayfirst=True)\n",
    "#     df = df[(df['Time']>='09:15:00') & (df['Time']<='15:30:00')]\n",
    "#     df = df.sort_values(by=['Date','Time'])\n",
    "    \n",
    "#     df = df[['Ticker','Date','Time','Open','High','Low','Close','Volume']]\n",
    "#     display(df)\n",
    "#     df.to_csv(rf\"C:\\\\Users\\Admin\\Desktop\\\\{index}_EqData\\\\{index}.csv\",index=False)\n",
    "    \n",
    "# ## DEFINING FUNCTIONS FOR INDEX OPTIONS DATA\n",
    "\n",
    "# def EOD(year1, year2,index,schema,hyphen_index):\n",
    "#     print(\"CONVERTING TO EOD\")\n",
    "#     for i in range(int(year1),int(year2)+1):\n",
    "#         df = pd.read_csv(rf\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_\"+str(i)+\".csv\")\n",
    "#         df = df.rename(columns={'ticker' : 'Ticker',\n",
    "#                                 'date' : 'Date',\n",
    "#                                 'time' : 'Time',\n",
    "#                                 'open' : 'Open',\n",
    "#                                 'high' : 'High', \n",
    "#                                 'low' : 'Low',\n",
    "#                                 'close' : 'Close',\n",
    "#                                 'volume' : 'Volume', \n",
    "#                                 'Open Int' : 'Open Interest'})\n",
    "#         df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "#         df = df.sort_values(by=['Date'])\n",
    "\n",
    "#         ## CHANGE AS PER USER INPUT\n",
    "#         symbol = index.upper()\n",
    "#         j='-' + schema[hyphen_index:]\n",
    "#         schema_find = schema[:hyphen_index].upper()\n",
    "\n",
    "#         final_df = df.copy()\n",
    "#         final_df['Final_strike'] = final_df['Ticker'].str.replace(j, '')\n",
    "#         final_df['Final_strike'] = final_df['Final_strike'].str.replace(f'{index.upper()}'+schema_find, '').str.replace(f'{index.upper()}','').str.replace('CE', '').str.replace('PE', '')\n",
    "#         final_df['Final_strike'] = final_df['Final_strike'].astype(float)\n",
    "#         final_df['Option_Type'] = final_df['Ticker'].str[-2:]\n",
    "\n",
    "#         final_df = final_df.rename(columns={'Time' : 'Timestamp',\n",
    "#                                             'Open' : 'Adj_Open',\n",
    "#                                             'High' : 'Adj_High',\n",
    "#                                             'Low' : 'Adj_Low',\n",
    "#                                             'Close' : 'Adj_Close',\n",
    "#                                             'Volume' : 'Adj_Volume',\n",
    "#                                             'Open Interest' : 'Adj_OI',        \n",
    "#                                             'Option_type' : 'Option_Type'})\n",
    "#         final_df['Date'] = pd.to_datetime(final_df['Date'],dayfirst=True).dt.date\n",
    "#         final_df['Timestamp'] = pd.to_datetime(final_df['Timestamp']).dt.time\n",
    "#         final_df = final_df.sort_values(by=['Date', 'Timestamp'])\n",
    "#         final_df['Date'] = final_df['Date'].astype(str)\n",
    "#         final_df['Timestamp'] = final_df['Timestamp'].astype(str)\n",
    "#         final_df['Datetime'] = pd.to_datetime(final_df['Date'] + ' ' + final_df['Timestamp'], dayfirst=True)\n",
    "\n",
    "#         final_df = final_df.set_index(\"Datetime\")\n",
    "#         final_df['Adj_OI_1'] = final_df['Adj_OI']\n",
    "\n",
    "#         df_eod = final_df.groupby(['Final_strike', 'Option_Type', pd.Grouper(freq='B')]).agg({\"Adj_Open\" : \"first\", \n",
    "#                                                               \"Adj_High\" : \"max\",\n",
    "#                                                               \"Adj_Low\" : \"min\",\n",
    "#                                                               \"Adj_Close\" : \"last\", \n",
    "#                                                               'Adj_Volume' : 'sum',\n",
    "#                                                               'Adj_OI' : 'first',\n",
    "#                                                               'Adj_OI_1' : 'last'})\n",
    "#         df_eod.columns = [\"Adj_Open\", \"Adj_High\", \"Adj_Low\", \"Adj_Close\", 'Adj_Volume', 'First_OI', 'Last_OI']\n",
    "#         df_eod = df_eod.reset_index()\n",
    "#         df_eod['rem'] = df_eod['Final_strike']%df_eod['Final_strike'].astype(int)\n",
    "#         df_eod.loc[df_eod['rem'] == 0, 'Ticker'] = symbol + schema_find + j +  df_eod['Final_strike'].astype(int).astype(str) + df_eod['Option_Type']\n",
    "#         df_eod.loc[df_eod['rem'] != 0, 'Ticker'] = symbol + schema_find + j + df_eod['Final_strike'].round(2).astype(str) + df_eod['Option_Type'] \n",
    "\n",
    "#         df_eod = df_eod.sort_values(by=['Datetime', 'Final_strike'])\n",
    "#         df_eod = df_eod.rename(columns={'Datetime' : 'Date'})\n",
    "#         ddf = df_eod.copy()\n",
    "#         ddf['Date'] = pd.to_datetime(ddf['Date'],dayfirst=True)\n",
    "#         ## CHECKING IF NULL VALUES\n",
    "#         ddf_OI = ddf.copy()\n",
    "#         ddf_OI['New_OI'] = ddf_OI['Last_OI']\n",
    "#         ddf_OI = ddf_OI.rename(columns={'Adj_Open':'Open','Adj_High':'High','Adj_Low':'Low','Adj_Close':'Close','Adj_Volume':'Volume','New_OI':'Open_Interest'})\n",
    "#         ddf_OI = ddf_OI.drop(['First_OI','Last_OI','Option_Type','Final_strike','rem'],axis=1)\n",
    "#         ddf_OI = ddf_OI[['Ticker','Date','Open','High','Low','Close','Volume','Open_Interest']]\n",
    "#         ddf_OI.to_csv(fr\"C:\\users\\admin\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}.csv\",mode='a',header= not os.path.exists(fr\"C:\\users\\admin\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}.csv\"),index=False)\n",
    "#         os.remove(rf\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_\"+str(i)+\".csv\")\n",
    "\n",
    "# def fifteen_min(year1, year2,index,schema,hyphen_index):\n",
    "#     print(\"CONVERTING TO 15Min\")\n",
    "#     for i in range(int(year1),int(year2)+1):\n",
    "#         df = pd.read_csv(rf\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_\"+str(i)+\".csv\")\n",
    "#         df = df.rename(columns={'ticker' : 'Ticker',\n",
    "#                                 'date' : 'Date',\n",
    "#                                 'time' : 'Time',\n",
    "#                                 'open' : 'Open',\n",
    "#                                 'high' : 'High', \n",
    "#                                 'low' : 'Low',\n",
    "#                                 'close' : 'Close',\n",
    "#                                 'volume' : 'Volume', \n",
    "#                                 'Open Int' : 'Open Interest'})\n",
    "#         df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "#         df = df.sort_values(by=['Date'])\n",
    "\n",
    "#         ## CHANGE AS PER USER INPUT\n",
    "#         symbol = index.upper()\n",
    "#         j='-' + schema[hyphen_index:]\n",
    "#         schema_find = schema[:hyphen_index].upper()\n",
    "\n",
    "#         final_df = df.copy()\n",
    "#         final_df['Final_strike'] = final_df['Ticker'].str.replace(j, '')\n",
    "#         final_df['Final_strike'] = final_df['Final_strike'].str.replace(f'{index.upper()}'+schema_find, '').str.replace(f'{index.upper()}','').str.replace('CE', '').str.replace('PE', '')\n",
    "#         final_df['Final_strike'] = final_df['Final_strike'].astype(float)\n",
    "#         final_df['Option_Type'] = final_df['Ticker'].str[-2:]\n",
    "\n",
    "#         final_df = final_df.rename(columns={'Time' : 'Timestamp',\n",
    "#                                             'Open' : 'Adj_Open',\n",
    "#                                             'High' : 'Adj_High',\n",
    "#                                             'Low' : 'Adj_Low',\n",
    "#                                             'Close' : 'Adj_Close',\n",
    "#                                             'Volume' : 'Adj_Volume',\n",
    "#                                             'Open Interest' : 'Adj_OI',        \n",
    "#                                             'Option_type' : 'Option_Type'})\n",
    "#         final_df['Date'] = pd.to_datetime(final_df['Date'],dayfirst=True).dt.date\n",
    "#         final_df['Timestamp'] = pd.to_datetime(final_df['Timestamp']).dt.time\n",
    "#         final_df = final_df.sort_values(by=['Date', 'Timestamp'])\n",
    "#         final_df['Date'] = final_df['Date'].astype(str)\n",
    "#         final_df['Timestamp'] = final_df['Timestamp'].astype(str)\n",
    "#         final_df['Datetime'] = pd.to_datetime(final_df['Date'] + ' ' + final_df['Timestamp'], dayfirst=True)\n",
    "\n",
    "#         final_df = final_df.set_index(\"Datetime\")\n",
    "#         final_df['Adj_OI_1'] = final_df['Adj_OI']\n",
    "\n",
    "#         df_eod = final_df.groupby(['Final_strike', 'Option_Type', pd.Grouper(freq='15min')]).agg({\"Adj_Open\" : \"first\", \n",
    "#                                                               \"Adj_High\" : \"max\",\n",
    "#                                                               \"Adj_Low\" : \"min\",\n",
    "#                                                               \"Adj_Close\" : \"last\", \n",
    "#                                                               'Adj_Volume' : 'sum',\n",
    "#                                                               'Adj_OI' : 'first',\n",
    "#                                                               'Adj_OI_1' : 'last'})\n",
    "#         df_eod.columns = [\"Adj_Open\", \"Adj_High\", \"Adj_Low\", \"Adj_Close\", 'Adj_Volume', 'First_OI', 'Last_OI']\n",
    "#         df_eod = df_eod.reset_index()\n",
    "#         df_eod['rem'] = df_eod['Final_strike']%df_eod['Final_strike'].astype(int)\n",
    "#         df_eod.loc[df_eod['rem'] == 0, 'Ticker'] = symbol + schema_find + j +  df_eod['Final_strike'].astype(int).astype(str) + df_eod['Option_Type']\n",
    "#         df_eod.loc[df_eod['rem'] != 0, 'Ticker'] = symbol + schema_find + j + df_eod['Final_strike'].round(2).astype(str) + df_eod['Option_Type'] \n",
    "\n",
    "#         df_eod = df_eod.sort_values(by=['Datetime', 'Final_strike'])\n",
    "#         df_eod = df_eod.rename(columns={'Datetime' : 'Date'})\n",
    "#         ddf = df_eod.copy()\n",
    "#         ddf['Time'] = pd.to_datetime(ddf['Date']).dt.time\n",
    "#         ddf['Date'] = pd.to_datetime(ddf['Date'],dayfirst=True).dt.date\n",
    "#         ## CHECKING IF NULL VALUES\n",
    "#         ddf_OI = ddf.copy()\n",
    "#         ddf_OI['New_OI'] = ddf_OI['Last_OI']\n",
    "#         ddf_OI = ddf_OI.rename(columns={'Adj_Open':'Open','Adj_High':'High','Adj_Low':'Low','Adj_Close':'Close','Adj_Volume':'Volume','New_OI':'Open_Interest'})\n",
    "#         ddf_OI = ddf_OI.drop(['First_OI','Last_OI','Option_Type','Final_strike','rem'],axis=1)\n",
    "#         ddf_OI = ddf_OI[['Ticker','Date','Time','Open','High','Low','Close','Volume','Open_Interest']]\n",
    "#         ddf_OI.to_csv(fr\"C:\\users\\admin\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}.csv\",mode='a',header= not os.path.exists(fr\"C:\\users\\admin\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}.csv\"),index=False)\n",
    "#         os.remove(rf\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_\"+str(i)+\".csv\")\n",
    "\n",
    "# def five_min(year1,year2,index,schema,hyphen_index):\n",
    "#     print(\"CONVERTING TO 5Min\")\n",
    "#     for i in range(int(year1),int(year2)+1):\n",
    "#         df = pd.read_csv(rf\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_\"+str(i)+\".csv\")\n",
    "#         df = df.rename(columns={'ticker' : 'Ticker',\n",
    "#                                 'date' : 'Date',\n",
    "#                                 'time' : 'Time',\n",
    "#                                 'open' : 'Open',\n",
    "#                                 'high' : 'High', \n",
    "#                                 'low' : 'Low',\n",
    "#                                 'close' : 'Close',\n",
    "#                                 'volume' : 'Volume', \n",
    "#                                 'Open Int' : 'Open Interest'})\n",
    "#         df['Date'] = pd.to_datetime(df['Date'], format = 'mixed', dayfirst=True)\n",
    "#         df = df.sort_values(by=['Date'])\n",
    "\n",
    "#         ## CHANGE AS PER USER INPUT\n",
    "#         symbol = index.upper()\n",
    "#         j='-' + schema[hyphen_index:]\n",
    "#         schema_find = schema[:hyphen_index].upper()\n",
    "\n",
    "#         final_df = df.copy()\n",
    "#         final_df['Final_strike'] = final_df['Ticker'].str.replace(j, '')\n",
    "#         final_df['Final_strike'] = final_df['Final_strike'].str.replace(f'{index.upper()}'+schema_find, '').str.replace(f'{index.upper()}','').str.replace('CE', '').str.replace('PE', '')\n",
    "#         final_df['Final_strike'] = final_df['Final_strike'].astype(float)\n",
    "#         final_df['Option_Type'] = final_df['Ticker'].str[-2:]\n",
    "\n",
    "#         final_df = final_df.rename(columns={'Time' : 'Timestamp',\n",
    "#                                             'Open' : 'Adj_Open',\n",
    "#                                             'High' : 'Adj_High',\n",
    "#                                             'Low' : 'Adj_Low',\n",
    "#                                             'Close' : 'Adj_Close',\n",
    "#                                             'Volume' : 'Adj_Volume',\n",
    "#                                             'Open Interest' : 'Adj_OI',        \n",
    "#                                             'Option_type' : 'Option_Type'})\n",
    "#         final_df['Date'] = pd.to_datetime(final_df['Date'],dayfirst=True).dt.date\n",
    "#         final_df['Timestamp'] = pd.to_datetime(final_df['Timestamp']).dt.time\n",
    "#         final_df = final_df.sort_values(by=['Date', 'Timestamp'])\n",
    "#         final_df['Date'] = final_df['Date'].astype(str)\n",
    "#         final_df['Timestamp'] = final_df['Timestamp'].astype(str)\n",
    "#         final_df['Datetime'] = pd.to_datetime(final_df['Date'] + ' ' + final_df['Timestamp'], format = 'mixed',dayfirst=True)\n",
    "\n",
    "#         final_df = final_df.set_index(\"Datetime\")\n",
    "#         final_df['Adj_OI_1'] = final_df['Adj_OI']\n",
    "\n",
    "#         df_eod = final_df.groupby(['Final_strike', 'Option_Type', pd.Grouper(freq='5min')]).agg({\"Adj_Open\" : \"first\", \n",
    "#                                                               \"Adj_High\" : \"max\",\n",
    "#                                                               \"Adj_Low\" : \"min\",\n",
    "#                                                               \"Adj_Close\" : \"last\", \n",
    "#                                                               'Adj_Volume' : 'sum',\n",
    "#                                                               'Adj_OI' : 'first',\n",
    "#                                                               'Adj_OI_1' : 'last'})\n",
    "#         df_eod.columns = [\"Adj_Open\", \"Adj_High\", \"Adj_Low\", \"Adj_Close\", 'Adj_Volume', 'First_OI', 'Last_OI']\n",
    "#         df_eod = df_eod.reset_index()\n",
    "#         df_eod['rem'] = df_eod['Final_strike']%df_eod['Final_strike'].astype(int)\n",
    "#         df_eod.loc[df_eod['rem'] == 0, 'Ticker'] = symbol + schema_find + j +  df_eod['Final_strike'].astype(int).astype(str) + df_eod['Option_Type']\n",
    "#         df_eod.loc[df_eod['rem'] != 0, 'Ticker'] = symbol + schema_find + j + df_eod['Final_strike'].round(2).astype(str) + df_eod['Option_Type'] \n",
    "\n",
    "#         df_eod = df_eod.sort_values(by=['Datetime', 'Final_strike'])\n",
    "#         df_eod = df_eod.rename(columns={'Datetime' : 'Date'})\n",
    "#         ddf = df_eod.copy()\n",
    "#         ddf['Time'] = pd.to_datetime(ddf['Date']).dt.time\n",
    "#         ddf['Date'] = pd.to_datetime(ddf['Date'],format = 'mixed',dayfirst=True).dt.date\n",
    "#         ## CHECKING IF NULL VALUES\n",
    "#         ddf_OI = ddf.copy()\n",
    "#         ddf_OI['New_OI'] = ddf_OI['Last_OI']\n",
    "#         ddf_OI = ddf_OI.rename(columns={'Adj_Open':'Open','Adj_High':'High','Adj_Low':'Low','Adj_Close':'Close','Adj_Volume':'Volume','New_OI':'Open_Interest'})\n",
    "#         ddf_OI = ddf_OI.drop(['First_OI','Last_OI','Option_Type','Final_strike','rem'],axis=1)\n",
    "#         ddf_OI = ddf_OI[['Ticker','Date','Time','Open','High','Low','Close','Volume','Open_Interest']]\n",
    "#         ddf_OI.to_csv(fr\"C:\\users\\admin\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}.csv\",mode='a',header= not os.path.exists(fr\"C:\\users\\admin\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}.csv\"),index=False)\n",
    "#         os.remove(rf\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_\"+str(i)+\".csv\")\n",
    "\n",
    "# def one_min(year1,year2,index,schema,hyphen_index): \n",
    "#     for i in range(int(year1),int(year2)+1):\n",
    "#         df = pd.read_csv(rf\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_\"+str(i)+\".csv\")\n",
    "\n",
    "#         ddf['Date'] = pd.to_datetime(ddf['Date'], dayfirst=True)\n",
    "#         ddf = ddf.sort_values(by=['Date'])\n",
    "#         ddf = ddf[(ddf['Time']>=time1) & ((ddf['Time']<=time2))]\n",
    "#         ddf = ddf.sort_values(by=['Date','Time'])\n",
    "#         ddf.reset_index(drop=True,inplace=True)\n",
    "#         ddf = ddf[['Ticker','Date','Time','Open','High','Low','Close','Volume','Open_Interest']]\n",
    "#         ddf.to_csv(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\Stocks_Data\\\\{symbol.upper()}_Opt_1min.csv\", mode='a', header = not os.path.exists(fr\"C:\\\\users\\\\{admin_path}\\\\desktop\\\\Stocks_Data\\\\{symbol.upper()}_Opt_1min.csv\"), index=False)\n",
    "\n",
    "#         df = df.rename(columns={'ticker' : 'Ticker',\n",
    "#                                 'date' : 'Date',\n",
    "#                                 'time' : 'Time',\n",
    "#                                 'open' : 'Open',\n",
    "#                                 'high' : 'High', \n",
    "#                                 'low' : 'Low',\n",
    "#                                 'close' : 'Close',\n",
    "#                                 'volume' : 'Volume', \n",
    "#                                 'Open Int' : 'Open Interest'})\n",
    "#         df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "#         df = df.sort_values(by=['Date'])\n",
    "\n",
    "#         ## CHANGE AS PER USER INPUT\n",
    "#         symbol = index.upper()\n",
    "#         j='-' + schema[hyphen_index:]\n",
    "#         schema_find = schema[:hyphen_index].upper()\n",
    "\n",
    "#         final_df = df.copy()\n",
    "#         final_df['Final_strike'] = final_df['Ticker'].str.replace(j, '')\n",
    "#         final_df['Final_strike'] = final_df['Final_strike'].str.replace(f'{index.upper()}'+schema_find, '').str.replace(f'{index.upper()}','').str.replace('CE', '').str.replace('PE', '')\n",
    "#         final_df['Final_strike'] = final_df['Final_strike'].astype(float)\n",
    "#         final_df['Option_Type'] = final_df['Ticker'].str[-2:]\n",
    "\n",
    "#         final_df = final_df.rename(columns={'Time' : 'Timestamp',\n",
    "#                                             'Open' : 'Adj_Open',\n",
    "#                                             'High' : 'Adj_High',\n",
    "#                                             'Low' : 'Adj_Low',\n",
    "#                                             'Close' : 'Adj_Close',\n",
    "#                                             'Volume' : 'Adj_Volume',\n",
    "#                                             'Open Interest' : 'Adj_OI',        \n",
    "#                                             'Option_type' : 'Option_Type'})\n",
    "#         final_df['Date'] = pd.to_datetime(final_df['Date'],dayfirst=True).dt.date\n",
    "#         final_df['Timestamp'] = pd.to_datetime(final_df['Timestamp']).dt.time\n",
    "#         final_df = final_df.sort_values(by=['Date', 'Timestamp'])\n",
    "#         final_df['Date'] = final_df['Date'].astype(str)\n",
    "#         final_df['Timestamp'] = final_df['Timestamp'].astype(str)\n",
    "#         final_df['Datetime'] = pd.to_datetime(final_df['Date'] + ' ' + final_df['Timestamp'], dayfirst=True)\n",
    "\n",
    "#         final_df = final_df.set_index(\"Datetime\")\n",
    "#         final_df['Adj_OI_1'] = final_df['Adj_OI']\n",
    "\n",
    "#         df_eod = final_df.groupby(['Final_strike', 'Option_Type', pd.Grouper(freq='1min')]).agg({\"Adj_Open\" : \"first\", \n",
    "#                                                               \"Adj_High\" : \"max\",\n",
    "#                                                               \"Adj_Low\" : \"min\",\n",
    "#                                                               \"Adj_Close\" : \"last\", \n",
    "#                                                               'Adj_Volume' : 'sum',\n",
    "#                                                               'Adj_OI' : 'first',\n",
    "#                                                               'Adj_OI_1' : 'last'})\n",
    "#         df_eod.columns = [\"Adj_Open\", \"Adj_High\", \"Adj_Low\", \"Adj_Close\", 'Adj_Volume', 'First_OI', 'Last_OI']\n",
    "#         df_eod = df_eod.reset_index()\n",
    "#         df_eod['rem'] = df_eod['Final_strike']%df_eod['Final_strike'].astype(int)\n",
    "#         df_eod.loc[df_eod['rem'] == 0, 'Ticker'] = symbol + schema_find + j +  df_eod['Final_strike'].astype(int).astype(str) + df_eod['Option_Type']\n",
    "#         df_eod.loc[df_eod['rem'] != 0, 'Ticker'] = symbol + schema_find + j + df_eod['Final_strike'].round(2).astype(str) + df_eod['Option_Type'] \n",
    "\n",
    "#         df_eod = df_eod.sort_values(by=['Datetime', 'Final_strike'])\n",
    "#         df_eod = df_eod.rename(columns={'Datetime' : 'Date'})\n",
    "#         ddf = df_eod.copy()\n",
    "#         ddf['Time'] = pd.to_datetime(ddf['Date']).dt.time\n",
    "#         ddf['Date'] = pd.to_datetime(ddf['Date'],dayfirst=True).dt.date\n",
    "#         ## CHECKING IF NULL VALUES\n",
    "#         ddf_OI = ddf.copy()\n",
    "#         ddf_OI['New_OI'] = ddf_OI['Last_OI']\n",
    "#         ddf_OI = ddf_OI.rename(columns={'Adj_Open':'Open','Adj_High':'High','Adj_Low':'Low','Adj_Close':'Close','Adj_Volume':'Volume','New_OI':'Open_Interest'})\n",
    "#         ddf_OI = ddf_OI.drop(['First_OI','Last_OI','Option_Type','Final_strike','rem'],axis=1)\n",
    "#         ddf_OI = ddf_OI[['Ticker','Date','Time','Open','High','Low','Close','Volume','Open_Interest']]\n",
    "#         ddf_OI.to_csv(fr\"C:\\users\\admin\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}.csv\",mode='a',header= not os.path.exists(fr\"C:\\users\\admin\\desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}.csv\"),index=False)\n",
    "#         os.remove(rf\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_\"+str(i)+\".csv\")\n",
    "\n",
    "# def option_data_inputs(index,date1,date2,conversion):    \n",
    "#     schema = input(\"ENTER THE SCHEMA OF WHOSE DATA YOU WANT - \\nMonthlyI , MonthlyII , WeeklyI , QuarterlyI and so on\\n\")\n",
    "#     hyphen_index = schema.find(\"I\")\n",
    "#     conn = psycopg2.connect(database=f\"{index}db\",\n",
    "#                             user='postgres', password='swancap123',\n",
    "#                             host='swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com', port='5432'\n",
    "#                             )\n",
    "#     conn.autocommit = True\n",
    "#     cursor = conn.cursor()\n",
    "#     buffer = StringIO()\n",
    "#     st=time.time()\n",
    "#     ## CREATING A DIRECTORY OF THE REQUIRED INDEX AND SCHEMA\n",
    "#     if not os.path.exists(rf\"C:\\\\users\\\\admin\\\\desktop\\\\{index}_{schema}_Data\\\\\"):\n",
    "#         os.makedirs(rf\"C:\\users\\admin\\desktop\\\\{index}_{schema}_Data\\\\\")\n",
    "\n",
    "#     date1 = datetime.strptime(date1, \"%Y-%m-%d\").date()\n",
    "#     date2 = datetime.strptime(date2, \"%Y-%m-%d\").date()\n",
    "#     year1 = date1.year\n",
    "#     year2 = date2.year\n",
    "#     print(\"\\nGENERATING OPTIONS DATA\")\n",
    "#     for i in range(int(year1),int(year2)+1):\n",
    "#         ddate1 = '-01-01'\n",
    "#         ddate2 = '-12-31'\n",
    "#         year_start = str(str(i)+ddate1)\n",
    "#         year_end = str(str(i)+ddate2)\n",
    "#         year_start = datetime.strptime(year_start, \"%Y-%m-%d\").date()\n",
    "#         year_end = datetime.strptime(year_end, \"%Y-%m-%d\").date()\n",
    "#         if date1 > year_start :\n",
    "#             year_start = date1\n",
    "#         else:\n",
    "#             year_start = year_start\n",
    "#         if year_end > date2 :\n",
    "#             year_end = date2\n",
    "#         else:\n",
    "#             year_end = year_end\n",
    "#         sql=f\"COPY (select *from \\\"{index}{schema}\\\".select_datewise(\\'{year_start}\\',\\'{year_end}\\')) TO STDOUT WITH DELIMITER ',' CSV HEADER\"\n",
    "#         print(\"Generating data from \", year_start , \" to \" , year_end)\n",
    "#         with open(f\"C:\\\\Users\\\\Admin\\\\Desktop\\\\{index}_{schema}_Data\\\\{index}_{schema}_\"+str(i)+\".csv\", \"w\") as file:\n",
    "#             cursor.copy_expert(sql, file)\n",
    "#     if conversion == 'E':\n",
    "#         df = EOD(year1, year2,index,schema,hyphen_index)\n",
    "\n",
    "#     elif conversion == '15':\n",
    "#         df = fifteen_min(year1,year2,index,schema,hyphen_index)\n",
    "\n",
    "#     elif conversion == '5':\n",
    "#         df = five_min(year1,year2,index,schema,hyphen_index)\n",
    "\n",
    "#     elif conversion == '1':\n",
    "#         df = one_min(year1,year2,index,schema,hyphen_index)\n",
    "\n",
    "#     conn.commit()\n",
    "#     conn.close()\n",
    "#     et=time.time()\n",
    "\n",
    "#     elapsed_time=et-st;\n",
    "#     print(\"OPTIONS DATA GENERATED!\")\n",
    "#     print(\"elapsed_time:\",elapsed_time)\n",
    "\n",
    "# def underlying_inputs(index,date1,date2,conversion):\n",
    "#     start_date = datetime.strptime(date1,\"%Y-%m-%d\")\n",
    "#     end_date = datetime.strptime(date2,\"%Y-%m-%d\")\n",
    "#     start_date=start_date.date()\n",
    "#     end_date = end_date.date()\n",
    "#     print(\"\\nGENERATING UNDERLYING DATA\")\n",
    "#     st = time.time()\n",
    "#     conn = psycopg2.connect(database=\"IndexEQ\",\n",
    "#                             user='postgres', password='swancap123',\n",
    "#                             host='swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com', port='5432'\n",
    "#     )\n",
    "\n",
    "#     conn.autocommit = True\n",
    "#     cursor = conn.cursor()\n",
    "#     buffer = StringIO()\n",
    "\n",
    "#     sql = f\"COPY (SELECT * from \\\"{index}\\\".\\\"AllData\\\" where \\\"Date\\\" BETWEEN \\'{start_date}' AND \\'{end_date}\\') TO STDOUT WITH DELIMITER ',' CSV HEADER\" \n",
    "\n",
    "#     if not os.path.exists(rf\"C:\\\\users\\\\admin\\\\desktop\\\\{index}_EqData\\\\\"):\n",
    "#         os.makedirs(rf\"C:\\users\\admin\\desktop\\\\{index}_EqData\\\\\")        \n",
    "\n",
    "#     with open(fr\"C:\\users\\admin\\desktop\\\\{index}_EqData\\\\{index}\" + \".csv\",\"w\") as file:\n",
    "#         cursor.copy_expert(sql,file)\n",
    "\n",
    "#     if conversion == '1':\n",
    "#         pass\n",
    "#         # df = one_min_underlying(index)\n",
    "\n",
    "#     elif conversion == '5':\n",
    "#         df = five_min_underlying(index)\n",
    "\n",
    "#     elif conversion == '15':\n",
    "#         df = fifteen_min_underlying(index)\n",
    "\n",
    "#     elif conversion == 'E':\n",
    "#         df = EOD_underlying(index)\n",
    "\n",
    "#     conn.commit()\n",
    "#     conn.close()\n",
    "#     et=time.time()\n",
    "\n",
    "#     elapsed_time=et-st;\n",
    "#     print(\"UNDERLYING DATA GENERATED!\")\n",
    "#     print(\"elapsed_time:\",elapsed_time)\n",
    "\n",
    "\n",
    "# data = input(\"Enter O for Options data, U for Underlying data, B for Both the data, E for Exiting \")\n",
    "\n",
    "# if data == 'o' or data == 'O' or data == 'u' or data == 'U' or data == 'b' or data == 'B':    \n",
    "#     index = input(\"Enter the index you want in the format below - \\nBankNifty\\nNifty\\nFinNifty\\n\")\n",
    "#     date1 = input(\"Enter start date as YYYY-MM-DD \")\n",
    "#     date2 = input(\"Enter end date as YYYY-MM-DD \")\n",
    "#     conversion = input(\"Enter 1 for 1 minute, 5 for 5 minutes, 15 for 15 minutes, E for EOD\\n\")\n",
    "\n",
    "# elif data == 'e' or data == 'E':\n",
    "#     print(\"Exit!\")\n",
    "\n",
    "# else:\n",
    "#     print(\"Wrong option\")\n",
    "    \n",
    "# if data == 'O' or data == 'o':\n",
    "#     option_data_inputs(index,date1,date2,conversion)\n",
    "\n",
    "# elif data == 'U' or data == 'u':\n",
    "#     underlying_inputs(index,date1,date2,conversion)\n",
    "\n",
    "# elif data == 'B' or data == 'b':\n",
    "#     option_data_inputs(index,date1,date2,conversion)\n",
    "#     underlying_inputs(index,date1,date2,conversion)\n",
    "\n",
    "# print(\"\\nCOMPLETED.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d14505-0340-4ed3-82d1-2dbb4cbd95a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
