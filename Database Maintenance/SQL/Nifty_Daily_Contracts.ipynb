{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2cfd5554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r27022023\n",
      "NIFTY CONTRACTS BEING CREATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_416\\2272847662.py:105: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  temp_df = temp_10.append(temp_12,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Success\n",
      "NIFTY MONTHLY CONTRACTS CREATED\n",
      "[0.0, 1.0, 2.0, 3.0, 4.0, 8.0, 12.0, 10000.0]\n",
      "NIFTY WEEKLY CONTRACTS CREATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_416\\2272847662.py:444: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  temp_df = temp_10.append(temp_12,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIFTY QUARTERLY CONTRACTS CREATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_416\\2272847662.py:632: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  temp_df = temp_10.append(temp_12,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "NIFTY HALF YEARLY CONTRACTS CREATED\n",
      "0 YEARLY I HALFYEARLY I II\n",
      "1 YEARLY II HALFYEARLY III IV\n",
      "2 YEARLY III HALFYEARLY V VI\n",
      "3 YEARLY IV HALFYEARLY VII VIII\n",
      "No contracts for Half yearly IX X\n",
      "YEARLY CONTRACTS GENERATED\n",
      "\n",
      "NIFTY CONTRACTS CREATED\n",
      "ELAPSED TIME 68.50235891342163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_416\\2272847662.py:1012: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  final_df = df1.append(df2,ignore_index=True)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_416\\2272847662.py:1012: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  final_df = df1.append(df2,ignore_index=True)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_416\\2272847662.py:1012: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  final_df = df1.append(df2,ignore_index=True)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_416\\2272847662.py:1012: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  final_df = df1.append(df2,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import walk\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import array_contains\n",
    "from pyspark.sql.functions import *\n",
    "import time\n",
    "from pyspark.sql.functions import date_format\n",
    "from datetime import date\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "date = date(2023,2,27)                                     ## TO BE CHANGED DAILY AS PER UPDATION DATE\n",
    "day = date.strftime('%d')\n",
    "nummonth=date.strftime(\"%m\")\n",
    "year=date.strftime('%Y')\n",
    "tablename=\"r\"+str(day)+str(nummonth)+str(year)\n",
    "print(tablename)\n",
    "\n",
    "st=time.time()\n",
    "\n",
    "def nifty_data():\n",
    "    spark = SparkSession.builder.config(\"spark.jars\", \"C:\\\\Users\\\\admin\\\\Downloads\\\\postgresql-42.5.0.jar\") \\\n",
    "    .master(\"local\").appName(\"PySpark_Postgres_test\").getOrCreate()\n",
    "    \n",
    "    df = spark.read.format(\"jdbc\").option(\"url\", \"jdbc:postgresql://swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com/RawDataBase\").option(\"user\",\"postgres\").option(\"password\",\"swancap123\")\\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\").option(\"dbtable\", tablename)\\\n",
    "        .option(\"user\", \"postgres\").option(\"password\", \"swancap123\").load()\n",
    "\n",
    "    ## GETTING ONLY TIME IN TIME COLUMN\n",
    "    q = df.withColumn('time',date_format('time', 'HH:mm:ss'))\n",
    "    ndata = q.filter(q.ticker.contains('NIFTY') & ((q.ticker.endswith('E.NFO'))| (q.ticker.endswith('E'))))\n",
    "    ndata = ndata.withColumn('ticker_check',substring('ticker',1,5))\n",
    "    ndata = ndata.filter(ndata.ticker_check.contains('NIFTY'))\n",
    "    ## REPLACING .NFO IN ticker\n",
    "    ndata = ndata.withColumn('ticker',regexp_replace('ticker','.NFO',''))\n",
    "    ndata = ndata.drop(col('ticker_check'))\n",
    "\n",
    "    ## CONVERTING PYSPARK DATAFRAME TO PANDAS DATAFRAME\n",
    "    ndata = ndata.toPandas()\n",
    "    return ndata\n",
    "    \n",
    "def nifty_monthly():\n",
    "    folpath = r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Monthly_Data\\\\\"\n",
    "    sym = 'NIFTY'\n",
    "    start_time = datetime.strptime('09:15:00', '%H:%M:%S').time()\n",
    "    end_time = datetime.strptime('15:30:00', '%H:%M:%S').time()\n",
    "    expiry_time = datetime.strptime('15:29:59', '%H:%M:%S').time()\n",
    "    s = 'NIFTY'\n",
    "\n",
    "    def add(stri):\n",
    "        obj = datetime.strptime(stri, \"%b\")\n",
    "        month_number = obj.month\n",
    "        return month_number\n",
    "\n",
    "    def get_symbol(tic):\n",
    "        li = list(filter(None, re.split(r'(\\d+)', tic)))\n",
    "        return li[0]\n",
    "\n",
    "    exp_file_path = r\"C:\\Users\\admin\\Downloads\\MonthlyExpiry.csv\"\n",
    "    exp_df = pd.read_csv(exp_file_path,parse_dates = [\"curr_exp_date\",\"curr_date\"],dayfirst =True).dropna()\n",
    "    exp_df.rename({'curr_date': 'New_date'}, axis=1, inplace=True)\n",
    "    exp_date = pd.read_excel(r'C:\\users\\admin\\desktop\\Expiry_DT.xlsx')    ## reading the expiry sheet file\n",
    "    \n",
    "    ## CALLING FUNCTION NIFTY_DATA TO GENERATE ONLY NIFTY TICKERS\n",
    "    ndata = nifty_data()\n",
    "    \n",
    "    temp = ndata.copy()\n",
    "    temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "    temp['Symbol'] = temp['ticker'].str[:7]\n",
    "    temp = temp[temp['Symbol']!='NIFTYIT']\n",
    "    temp['time'] = pd.to_datetime(temp['time']).dt.time\n",
    "    temp['ticker'] = temp['ticker'].str.replace('30MAR23','29MAR23',regex=True)\n",
    "    temp['Option_Type'] = temp['ticker'].str[-2:]\n",
    "    temp['Temp'] = temp[\"ticker\"].str.replace(s,\"\")\n",
    "    temp['Temp'] = temp['Temp'].str[:-2]\n",
    "    temp['Length_of_temp'] = temp['Temp'].str.len()\n",
    "    temp['Strike'] = np.where((temp['Temp'].str.len()==9) | (temp['Temp'].str.len()==11) , \n",
    "                              temp['Temp'].str[-4:] , \n",
    "                              temp['Temp'].str[-5:])\n",
    "    temp['Exp_Year'] = np.where((temp['Temp'].str.len()==9) | (temp['Temp'].str.len()==10) ,\n",
    "                               temp['Temp'].str[:2] ,\n",
    "                               temp['Temp'].str[5:7])\n",
    "    temp['Exp_month'] = temp['Temp'].str[2:5]\n",
    "    temp['Exp_Year'] = temp['Exp_Year'].astype('str')\n",
    "    temp['MonthYear'] = temp['Exp_month']+temp['Exp_Year']\n",
    "    temp = pd.merge(temp,exp_date,on='MonthYear')\n",
    "    temp = temp.drop(['MonthYear','Month','Year','Next_Exp_DT'],axis=1)\n",
    "    temp['Length_of_temp'] = temp['Length_of_temp'].astype('int64')\n",
    "    temp_10 = temp[(temp['Length_of_temp']==10) | (temp['Length_of_temp']==9)]\n",
    "\n",
    "    temp_12 = temp[(temp['Length_of_temp']==12) | (temp['Length_of_temp']==11)]\n",
    "    temp_12['DateDate'] = temp_12['Temp'].str[:2]\n",
    "    temp_12['DateDate'] = temp_12['DateDate'].astype('int64')\n",
    "    temp_12['Exp_DT'] = pd.to_datetime(temp_12['Exp_DT'],dayfirst=True)\n",
    "    temp_12['Exp_Day'] = temp_12['Exp_DT'].dt.day\n",
    "    temp_12 = temp_12[temp_12['Exp_Day']==temp_12['DateDate']]\n",
    "    temp_12 = temp_12.drop(['DateDate','Exp_Day'],axis=1)\n",
    "\n",
    "    temp_df = temp_10.append(temp_12,ignore_index=True)\n",
    "\n",
    "    temp_df['time'] = temp_df['time'].astype(str).str.replace(' 15:00:59','15:00:59')\n",
    "    temp_df['time'] = temp_df['time'].astype(str).str.replace(' 9:','09:',regex=True)\n",
    "    temp_df['time'] = pd.to_datetime(temp_df['time'], format='%H:%M:%S').dt.time\n",
    "    temp_df = temp_df[(temp_df['time']>=start_time) & (temp_df['time']<=end_time)]\n",
    "\n",
    "    temp_df['exp_month_number'] = temp_df.apply(lambda row : add(row[\"Exp_month\"]), axis = 1)\n",
    "    temp_df['New_date'] = temp_df['date']\n",
    "    temp_df[\"New_date\"] = pd.to_datetime(temp_df[\"New_date\"])\n",
    "    temp_df[\"current_month_number\"] = temp_df['New_date'].dt.month\n",
    "    temp_df[\"difference\"] = temp_df['exp_month_number'].astype(int) - temp_df[\"current_month_number\"].astype(int)\n",
    "    temp_df1 = pd.merge(temp_df, \n",
    "                 exp_df, \n",
    "                 on ='New_date', \n",
    "                 how ='left')\n",
    "    temp_df1.drop(temp_df1.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "    temp_df1[\"current_exp_month_number\"] = temp_df1['curr_exp_date'].dt.month\n",
    "    temp_df1[\"Diff_months\"] = temp_df1[\"current_exp_month_number\"] - temp_df1[\"current_month_number\"]\n",
    "    temp_df1[\"Diff_months\"] = temp_df1[\"Diff_months\"].astype(int) \n",
    "    temp_df1['Current_Year'] = temp_df1['New_date'].dt.year.astype(str).str[-2:]\n",
    "    temp_df1['Flag'] = np.where((temp_df1['Current_Year']==temp_df1['Exp_Year']) | (temp_df1['current_month_number']==12) & (temp_df1['exp_month_number']<=3),1,0)\n",
    "    temp_df1 = temp_df1[temp_df1['Flag']==1]\n",
    "    bdf = temp_df1[temp_df1[\"Diff_months\"] == 0]\n",
    "    adf = temp_df1[(temp_df1[\"Diff_months\"] == 1) | (temp_df1[\"Diff_months\"] == -11)]\n",
    "    if bdf.shape[0] + adf.shape[0] == temp_df1.shape[0]:\n",
    "        print(\"Sanity Check Success\")\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "\n",
    "    agb = adf.groupby([\"difference\"])\n",
    "    unique_val_list_a = list(adf[\"difference\"].unique())\n",
    "    bgb = bdf.groupby([\"difference\"])\n",
    "    unique_val_list_b = list(bdf[\"difference\"].unique())\n",
    "\n",
    "    if os.path.exists(folpath+sym+'-I.csv'):\n",
    "        os.remove(folpath+sym+'-I.csv')\n",
    "    if os.path.exists(folpath+sym+'-II.csv'):\n",
    "        os.remove(folpath+sym+'-II.csv')\n",
    "    if os.path.exists(folpath+sym+'-III.csv'):\n",
    "        os.remove(folpath+sym+'-III.csv')\n",
    "    if os.path.exists(folpath+sym+'-misc.csv'):\n",
    "        os.remove(folpath+sym+'-misc.csv')\n",
    "\n",
    "    for i in unique_val_list_b:\n",
    "        temp_df_new = bgb.get_group(i)\n",
    "        temp_df_new = temp_df_new.drop(temp_df_new.columns[9:],axis=1)\n",
    "        if i == 0:\n",
    "            temp_df_new.to_csv(folpath + sym + '-I.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "\n",
    "        if i == 1 or i == -11:\n",
    "            temp_df_new.to_csv(folpath + sym + '-II.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "\n",
    "        if i == 2 or i == -10:\n",
    "            temp_df_new.to_csv(folpath + sym + '-III.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "\n",
    "    for i in unique_val_list_a:\n",
    "        temp_df_new = agb.get_group(i)\n",
    "        temp_df_new = temp_df_new.drop(temp_df_new.columns[9:],axis=1)\n",
    "        if i == 1 or i == -11:\n",
    "            temp_df_new.to_csv(folpath + sym + '-I.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "\n",
    "        if i == 2 or i == -10:\n",
    "            temp_df_new.to_csv(folpath + sym + '-II.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "\n",
    "        if i == 3 or i == -9:\n",
    "            temp_df_new.to_csv(folpath + sym + '-III.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "\n",
    "    ##########################CREATING LABEL IN STANDARD FORM#####################\n",
    "    for i in range(3):\n",
    "        if i == 0:\n",
    "            file='I'\n",
    "        elif i == 1:\n",
    "            file='II'\n",
    "        elif i == 2:\n",
    "            file='III'\n",
    "        if os.path.exists(r'C:\\users\\admin\\desktop\\Pyspark\\Nifty\\Monthly\\NIFTY-'+file+\".csv\"):\n",
    "            os.remove(r'C:\\users\\admin\\desktop\\Pyspark\\Nifty\\Monthly\\NIFTY-'+file+\".csv\")\n",
    "        if os.path.exists(r'C:\\users\\admin\\desktop\\Pyspark_Contracts\\Nifty\\Monthly_Data\\NIFTY-'+file+'.csv'):\n",
    "            ddf = pd.read_csv(r'C:\\users\\admin\\desktop\\Pyspark_Contracts\\Nifty\\Monthly_Data\\NIFTY-'+file+'.csv')\n",
    "            ddf['Option_Type'] = ddf['ticker'].str[-2:]\n",
    "            ddf['Strike'] = np.where((ddf['ticker'].str.len()==16) | (ddf['ticker'].str.len()==18) , ddf['ticker'].str[-6:-2] , ddf['ticker'].str[-7:-2])\n",
    "            ddf['Symbol'] = 'NIFTY' + 'MONTHLY-' + file + ddf['Strike'].astype(int).astype(str) + ddf['Option_Type']\n",
    "            ddf['ticker'] = ddf['Symbol']\n",
    "            ddf = ddf.drop(ddf.columns[9:],axis=1)\n",
    "            ddf = ddf.rename(columns = {\"ticker\":\"Ticker\"})\n",
    "            ddf.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\Nifty\\Monthly\\\\NIFTY-\"+file+\".csv\",index=False)\n",
    "    print(\"NIFTY MONTHLY CONTRACTS CREATED\")\n",
    "\n",
    "def nifty_weekly():\n",
    "    folpath = r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Weekly_Data\\\\\"\n",
    "    sym = 'NIFTY'\n",
    "    start_time = datetime.strptime('09:15:00', '%H:%M:%S').time()\n",
    "    end_time = datetime.strptime('15:30:00', '%H:%M:%S').time()\n",
    "    expiry_time = datetime.strptime('15:29:59', '%H:%M:%S').time()\n",
    "    s = 'NIFTY'\n",
    "    def add(stri):\n",
    "        obj = datetime.strptime(stri, \"%b\")\n",
    "        month_number = obj.month\n",
    "        return month_number\n",
    "    def get_symbol(tic):\n",
    "        li = list(filter(None, re.split(r'(\\d+)', tic)))\n",
    "        return li[0]\n",
    "    exp_file_path = r\"C:\\Users\\admin\\Downloads\\WeeklyExpiry.csv\"\n",
    "    exp_date = pd.read_excel(r'C:\\users\\admin\\desktop\\Expiry_DT.xlsx')    ## reading the expiry sheet file\n",
    "    exp_df = pd.read_csv(exp_file_path,parse_dates = [\"date\"],dayfirst =True,usecols= ['date', 'Week_number'])\n",
    "    exp_df.rename({'curr_date': 'New_date'}, axis=1, inplace=True)\n",
    "    \n",
    "    ## CALLING FUNCTION NIFTY_DATA TO GENERATE ONLY NIFTY TICKERS\n",
    "    ndata=nifty_data()\n",
    "    \n",
    "    temp = ndata.copy()\n",
    "    temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "    temp['Symbol'] = temp['ticker'].str[:7]\n",
    "    temp = temp[temp['Symbol']!='NIFTYIT']\n",
    "    temp = temp.reset_index(drop=True)\n",
    "    temp['time'] = temp['time'].str.replace(' 15:00:59','15:00:59')\n",
    "    temp['time'] = temp['time'].str.replace(' 9:','09:',regex=True)\n",
    "    temp['time'] = pd.to_datetime(temp['time']).dt.time\n",
    "    temp['date'] = pd.to_datetime(temp['date'])\n",
    "    temp['ticker'] = temp['ticker'].str.replace('30MAR23','29MAR23',regex=True)\n",
    "    temp['Option_Type'] = temp['ticker'].str[-2:]\n",
    "    temp['Temp'] = temp[\"ticker\"].str.replace(s,\"\")\n",
    "    temp['Temp'] = temp['Temp'].str[:-2]\n",
    "    temp['EXPIRY_DT'] = temp['Temp'].str[:7]\n",
    "    temp['EXPIRY_DT'] = pd.to_datetime(temp['EXPIRY_DT'],dayfirst=True)\n",
    "    temp['Length_of_temp'] = temp['Temp'].str.len()\n",
    "    temp['Strike'] = np.where((temp['Temp'].str.len()==9) | (temp['Temp'].str.len()==11) , \n",
    "                              temp['Temp'].str[-4:] , \n",
    "                              temp['Temp'].str[-5:])\n",
    "    temp['Exp_year'] = np.where((temp['Temp'].str.len()==9) | (temp['Temp'].str.len()==10) ,\n",
    "                               temp['Temp'].str[:2] ,\n",
    "                               temp['Temp'].str[5:7])\n",
    "    temp['Exp_month'] = temp['Temp'].str[2:5]\n",
    "    temp['MonthYear'] = temp['Exp_month'] + temp['Exp_year']\n",
    "    temp = temp.rename(columns={'EXPIRY_DT' : 'expiry_date'})\n",
    "    temp1 = pd.merge(temp,exp_df,on='date',how='left')\n",
    "    temp1 = temp1.drop_duplicates()\n",
    "    temp1 = pd.merge(temp1,exp_date,on='MonthYear',how='left')\n",
    "    temp1 = temp1.drop(['Month','Year','MonthYear','Next_Exp_DT'],axis=1)\n",
    "\n",
    "    ## GETTING EXPIRY DATES FOR MONTHLY CONTRACTS\n",
    "    temp1['expiry_date'] = np.where(temp1['Length_of_temp']>=11,temp1['expiry_date'],temp1['Exp_DT'])\n",
    "    temp1 = temp1.drop(['Exp_DT'],axis=1)\n",
    "    exp_df = pd.read_csv(exp_file_path,parse_dates = [\"Weekly_Expiry_Date\"],dayfirst =True,usecols= ['Weekly_Expiry_Date', 'Expiry_Week_number'])\n",
    "    exp_df = exp_df.dropna()\n",
    "    exp_df = exp_df.rename(columns = {'Weekly_Expiry_Date':'expiry_date'})\n",
    "    temp2 = pd.merge(temp1, exp_df, on = 'expiry_date', how = 'left')\n",
    "    temp2 = temp2.drop_duplicates()\n",
    "    temp2['week_diff'] = temp2['Expiry_Week_number'] - temp2['Week_number']\n",
    "    final_df = temp2\n",
    "    final_df[\"week_diff\"] = final_df['week_diff'].replace(np.nan,10000)\n",
    "\n",
    "    agb = final_df.groupby([\"week_diff\"])\n",
    "    unique_val_list_a = list(final_df[\"week_diff\"].unique())\n",
    "    unique_val_list_a = sorted([a for a in unique_val_list_a if a>=0])[0:12]\n",
    "    print(unique_val_list_a)\n",
    "\n",
    "    ############CREATING -I,-II BASED ON WEEK DIFFERENCES###################\n",
    "    if os.path.exists(folpath+sym+'-I.csv'):\n",
    "        os.remove(folpath+sym+'-I.csv')\n",
    "    if os.path.exists(folpath+sym+'-II.csv'):\n",
    "        os.remove(folpath+sym+'-II.csv')\n",
    "    if os.path.exists(folpath+sym+'-III.csv'):\n",
    "        os.remove(folpath+sym+'-III.csv')\n",
    "    if os.path.exists(folpath+sym+'-IV.csv'):\n",
    "        os.remove(folpath+sym+'-IV.csv')\n",
    "    if os.path.exists(folpath+sym+'-V.csv'):\n",
    "        os.remove(folpath+sym+'-V.csv')\n",
    "    if os.path.exists(folpath+sym+'-VI.csv'):\n",
    "        os.remove(folpath+sym+'-VI.csv')\n",
    "    if os.path.exists(folpath+sym+'-VII.csv'):\n",
    "        os.remove(folpath+sym+'-VII.csv')\n",
    "    if os.path.exists(folpath+sym+'-VIII.csv'):\n",
    "        os.remove(folpath+sym+'-VIII.csv')\n",
    "    if os.path.exists(folpath+sym+'-IX.csv'):\n",
    "        os.remove(folpath+sym+'-IX.csv')\n",
    "    if os.path.exists(folpath+sym+'-X.csv'):\n",
    "        os.remove(folpath+sym+'-X.csv')\n",
    "    if os.path.exists(folpath+sym+'-XI.csv'):\n",
    "        os.remove(folpath+sym+'-XI.csv')\n",
    "    if os.path.exists(folpath+sym+'-XII.csv'):\n",
    "        os.remove(folpath+sym+'-XII.csv')  \n",
    "    if os.path.exists(folpath+sym+'-XIII.csv'):\n",
    "        os.remove(folpath+sym+'-XIII.csv')  \n",
    "    if os.path.exists(folpath+sym+'-XIV.csv'):\n",
    "        os.remove(folpath+sym+'-XIV.csv')  \n",
    "        \n",
    "    for i in sorted(unique_val_list_a):\n",
    "        temp_df = agb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        temp_df = temp_df.drop_duplicates()\n",
    "        if i == 0:\n",
    "            temp_df.to_csv(folpath + s + '-I.csv', mode = 'a', header = not os.path.exists(folpath + s + '-I.csv'), index=False)\n",
    "\n",
    "        if i == 1:\n",
    "            temp_df.to_csv(folpath + s + '-II.csv', mode = 'a', header = not os.path.exists(folpath + s + '-II.csv'), index=False)\n",
    "\n",
    "        if i == 2:\n",
    "            temp_df.to_csv(folpath + s + '-III.csv', mode = 'a', header = not os.path.exists(folpath + s + '-III.csv'), index=False)\n",
    "\n",
    "        if i == 3:\n",
    "            temp_df.to_csv(folpath + s + '-IV.csv', mode = 'a', header = not os.path.exists(folpath + s + '-IV.csv'), index=False)\n",
    "\n",
    "        if i == 4:\n",
    "            temp_df.to_csv(folpath + s + '-V.csv', mode = 'a', header = not os.path.exists(folpath + s + '-V.csv'), index=False)\n",
    "\n",
    "        if i == 5:\n",
    "            temp_df.to_csv(folpath + s + '-VI.csv', mode = 'a', header = not os.path.exists(folpath + s + '-VI.csv'), index=False)\n",
    "\n",
    "        if i == 6:\n",
    "            temp_df.to_csv(folpath + s + '-VII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-VII.csv'), index=False)\n",
    "\n",
    "        if i == 7:\n",
    "            temp_df.to_csv(folpath + s + '-VIII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-VIII.csv'), index=False)\n",
    "\n",
    "        if i == 8:\n",
    "            temp_df.to_csv(folpath + s + '-IX.csv', mode = 'a', header = not os.path.exists(folpath + s + '-IX.csv'), index=False)\n",
    "\n",
    "        if i == 9:\n",
    "            temp_df.to_csv(folpath + s + '-X.csv', mode = 'a', header = not os.path.exists(folpath + s + '-X.csv'), index=False)\n",
    "\n",
    "        if i == 10:\n",
    "            temp_df.to_csv(folpath + s + '-XI.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XI.csv'), index=False)\n",
    "\n",
    "        if i == 11:\n",
    "            temp_df.to_csv(folpath + s + '-XII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XII.csv'), index=False)\n",
    "\n",
    "        if i == 12:\n",
    "            temp_df.to_csv(folpath + s + '-XIII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XIII.csv'), index=False)\n",
    "\n",
    "        if i == 13:\n",
    "            temp_df.to_csv(folpath + s + '-XIV.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XIV.csv'), index=False)\n",
    "\n",
    "    #################LABELLING FILES IN STANDARD FORM######################\n",
    "    for i in range(15):\n",
    "        if i==0:\n",
    "            file='I'\n",
    "        elif i==1:\n",
    "            file='II'\n",
    "        elif i==2:\n",
    "            file='III'\n",
    "        elif i==3:\n",
    "            file='IV'\n",
    "        elif i==4:\n",
    "            file='V'\n",
    "        elif i==5:\n",
    "            file='VI'\n",
    "        elif i==6:\n",
    "            file='VII'\n",
    "        elif i==7:\n",
    "            file='VIII'\n",
    "        elif i==8:\n",
    "            file='IX'\n",
    "        elif i==9:\n",
    "            file='X'\n",
    "        elif i==10:\n",
    "            file='XI'\n",
    "        elif i==11:\n",
    "            file='XII'\n",
    "        elif i==12:\n",
    "            file='XIII'\n",
    "        elif i==13:\n",
    "            file='XIV'\n",
    "        if os.path.exists(r'C:\\users\\admin\\desktop\\Pyspark\\Nifty\\Weekly\\NIFTY-'+file+'.csv'):\n",
    "            os.remove(r'C:\\users\\admin\\desktop\\Pyspark\\Nifty\\Weekly\\NIFTY-'+file+'.csv')\n",
    "        if os.path.exists(r'C:\\users\\admin\\desktop\\Pyspark_Contracts\\Nifty\\Weekly_Data\\NIFTY-'+file+'.csv'):\n",
    "            ddf = pd.read_csv(r'C:\\users\\admin\\desktop\\Pyspark_Contracts\\Nifty\\Weekly_Data\\NIFTY-'+file+'.csv')\n",
    "            ddf['Option_Type'] = ddf['ticker'].str[-2:]\n",
    "            ddf['Strike'] = np.where((ddf['ticker'].str.len()==16) | (ddf['ticker'].str.len()==18) , ddf['ticker'].str[-6:-2] , ddf['ticker'].str[-7:-2])\n",
    "            ddf['Symbol'] = 'NIFTY' + 'WEEKLY-' + file + + ddf['Strike'].astype(int).astype(str) + ddf['Option_Type']\n",
    "            ddf['ticker'] = ddf['Symbol']\n",
    "            ddf = ddf.drop(ddf.columns[9:],axis=1)\n",
    "            ddf = ddf.rename(columns = {'date':'Date','ticker':'Ticker'})\n",
    "            ddf = ddf.drop_duplicates()\n",
    "            ddf.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\Nifty\\Weekly\\NIFTY-\"+file+\".csv\",index=False)\n",
    "    print(\"NIFTY WEEKLY CONTRACTS CREATED\")\n",
    "    \n",
    "def nifty_quarterly():\n",
    "    folpath = r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Quarterly_Data\\\\\"\n",
    "    sym = 'NIFTY'\n",
    "    start_time = datetime.strptime('09:15:00', '%H:%M:%S').time()\n",
    "    end_time = datetime.strptime('15:30:00', '%H:%M:%S').time()\n",
    "    expiry_time = datetime.strptime('15:29:59', '%H:%M:%S').time()\n",
    "    s = 'NIFTY'\n",
    "\n",
    "    def add(stri):\n",
    "        obj = datetime.strptime(stri, \"%b\")\n",
    "        month_number = obj.month\n",
    "        return month_number\n",
    "\n",
    "    def get_symbol(tic):\n",
    "        li = list(filter(None, re.split(r'(\\d+)', tic)))\n",
    "        return li[0]\n",
    "\n",
    "    exp_date = pd.read_excel(r'C:\\users\\admin\\desktop\\Expiry_DT.xlsx')    ## reading the expiry sheet file\n",
    "    exp_file_path = r\"C:\\Users\\admin\\Downloads\\MonthlyExpiry.csv\"\n",
    "    exp_df = pd.read_csv(exp_file_path,parse_dates = [\"curr_exp_date\",\"curr_date\"],dayfirst =True,usecols = [\"curr_exp_date\",\"curr_date\"]).dropna()\n",
    "    exp_df.rename({'curr_date': 'New_date'}, axis=1, inplace=True)\n",
    "    \n",
    "    ndata = nifty_data()\n",
    "    temp = ndata.copy()\n",
    "    temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "    temp = temp.reset_index(drop=True)\n",
    "    temp['time'] = temp['time'].str.replace(' 15:00:59','15:00:59')\n",
    "    temp['time'] = temp['time'].str.replace(' 9:','09:',regex=True)\n",
    "    temp['time'] = pd.to_datetime(temp['time']).dt.time\n",
    "    temp['date'] = pd.to_datetime(temp['date'],dayfirst=True)\n",
    "    temp['ticker'] = temp['ticker'].str.replace('30MAR23','29MAR23',regex=True)\n",
    "    temp['Option_Type'] = temp['ticker'].str[-2:]\n",
    "    temp['Temp'] = temp[\"ticker\"].str.replace(s,\"\")\n",
    "    temp['Temp'] = temp['Temp'].str[:-2]\n",
    "    temp['Length_of_temp'] = temp['Temp'].str.len()\n",
    "    temp['Strike'] = np.where((temp['Temp'].str.len()==9) | (temp['Temp'].str.len()==11) , \n",
    "                              temp['Temp'].str[-4:] , \n",
    "                              temp['Temp'].str[-5:])\n",
    "    temp['Exp_Year'] = np.where((temp['Temp'].str.len()==9) | (temp['Temp'].str.len()==10) ,\n",
    "                               temp['Temp'].str[:2] ,\n",
    "                               temp['Temp'].str[5:7])\n",
    "    temp['Current_Year'] = temp['date'].dt.year\n",
    "    temp['Current_Year'] = temp['Current_Year'].astype(str).str[-2:]\n",
    "    temp['Exp_month'] = temp['Temp'].str[2:5]\n",
    "    temp['Exp_Year'] = temp['Exp_Year'].astype('str')\n",
    "    temp['MonthYear'] = temp['Exp_month']+temp['Exp_Year']\n",
    "    temp = pd.merge(temp,exp_date,on='MonthYear')\n",
    "    temp = temp.drop(['MonthYear','Month','Year','Next_Exp_DT'],axis=1)\n",
    "\n",
    "    temp['Length_of_temp'] = temp['Length_of_temp'].astype('int64')\n",
    "    temp_10 = temp[(temp['Length_of_temp']==10) | (temp['Length_of_temp']==9)]\n",
    "\n",
    "    temp_12 = temp[(temp['Length_of_temp']==12) | (temp['Length_of_temp']==11)]\n",
    "\n",
    "    temp_12['DateDate'] = temp_12['Temp'].str[:2]\n",
    "    temp_12['DateDate'] = temp_12['DateDate'].astype('int64')\n",
    "    temp_12['Exp_DT'] = pd.to_datetime(temp['Exp_DT'],dayfirst=True)\n",
    "    temp_12['Exp_Day'] = temp_12['Exp_DT'].dt.day\n",
    "    temp_12 = temp_12[temp_12['Exp_Day']==temp_12['DateDate']]\n",
    "    temp_12 = temp_12.drop(['DateDate','Exp_Day'],axis=1)\n",
    "\n",
    "    temp_df = temp_10.append(temp_12,ignore_index=True)\n",
    "\n",
    "    temp_df['exp_month_number'] = temp_df.apply(lambda row : add(row[\"Exp_month\"]), axis = 1)\n",
    "    temp_df['New_date'] = temp_df['date']\n",
    "    temp_df[\"New_date\"] = pd.to_datetime(temp_df[\"New_date\"])\n",
    "    temp_df[\"current_month_number\"] = temp_df['New_date'].dt.month\n",
    "    temp_df[\"difference\"] = temp_df['exp_month_number'].astype(int) - temp_df[\"current_month_number\"].astype(int)\n",
    "    temp_df['Year_difference'] = temp_df['Exp_Year'].astype(int) - temp_df['Current_Year'].astype(int)\n",
    "    temp_df = temp_df[(temp_df['exp_month_number']==3) | (temp_df['exp_month_number']==6) | (temp_df['exp_month_number']==9) | (temp_df['exp_month_number']==12)]\n",
    "\n",
    "    temp1 = pd.merge(temp_df, \n",
    "                     exp_df, \n",
    "                     on ='New_date', \n",
    "                     how ='left')\n",
    "\n",
    "    temp1.drop(temp1.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "    temp1[\"current_exp_month_number\"] = temp1['curr_exp_date'].dt.month\n",
    "    temp1[\"Diff_months\"] = temp1[\"current_exp_month_number\"] - temp1[\"current_month_number\"]\n",
    "    temp1[\"Diff_months\"] = temp1[\"Diff_months\"].astype(int) \n",
    "\n",
    "    temp1 = temp1[temp1['Exp_DT']>=temp1['curr_exp_date']]                 ## to filter out dates which have wrong ticker\n",
    "\n",
    "    if os.path.exists(folpath+sym+'-I.csv'):\n",
    "        os.remove(folpath+sym+'-I.csv')\n",
    "    if os.path.exists(folpath+sym+'-II.csv'):\n",
    "        os.remove(folpath+sym+'-II.csv')\n",
    "    if os.path.exists(folpath+sym+'-III.csv'):\n",
    "        os.remove(folpath+sym+'-III.csv')\n",
    "    if os.path.exists(folpath+sym+'-IV.csv'):\n",
    "        os.remove(folpath+sym+'-IV.csv')\n",
    "\n",
    "\n",
    "    atemp = temp1[(temp1['Diff_months']==0) & (temp1['Year_difference']==0)]\n",
    "    agb = atemp.groupby(['difference'])\n",
    "    unique_a = list(atemp['difference'].unique())\n",
    "\n",
    "    for i in unique_a:\n",
    "        temp_df = agb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==0 or i==1 or i==2:\n",
    "            temp_df.to_csv(folpath + sym + '-I.csv', mode='a', header=not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "\n",
    "        if i==3 or i==4 or i==5:\n",
    "            temp_df.to_csv(folpath + sym + '-II.csv', mode='a', header=not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "\n",
    "        if i==6 or i==7 or i==8:\n",
    "            temp_df.to_csv(folpath + sym + '-III.csv', mode='a', header=not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "\n",
    "        if i==9 or i==10 or i==11:\n",
    "            temp_df.to_csv(folpath + sym + '-IV.csv', mode='a', header=not os.path.exists(folpath + sym + '-IV.csv'), index=False)\n",
    "\n",
    "\n",
    "    btemp = temp1[(temp1['Diff_months']==0) & (temp1['Year_difference']==1)]\n",
    "    bgb = btemp.groupby(['difference'])\n",
    "    unique_b = list(btemp['difference'].unique())        \n",
    "\n",
    "    for i in unique_b:\n",
    "        temp_df = bgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "\n",
    "        if i==-7 or i==-8 or i==-9:\n",
    "            temp_df.to_csv(folpath + sym + '-II.csv', mode='a', header=not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "\n",
    "        if i==-4 or i==-5 or i==-6:\n",
    "            temp_df.to_csv(folpath + sym + '-III.csv', mode='a', header=not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "\n",
    "        if i==-1 or i==-2 or i==-3:\n",
    "            temp_df.to_csv(folpath + sym + '-IV.csv', mode='a', header=not os.path.exists(folpath + sym + '-IV.csv'), index=False)\n",
    "\n",
    "\n",
    "\n",
    "    ctemp = temp1[((temp1['Diff_months']==1) | (temp1['Diff_months']==-11)) & (temp1['Year_difference']==0)]\n",
    "    cgb = ctemp.groupby(['difference'])\n",
    "    unique_c = list(ctemp['difference'].unique())\n",
    "\n",
    "    for i in unique_c:\n",
    "        temp_df = cgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "\n",
    "        if i==1 or i==2 or i==3:\n",
    "            temp_df.to_csv(folpath + sym + '-I.csv', mode='a', header=not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "\n",
    "        if i==4 or i==5 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-II.csv', mode='a', header=not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "\n",
    "        if i==7 or i==8 or i==9:\n",
    "            temp_df.to_csv(folpath + sym + '-III.csv', mode='a', header=not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "\n",
    "        if i==10 or i==11:\n",
    "            temp_df.to_csv(folpath + sym + '-IV.csv', mode='a', header=not os.path.exists(folpath + sym + '-IV.csv'), index=False)\n",
    "\n",
    "\n",
    "    dtemp = temp1[((temp1['Diff_months']==1) | (temp1['Diff_months']==-11)) & (temp1['Year_difference']==1)]\n",
    "    dgb = dtemp.groupby(['difference'])\n",
    "    unique_d = list(dtemp['difference'].unique())\n",
    "\n",
    "    for i in unique_d:\n",
    "        temp_df = dgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "\n",
    "        if i==-9:\n",
    "            temp_df.to_csv(folpath + sym + '-I.csv', mode='a', header=not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "\n",
    "        if i==-6 or i==-7:\n",
    "            temp_df.to_csv(folpath + sym + '-II.csv', mode='a', header=not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "\n",
    "        if i==-3 or i==-4:\n",
    "            temp_df.to_csv(folpath + sym + '-III.csv', mode='a', header=not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "\n",
    "        if i==0 or i==-1 or i==-2:\n",
    "            temp_df.to_csv(folpath + sym + '-IV.csv', mode='a', header=not os.path.exists(folpath + sym + '-IV.csv'), index=False)\n",
    "\n",
    "    for i in range(4):\n",
    "        if i==0:\n",
    "            file='I'\n",
    "        elif i==1:\n",
    "            file='II'\n",
    "        elif i==2:\n",
    "            file='III'\n",
    "        elif i==3:\n",
    "            file='IV'\n",
    "        if os.path.exists(r'C:\\users\\admin\\desktop\\Pyspark\\Nifty\\Quarterly\\NIFTY-'+file+'.csv'):\n",
    "            os.remove(r'C:\\users\\admin\\desktop\\Pyspark\\Nifty\\Quarterly\\NIFTY-'+file+'.csv')\n",
    "        if os.path.exists(r'C:\\users\\admin\\desktop\\Pyspark_Contracts\\Nifty\\Quarterly_Data\\NIFTY-'+file+'.csv'):\n",
    "            ddf = pd.read_csv(r'C:\\users\\admin\\desktop\\Pyspark_Contracts\\Nifty\\Quarterly_Data\\NIFTY-'+file+'.csv')\n",
    "            ddf['Option_Type'] = ddf['ticker'].str[-2:]\n",
    "            ddf['Strike'] = np.where((ddf['ticker'].str.len()==16) | (ddf['ticker'].str.len()==18) , ddf['ticker'].str[-6:-2] , ddf['ticker'].str[-7:-2])\n",
    "            ddf['Symbol'] = 'NIFTY' + 'QUARTERLY-' + file + ddf['Strike'].astype(int).astype(str) + ddf['Option_Type']\n",
    "            ddf['ticker'] = ddf['Symbol']\n",
    "            ddf = ddf.drop(ddf.columns[9:],axis=1)\n",
    "            ddf = ddf.rename(columns = {'date':'Date','ticker':'Ticker'})\n",
    "            ddf = ddf.drop_duplicates()\n",
    "            ddf.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\Nifty\\Quarterly\\NIFTY-\"+file+\".csv\",index=False)\n",
    "    print(\"NIFTY QUARTERLY CONTRACTS CREATED\")\n",
    "    \n",
    "def nifty_halfyearly():\n",
    "    folpath = r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\\\\"\n",
    "    sym = 'NIFTY'\n",
    "    s = 'NIFTY'\n",
    "    def add(stri):\n",
    "        obj = datetime.strptime(stri, \"%b\")\n",
    "        month_number = obj.month\n",
    "        return month_number\n",
    "    def get_symbol(tic):\n",
    "        li = list(filter(None, re.split(r'(\\d+)', tic)))\n",
    "        return li[0]\n",
    "\n",
    "    exp_date = pd.read_excel(r'C:\\users\\admin\\desktop\\Expiry_DT.xlsx')    ## reading the expiry sheet file\n",
    "\n",
    "    hy_exp_date = pd.read_csv(r\"C:\\Users\\admin\\Downloads\\half_yearly_expiry.csv\",dayfirst=True,parse_dates=['date','Current_Expiry'], usecols =['date','Current_Expiry'])\n",
    "    \n",
    "    ndata = nifty_data()\n",
    "    temp = ndata.copy()\n",
    "    temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "    temp = temp.reset_index(drop=True)\n",
    "    temp['time'] = temp['time'].str.replace(' 15:00:59','15:00:59')\n",
    "    temp['time'] = temp['time'].str.replace(' 9:','09:',regex=True)\n",
    "    temp['time'] = pd.to_datetime(temp['time']).dt.time\n",
    "    temp['date'] = pd.to_datetime(temp['date'],dayfirst=True)\n",
    "    temp['ticker'] = temp['ticker'].str.replace('30MAR23','29MAR23',regex=True)\n",
    "    temp['Option_Type'] = temp['ticker'].str[-2:]\n",
    "    temp['Temp'] = temp[\"ticker\"].str.replace(s,\"\")\n",
    "    temp['Temp'] = temp['Temp'].str[:-2]\n",
    "    temp['Length_of_temp'] = temp['Temp'].str.len()\n",
    "    temp['Strike'] = np.where((temp['Temp'].str.len()==9) | (temp['Temp'].str.len()==11) , \n",
    "                              temp['Temp'].str[-4:] , \n",
    "                              temp['Temp'].str[-5:])\n",
    "    temp['Exp_Year'] = np.where((temp['Temp'].str.len()==9) | (temp['Temp'].str.len()==10) ,\n",
    "                               temp['Temp'].str[:2] ,\n",
    "                               temp['Temp'].str[5:7])\n",
    "    temp['Current_Year'] = temp['date'].dt.year\n",
    "    temp['Current_Year'] = temp['Current_Year'].astype(str).str[-2:]\n",
    "    temp['Exp_month'] = temp['Temp'].str[2:5]\n",
    "    temp['Exp_Year'] = temp['Exp_Year'].astype('str')\n",
    "    temp['MonthYear'] = temp['Exp_month']+temp['Exp_Year']\n",
    "    temp = pd.merge(temp,exp_date,on='MonthYear')\n",
    "    temp = temp.drop(['MonthYear','Month','Year','Next_Exp_DT'],axis=1)\n",
    "    temp['Length_of_temp'] = temp['Length_of_temp'].astype('int64')\n",
    "    temp_10 = temp[(temp['Length_of_temp']==10) | (temp['Length_of_temp']==9)]\n",
    "\n",
    "    temp_12 = temp[(temp['Length_of_temp']==12) | (temp['Length_of_temp']==11)]\n",
    "    temp_12['DateDate'] = temp_12['Temp'].str[:2]\n",
    "    temp_12['DateDate'] = temp_12['DateDate'].astype('int64')\n",
    "    temp_12['Exp_DT'] = pd.to_datetime(temp['Exp_DT'],dayfirst=True)\n",
    "    temp_12['Exp_Day'] = temp_12['Exp_DT'].dt.day\n",
    "    temp_12 = temp_12[temp_12['Exp_Day']==temp_12['DateDate']]\n",
    "    temp_12 = temp_12.drop(['DateDate','Exp_Day'],axis=1)\n",
    "\n",
    "    temp_df = temp_10.append(temp_12,ignore_index=True)\n",
    "\n",
    "    temp_df['exp_month_number'] = temp_df.apply(lambda row : add(row[\"Exp_month\"]), axis = 1)\n",
    "    temp_df['New_date'] = temp_df['date']\n",
    "    temp_df[\"New_date\"] = pd.to_datetime(temp_df[\"New_date\"])\n",
    "    temp_df[\"current_month_number\"] = temp_df['New_date'].dt.month\n",
    "    temp_df[\"difference\"] = temp_df['exp_month_number'].astype(int) - temp_df[\"current_month_number\"].astype(int)\n",
    "    temp_df['Year_difference'] = temp_df['Exp_Year'].astype(int) - temp_df['Current_Year'].astype(int)\n",
    "    temp_df = temp_df[(temp_df['exp_month_number']==6) | (temp_df['exp_month_number']==12)]\n",
    "\n",
    "    hy_exp_date = hy_exp_date.rename({'date':'New_date'},axis=1)\n",
    "    temp1 = pd.merge(temp_df, \n",
    "                         hy_exp_date, \n",
    "                         on ='New_date', \n",
    "                         how ='left')\n",
    "\n",
    "    temp1.drop(temp1.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "    temp1[\"current_exp_month_number\"] = temp1['Current_Expiry'].dt.month\n",
    "    temp1[\"Diff_months\"] = temp1[\"current_exp_month_number\"] - temp1[\"current_month_number\"]\n",
    "    temp1[\"Diff_months\"] = temp1[\"Diff_months\"].astype(int) \n",
    "\n",
    "    temp1 = temp1[temp1['Exp_DT']>=temp1['Current_Expiry']]                 ## to filter out dates which have wrong ticker\n",
    "\n",
    "    corner_case = temp1[((temp1['current_month_number']==12) & (temp1['current_exp_month_number']==6)) | ((temp1['current_month_number']==6) & (temp1['current_exp_month_number']==12))]\n",
    "    normal_case = temp1[((temp1['current_month_number']>6) & (temp1['current_month_number']<=12) & (temp1['current_exp_month_number']==12)) | ((temp1['current_month_number']>0) & (temp1['current_month_number']<=6) & (temp1['current_exp_month_number']==6))]\n",
    "    if(normal_case.shape[0]+corner_case.shape[0]==temp1.shape[0]):\n",
    "        print(\"Success\")\n",
    "\n",
    "    if os.path.exists(folpath+sym+'-I.csv'):\n",
    "        os.remove(folpath+sym+'-I.csv')\n",
    "    if os.path.exists(folpath+sym+'-II.csv'):\n",
    "        os.remove(folpath+sym+'-II.csv')\n",
    "    if os.path.exists(folpath+sym+'-III.csv'):\n",
    "        os.remove(folpath+sym+'-III.csv')\n",
    "    if os.path.exists(folpath+sym+'-IV.csv'):\n",
    "        os.remove(folpath+sym+'-IV.csv')\n",
    "    if os.path.exists(folpath+sym+'-V.csv'):\n",
    "        os.remove(folpath+sym+'-V.csv')\n",
    "    if os.path.exists(folpath+sym+'-VI.csv'):\n",
    "        os.remove(folpath+sym+'-VI.csv')\n",
    "    if os.path.exists(folpath+sym+'-VII.csv'):\n",
    "        os.remove(folpath+sym+'-VII.csv')\n",
    "    if os.path.exists(folpath+sym+'-VIII.csv'):\n",
    "        os.remove(folpath+sym+'-VIII.csv')\n",
    "    if os.path.exists(folpath+sym+'-IX.csv'):\n",
    "        os.remove(folpath+sym+'-IX.csv')\n",
    "    if os.path.exists(folpath+sym+'-X.csv'):\n",
    "        os.remove(folpath+sym+'-X.csv')\n",
    "\n",
    "    ## NORMAL CASE HY1\n",
    "    atemp = normal_case[(normal_case['Diff_months']<=5) & (normal_case['Diff_months']>=0) & (normal_case['Year_difference']==0) & ((normal_case['difference']>=0) & (normal_case['difference']<6))]\n",
    "    agb = atemp.groupby(['Diff_months'])\n",
    "    unique_a = list(atemp['Diff_months'].unique())\n",
    "    for i in unique_a:\n",
    "        temp_df = agb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i<=5 and i>=0:\n",
    "            temp_df.to_csv(folpath + sym + '-I.csv', mode='a', header=not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "\n",
    "    ## NORMAL CASE HY2\n",
    "    btemp = normal_case[((normal_case['Diff_months']<=5) & (normal_case['Year_difference']==0) & (normal_case['difference']>=6)) | ((normal_case['Diff_months']<=5) & (normal_case['Year_difference']==1) & (normal_case['difference']<=-6))]\n",
    "    bgb = btemp.groupby(['Diff_months'])\n",
    "    unique_b = list(btemp['Diff_months'].unique())\n",
    "    for i in unique_b:\n",
    "        temp_df = bgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i<=6 and i>=0:\n",
    "            temp_df.to_csv(folpath + sym + '-II.csv', mode='a', header=not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "\n",
    "    ## NORMAL CASE HY3\n",
    "    ctemp = normal_case[(normal_case['Diff_months']<=5) & (normal_case['Diff_months']>=0) & (normal_case['Year_difference']==1) & ((normal_case['difference']>=0) & (normal_case['difference']<6))]\n",
    "    cgb = ctemp.groupby(['Diff_months'])\n",
    "    unique_c = list(ctemp['Diff_months'].unique())\n",
    "    for i in unique_c:\n",
    "        temp_df = cgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i<=5 and i>=0:\n",
    "            temp_df.to_csv(folpath + sym + '-III.csv', mode='a', header=not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "\n",
    "    ## NORMAL CASE HY4\n",
    "    dtemp = normal_case[((normal_case['Diff_months']<=5) & (normal_case['Year_difference']==1) & (normal_case['difference']>=6)) | ((normal_case['Diff_months']<=5) & (normal_case['Year_difference']==2) & (normal_case['difference']<=-6))]\n",
    "    dgb = dtemp.groupby(['Diff_months'])\n",
    "    unique_d = list(dtemp['Diff_months'].unique())\n",
    "    for i in unique_d:\n",
    "        temp_df = dgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i<=6 and i>=0:\n",
    "            temp_df.to_csv(folpath + sym + '-IV.csv', mode='a', header=not os.path.exists(folpath + sym + '-IV.csv'), index=False)\n",
    "\n",
    "    ## NORMAL CASE HY5\n",
    "    etemp = normal_case[(normal_case['Diff_months']<=5) & (normal_case['Diff_months']>=0) & (normal_case['Year_difference']==2) & ((normal_case['difference']>=0) & (normal_case['difference']<6))]\n",
    "    egb = etemp.groupby(['Diff_months'])\n",
    "    unique_e = list(etemp['Diff_months'].unique())\n",
    "    for i in unique_e:\n",
    "        temp_df = egb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i<=5 and i>=0:\n",
    "            temp_df.to_csv(folpath + sym + '-V.csv', mode='a', header=not os.path.exists(folpath + sym + '-V.csv'), index=False)\n",
    "\n",
    "    ## NORMAL CASE HY6\n",
    "    ftemp = normal_case[((normal_case['Diff_months']<=5) & (normal_case['Year_difference']==2) & (normal_case['difference']>=6)) | ((normal_case['Diff_months']<=5) & (normal_case['Year_difference']==3) & (normal_case['difference']<=-6))]\n",
    "    fgb = ftemp.groupby(['Diff_months'])\n",
    "    unique_f = list(ftemp['Diff_months'].unique())\n",
    "    for i in unique_f:\n",
    "        temp_df = fgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i<=6 and i>=0:\n",
    "            temp_df.to_csv(folpath + sym + '-VI.csv', mode='a', header=not os.path.exists(folpath + sym + '-VI.csv'), index=False)\n",
    "\n",
    "    ## NORMAL CASE HY7\n",
    "    gtemp = normal_case[(normal_case['Diff_months']<=5) & (normal_case['Diff_months']>=0) & (normal_case['Year_difference']==3) & ((normal_case['difference']>=0) & (normal_case['difference']<6))]\n",
    "    ggb = gtemp.groupby(['Diff_months'])\n",
    "    unique_g = list(gtemp['Diff_months'].unique())\n",
    "    for i in unique_g:\n",
    "        temp_df = ggb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i<=5 and i>=0:\n",
    "            temp_df.to_csv(folpath + sym + '-VII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VII.csv'), index=False)\n",
    "\n",
    "    ## NORMAL CASE HY8\n",
    "    htemp = normal_case[((normal_case['Diff_months']<=5) & (normal_case['Year_difference']==3) & (normal_case['difference']>=6)) | ((normal_case['Diff_months']<=5) & (normal_case['Year_difference']==4) & (normal_case['difference']<=-6))]\n",
    "    hgb = htemp.groupby(['Diff_months'])\n",
    "    unique_h = list(htemp['Diff_months'].unique())\n",
    "    for i in unique_h:\n",
    "        temp_df = hgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i<=6 and i>=0:\n",
    "            temp_df.to_csv(folpath + sym + '-VIII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VIII.csv'), index=False)\n",
    "\n",
    "    ## NORMAL CASE HY9\n",
    "    itemp = normal_case[(normal_case['Diff_months']<=5) & (normal_case['Diff_months']>=0) & (normal_case['Year_difference']==4) & ((normal_case['difference']>=0) & (normal_case['difference']<6))]\n",
    "    igb = itemp.groupby(['Diff_months'])\n",
    "    unique_i = list(itemp['Diff_months'].unique())\n",
    "    for i in unique_i:\n",
    "        temp_df = igb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i<=5 and i>=0:\n",
    "            temp_df.to_csv(folpath + sym + '-IX.csv', mode='a', header=not os.path.exists(folpath + sym + '-IX.csv'), index=False)\n",
    "\n",
    "    ## NORMAL CASE HY10\n",
    "    jtemp = normal_case[((normal_case['Diff_months']<=5) & (normal_case['Year_difference']==4) & (normal_case['difference']>=6)) | ((normal_case['Diff_months']<=5) & (normal_case['Year_difference']==5) & (normal_case['difference']<=-6))]\n",
    "    jgb = jtemp.groupby(['Diff_months'])\n",
    "    unique_j = list(jtemp['Diff_months'].unique())\n",
    "    for i in unique_j:\n",
    "        temp_df = jgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i<=6 and i>=0:\n",
    "            temp_df.to_csv(folpath + sym + '-X.csv', mode='a', header=not os.path.exists(folpath + sym + '-X.csv'), index=False)\n",
    "\n",
    "    ## CORNER CASE HY1\n",
    "    ktemp = corner_case[((corner_case['Diff_months']==6) & (corner_case['Year_difference']==0) & (corner_case['difference']==6)) | ((corner_case['Diff_months']==-6) & (corner_case['Year_difference']==1) & (corner_case['difference']==-6))]\n",
    "    kgb = ktemp.groupby(['Diff_months'])\n",
    "    unique_k = list(ktemp['Diff_months'].unique())\n",
    "    for i in unique_k:\n",
    "        temp_df = kgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-6 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-I.csv', mode='a', header=not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "\n",
    "    ## CORNER CASE HY2\n",
    "    ltemp = corner_case[((corner_case['Diff_months']==6) & (corner_case['difference']==0) & (corner_case['Year_difference']==1)) | ((corner_case['Diff_months']==-6) & (corner_case['difference']==0) & (corner_case['Year_difference']==1))]\n",
    "    lgb = ltemp.groupby(['Diff_months'])\n",
    "    unique_l = list(ltemp['Diff_months'].unique())\n",
    "    for i in unique_l:\n",
    "        temp_df = lgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-6 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-II.csv', mode='a', header=not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "\n",
    "    ## CORNER CASE HY3\n",
    "    mtemp = corner_case[((corner_case['Diff_months']==6) & (corner_case['Year_difference']==1) & (corner_case['difference']==6)) | ((corner_case['Diff_months']==-6) & (corner_case['Year_difference']==2) & (corner_case['difference']==-6))]\n",
    "    mgb = mtemp.groupby(['Diff_months'])\n",
    "    unique_m = list(mtemp['Diff_months'].unique())\n",
    "    for i in unique_m:\n",
    "        temp_df = mgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-6 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-III.csv', mode='a', header=not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "\n",
    "    ## CORNER CASE HY4\n",
    "    ntemp = corner_case[((corner_case['Diff_months']==6) & (corner_case['difference']==0) & (corner_case['Year_difference']==2)) | ((corner_case['Diff_months']==-6) & (corner_case['difference']==0) & (corner_case['Year_difference']==2))]\n",
    "    ngb = ntemp.groupby(['Diff_months'])\n",
    "    unique_n = list(ntemp['Diff_months'].unique())\n",
    "    for i in unique_n:\n",
    "        temp_df = ngb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-6 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-IV.csv', mode='a', header=not os.path.exists(folpath + sym + '-IV.csv'), index=False)\n",
    "\n",
    "    ## CORNER CASE HY5\n",
    "    otemp = corner_case[((corner_case['Diff_months']==6) & (corner_case['Year_difference']==2) & (corner_case['difference']==6)) | ((corner_case['Diff_months']==-6) & (corner_case['Year_difference']==3) & (corner_case['difference']==-6))]\n",
    "    ogb = otemp.groupby(['Diff_months'])\n",
    "    unique_o = list(otemp['Diff_months'].unique())\n",
    "    for i in unique_o:\n",
    "        temp_df = ogb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-6 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-V.csv', mode='a', header=not os.path.exists(folpath + sym + '-V.csv'), index=False)\n",
    "\n",
    "    ## CORNER CASE HY6\n",
    "    ptemp = corner_case[((corner_case['Diff_months']==6) & (corner_case['difference']==0) & (corner_case['Year_difference']==3)) | ((corner_case['Diff_months']==-6) & (corner_case['difference']==0) & (corner_case['Year_difference']==3))]\n",
    "    pgb = ptemp.groupby(['Diff_months'])\n",
    "    unique_p = list(ptemp['Diff_months'].unique())\n",
    "    for i in unique_p:\n",
    "        temp_df = pgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-6 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-VI.csv', mode='a', header=not os.path.exists(folpath + sym + '-VI.csv'), index=False)\n",
    "\n",
    "    ## CORNER CASE HY7\n",
    "    qtemp = corner_case[((corner_case['Diff_months']==6) & (corner_case['Year_difference']==3) & (corner_case['difference']==6)) | ((corner_case['Diff_months']==-6) & (corner_case['Year_difference']==4) & (corner_case['difference']==-6))]\n",
    "    qgb = qtemp.groupby(['Diff_months'])\n",
    "    unique_q = list(qtemp['Diff_months'].unique())\n",
    "    for i in unique_q:\n",
    "        temp_df = qgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-6 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-VII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VII.csv'), index=False)\n",
    "\n",
    "    ## CORNER CASE HY8\n",
    "    rtemp = corner_case[((corner_case['Diff_months']==6) & (corner_case['difference']==0) & (corner_case['Year_difference']==4)) | ((corner_case['Diff_months']==-6) & (corner_case['difference']==0) & (corner_case['Year_difference']==4))]\n",
    "    rgb = rtemp.groupby(['Diff_months'])\n",
    "    unique_r = list(rtemp['Diff_months'].unique())\n",
    "    for i in unique_r:\n",
    "        temp_df = rgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-6 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-VIII.csv', mode='a', header=not os.path.exists(folpath + sym + '-VIII.csv'), index=False)\n",
    "\n",
    "    ## CORNER CASE HY9\n",
    "    stemp = corner_case[((corner_case['Diff_months']==6) & (corner_case['Year_difference']==4) & (corner_case['difference']==6)) | ((corner_case['Diff_months']==-6) & (corner_case['Year_difference']==5) & (corner_case['difference']==-6))]\n",
    "    sgb = stemp.groupby(['Diff_months'])\n",
    "    unique_s = list(stemp['Diff_months'].unique())\n",
    "    for i in unique_s:\n",
    "        temp_df = sgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-6 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-IX.csv', mode='a', header=not os.path.exists(folpath + sym + '-IX.csv'), index=False)\n",
    "\n",
    "    ## CORNER CASE HY10\n",
    "    ttemp = corner_case[((corner_case['Diff_months']==6) & (corner_case['difference']==0) & (corner_case['Year_difference']==5)) | ((corner_case['Diff_months']==-6) & (corner_case['difference']==0) & (corner_case['Year_difference']==5))]\n",
    "    tgb = ttemp.groupby(['Diff_months'])\n",
    "    unique_t = list(ttemp['Diff_months'].unique())\n",
    "    for i in unique_t:\n",
    "        temp_df = tgb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i==-6 or i==6:\n",
    "            temp_df.to_csv(folpath + sym + '-X.csv', mode='a', header=not os.path.exists(folpath + sym + '-X.csv'), index=False)\n",
    "\n",
    "    for i in range(10):\n",
    "        if(i==0):\n",
    "            file='I'\n",
    "        elif(i==1):\n",
    "            file='II'\n",
    "        elif(i==2):\n",
    "            file='III'\n",
    "        elif(i==3):\n",
    "            file='IV'\n",
    "        elif(i==4):\n",
    "            file='V'\n",
    "        elif(i==5):\n",
    "            file='VI'\n",
    "        elif(i==6):\n",
    "            file='VII'\n",
    "        elif(i==7):\n",
    "            file='VIII'\n",
    "        elif(i==8):\n",
    "            file='IX'\n",
    "        else:\n",
    "            file='X'\n",
    "        if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark\\Nifty\\Half_Yearly\\\\Nifty-\"+file+'.csv'):\n",
    "            os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark\\Nifty\\Half_Yearly\\\\Nifty-\"+file+'.csv')\n",
    "        if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-\"+file+\".csv\"):\n",
    "            df1 = pd.read_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-\"+file+\".csv\")\n",
    "            df1['Option_Type'] = df1['ticker'].str[-2:]\n",
    "            df1['Strike'] = np.where((df1['ticker'].str.len()==16) | (df1['ticker'].str.len()==18) , df1['ticker'].str[-6:-2] , df1['ticker'].str[-7:-2])\n",
    "            df1['Symbol'] = 'NIFTY-' + file + df1['Strike'].astype(int).astype(str) + df1['Option_Type']\n",
    "            df1['ticker'] = df1['Symbol']\n",
    "            df1 = df1.drop(df1.columns[9:],axis=1)\n",
    "            df1.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\Nifty\\Half_Yearly\\\\Nifty-\"+file+'.csv',index=False)\n",
    "    print(\"NIFTY HALF YEARLY CONTRACTS CREATED\")\n",
    "    \n",
    "def nifty_yearly():\n",
    "    for i in range(5):\n",
    "        if(i==0):\n",
    "            file='I'\n",
    "            file1='I'\n",
    "            file2='II'\n",
    "            ## REMOVING YEARLY CONTRACT FILE \n",
    "            if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv'):\n",
    "                os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv')\n",
    "            ## CHECKING IF HALFYEARLY FILE EXISTS\n",
    "            if os.path.exists(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file1+'.csv'):\n",
    "                df1 = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file1+'.csv')\n",
    "            else:\n",
    "                df1 = pd.DataFrame()\n",
    "            ## CHECKING IF HALFYEARLY FILE EXISTS\n",
    "            if os.path.exists(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file2+'.csv'):\n",
    "                df2 = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file2+'.csv')\n",
    "            else:\n",
    "                df2 = pd.DataFrame()\n",
    "        elif(i==1):\n",
    "            file='II'\n",
    "            file1='III'\n",
    "            file2='IV'\n",
    "            ## REMOVING YEARLY CONTRACT FILE \n",
    "            if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv'):\n",
    "                os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv')\n",
    "            ## CHECKING IF HALFYEARLY FILE EXISTS\n",
    "            if os.path.exists(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file1+'.csv'):\n",
    "                df1 = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file1+'.csv')\n",
    "            else:\n",
    "                df1 = pd.DataFrame()\n",
    "            ## CHECKING IF HALFYEARLY FILE EXISTS\n",
    "            if os.path.exists(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file2+'.csv'):\n",
    "                df2 = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file2+'.csv')\n",
    "            else:\n",
    "                df2 = pd.DataFrame()\n",
    "        elif(i==2):\n",
    "            file='III'\n",
    "            file1='V'\n",
    "            file2='VI'\n",
    "            ## REMOVING YEARLY CONTRACT FILE \n",
    "            if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv'):\n",
    "                os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv')\n",
    "            if os.path.exists(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file1+'.csv'):\n",
    "                df1 = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file1+'.csv')\n",
    "            else:\n",
    "                df1 = pd.DataFrame()\n",
    "            if os.path.exists(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file2+'.csv'):\n",
    "                df2 = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file2+'.csv')\n",
    "            else:\n",
    "                df2 = pd.DataFrame()\n",
    "        elif(i==3):\n",
    "            file='IV'\n",
    "            file1='VII'\n",
    "            file2='VIII'\n",
    "            ## REMOVING YEARLY CONTRACT FILE \n",
    "            if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv'):\n",
    "                os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv')\n",
    "            ## CHECKING IF HALFYEARLY FILE EXISTS\n",
    "            if os.path.exists(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file1+'.csv'):\n",
    "                df1 = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file1+'.csv')\n",
    "            else:\n",
    "                df1 = pd.DataFrame()\n",
    "            ## CHECKING IF HALFYEARLY FILE EXISTS\n",
    "            if os.path.exists(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file2+'.csv'):\n",
    "                df2 = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file2+'.csv')\n",
    "            else:\n",
    "                df2 = pd.DataFrame()\n",
    "        elif(i==4):\n",
    "            file='V'\n",
    "            file1='IX'\n",
    "            file2='X'\n",
    "            ## REMOVING YEARLY CONTRACT FILE \n",
    "            if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv'):\n",
    "                os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv')\n",
    "            ## CHECKING IF HALFYEARLY FILE EXISTS\n",
    "            if os.path.exists(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file1+'.csv'):\n",
    "                df1 = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file1+'.csv')\n",
    "            else:\n",
    "                df1 = pd.DataFrame()\n",
    "            ## CHECKING IF HALFYEARLY FILE EXISTS\n",
    "            if os.path.exists(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file2+'.csv'):\n",
    "                df2 = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Half_Yearly_Data\\NIFTY-'+file2+'.csv')\n",
    "            else:\n",
    "                df2 = pd.DataFrame()\n",
    "        \n",
    "        if df1.empty and df2.empty:\n",
    "            print(\"No contracts for Half yearly\",file1,file2)\n",
    "        else:\n",
    "            print(i,\"YEARLY\",file,\"HALFYEARLY\",file1,file2)\n",
    "            if not df1.empty:\n",
    "                df1 = df1.sort_values(by='date')\n",
    "                df1['Month'] = df1['ticker'].str[7:10]\n",
    "                df1 = df1[df1['Month']=='DEC']\n",
    "            if not df2.empty:\n",
    "                df2 = df2.sort_values(by='date')\n",
    "                df2['Month'] = df2['ticker'].str[7:10]\n",
    "                df2 = df2[df2['Month']=='DEC']\n",
    "            final_df = df1.append(df2,ignore_index=True)\n",
    "            if not final_df.empty:\n",
    "                final_df = final_df.drop_duplicates()\n",
    "                final_df = final_df.drop(final_df.columns[9:],axis=1)\n",
    "                final_df.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv',index=False)\n",
    "\n",
    "    for i in range(5):\n",
    "        if(i==0):\n",
    "            file='I'\n",
    "        if(i==1):\n",
    "            file='II'\n",
    "        if(i==2):\n",
    "            file='III'\n",
    "        if(i==3):\n",
    "            file='IV'\n",
    "        if(i==4):\n",
    "            file='V'\n",
    "        if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark\\Nifty\\Yearly\\\\Nifty-\"+file+\".csv\"):\n",
    "            os.remove(r\"C:\\Users\\admin\\Desktop\\Pyspark\\Nifty\\Yearly\\\\Nifty-\"+file+\".csv\")\n",
    "        if os.path.exists(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv'):\n",
    "            df = pd.read_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\Nifty\\Yearly_Data\\\\Nifty-\"+file+'.csv')\n",
    "            df['Option_Type'] = df['ticker'].str[-2:]\n",
    "            df['Strike'] = np.where((df['ticker'].str.len()==16) | (df['ticker'].str.len()==18) , df['ticker'].str[-6:-2] , df['ticker'].str[-7:-2])\n",
    "            df['Symbol'] = 'NIFTY-' + file + df['Strike'].astype(int).astype(str) + df['Option_Type']\n",
    "            df['ticker'] = df['Symbol']\n",
    "            df = df.drop(df.columns[9:],axis=1)\n",
    "            df.to_csv(r\"C:\\Users\\admin\\Desktop\\Pyspark\\Nifty\\Yearly\\\\Nifty-\"+file+\".csv\",index=False)\n",
    "    print(\"YEARLY CONTRACTS GENERATED\")\n",
    "\n",
    "print(\"NIFTY CONTRACTS BEING CREATED\")\n",
    "nifty_monthly()\n",
    "nifty_weekly()\n",
    "nifty_quarterly()\n",
    "nifty_halfyearly()\n",
    "nifty_yearly()\n",
    "\n",
    "et = time.time()\n",
    "print(\"\\nNIFTY CONTRACTS CREATED\")\n",
    "print(\"ELAPSED TIME\",et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c479faa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
