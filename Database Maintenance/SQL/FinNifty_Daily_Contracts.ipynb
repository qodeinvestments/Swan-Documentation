{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6154213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r27022023\n",
      "FINNIFTY CONTRACTS BEING CREATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_7404\\586304269.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  temp_df = temp_10.append(temp_12,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-I 22910\n",
      "-I 22910\n",
      "-II 7\n",
      "-II 7\n",
      "-III 1\n",
      "-III 1\n",
      "FINNIFTY MONTHLY CONTRACTS GENERATED\n",
      "[0.0, 1.0, 2.0, 3.0, 4.0, 10000.0]\n",
      "-I\n",
      "22910\n",
      "22910\n",
      "-II\n",
      "5057\n",
      "5057\n",
      "-III\n",
      "21\n",
      "21\n",
      "-IV\n",
      "3\n",
      "3\n",
      "-V\n",
      "7\n",
      "7\n",
      "-VI not exists\n",
      "-VII not exists\n",
      "-VIII not exists\n",
      "-IX not exists\n",
      "-X not exists\n",
      "-XI not exists\n",
      "-XII not exists\n",
      "FINNIFTY WEEKLY CONTRACTS CREATED\n",
      "Elapsed Time 28.550374031066895\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import walk\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import array_contains\n",
    "from pyspark.sql.functions import *\n",
    "import time\n",
    "from pyspark.sql.functions import date_format\n",
    "from datetime import date\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "date = date(2023,2,27)                  ## to be changed as per requirement\n",
    "day = date.strftime('%d')\n",
    "nummonth=date.strftime(\"%m\")\n",
    "year=date.strftime('%Y')\n",
    "tablename=\"r\"+str(day)+str(nummonth)+str(year)\n",
    "print(tablename)\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "def finnifty_data():\n",
    "    spark = SparkSession.builder.config(\"spark.jars\", \"C:\\\\Users\\\\admin\\\\Downloads\\\\postgresql-42.5.0.jar\") \\\n",
    "    .master(\"local\").appName(\"PySpark_Postgres_test\").getOrCreate()\n",
    "    #spark.sparkContext.setLogLevel(\"WARN\")\n",
    "    df = spark.read.format(\"jdbc\").option(\"url\", \"jdbc:postgresql://swandatabase.cfehmk2wtejq.ap-south-1.rds.amazonaws.com/RawDataBase\").option(\"user\",\"postgres\").option(\"password\",\"swancap123\")\\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\").option(\"dbtable\", tablename)\\\n",
    "        .option(\"user\", \"postgres\").option(\"password\", \"swancap123\").load()\n",
    "    ## GETTING ONLY TIME IN TIME COLUMN\n",
    "    q = df.withColumn('time',date_format('time', 'HH:mm:ss'))\n",
    "    ## FILTERING FINNIFTY DATA\n",
    "    fndata = q.filter(q.ticker.contains('FINNIFTY') & ((q.ticker.endswith('E.NFO'))| (q.ticker.endswith('E'))))\n",
    "    ## REPLACING .NFO IN ticker\n",
    "    fndata = fndata.withColumn('ticker',regexp_replace('ticker','.NFO',''))\n",
    "    fndata = fndata.drop(col('ticker_check'))\n",
    "    ## CONVERTING PYSPARK DATAFRAME TO PANDAS DATAFRAME\n",
    "    fndata=fndata.toPandas()\n",
    "    return fndata\n",
    "\n",
    "def finnifty_monthly():\n",
    "    exp_df = pd.read_excel(r\"C:\\Users\\admin\\Desktop\\Expiry_Dates\\Finnifty.xlsx\",sheet_name='Monthly')\n",
    "    exp_df.rename({'curr_date': 'New_date'}, axis=1, inplace=True)\n",
    "    exp_date = pd.read_excel(r\"C:\\Users\\admin\\Desktop\\Expiry_Dates\\Finnifty_Monthly_Expiry.xlsx\")\n",
    "\n",
    "    folpath = r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\FinNifty\\Monthly_Data\\\\\"\n",
    "    finalpath = r\"C:\\Users\\admin\\Desktop\\Pyspark\\FinNifty\\Monthly\\\\\"\n",
    "    s = 'FINNIFTY'\n",
    "    def add(stri):\n",
    "        obj = datetime.strptime(stri, \"%b\")\n",
    "        month_number = obj.month\n",
    "        return month_number\n",
    "    sym = 'FINNIFTY'\n",
    "    fndata = finnifty_data()\n",
    "    dff = fndata.copy()\n",
    "    dff = dff[dff['ticker'].str.contains('FINNIFTY')]\n",
    "    dff = dff[(dff['ticker'].str.endswith('E')) | (dff['ticker'].str.endswith('E.NFO'))]\n",
    "    dff = dff.loc[:, ~dff.columns.str.contains('^Unnamed')]\n",
    "    dff['time'] = pd.to_datetime(dff['time']).dt.time\n",
    "    dff['date'] = pd.to_datetime(dff['date'],dayfirst=True)\n",
    "    dff['ticker'] = dff['ticker'].str.replace('30MAR23','29MAR23',regex=True)\n",
    "\n",
    "    dff['Option_Type'] = dff['ticker'].str[-2:]\n",
    "    dff['Temp'] = dff[\"ticker\"].str.replace(s,\"\")\n",
    "    dff['Temp'] = dff['Temp'].str[:-2]\n",
    "    dff['Length_of_Temp'] = dff['Temp'].str.len()\n",
    "    dff['Strike'] = np.where((dff['Temp'].str.len()==9) | (dff['Temp'].str.len()==11) , \n",
    "                              dff['Temp'].str[-4:] , \n",
    "                              dff['Temp'].str[-5:])\n",
    "    dff['Exp_Year'] = np.where((dff['Temp'].str.len()==9) | (dff['Temp'].str.len()==10) ,\n",
    "                               dff['Temp'].str[:2] ,\n",
    "                               dff['Temp'].str[5:7])\n",
    "    dff['Exp_month'] = dff['Temp'].str[2:5]\n",
    "\n",
    "    dff['Exp_Year'] = dff['Exp_Year'].astype('str')\n",
    "    dff['MonthYear'] = dff['Exp_month']+dff['Exp_Year']\n",
    "    dff = pd.merge(dff,exp_date,on='MonthYear')\n",
    "    dff = dff.drop(['MonthYear','Month','Year'],axis=1)\n",
    "    dff = dff.rename(columns={'Exp_DT':'Monthly_Expiry'})\n",
    "\n",
    "    dff['Length_of_Temp'] = dff['Length_of_Temp'].astype('int64')\n",
    "    temp_10 = dff[(dff['Length_of_Temp']==10) | (dff['Length_of_Temp']==9)]\n",
    "\n",
    "    temp_12 = dff[(dff['Length_of_Temp']==12) | (dff['Length_of_Temp']==11)]\n",
    "    temp_12['DateDate'] = temp_12['Temp'].str[:2]\n",
    "    temp_12['DateDate'] = temp_12['DateDate'].astype('int64')\n",
    "    temp_12['Exp_DT'] = pd.to_datetime(temp_12['Monthly_Expiry'],dayfirst=True)\n",
    "    temp_12['Exp_Day'] = temp_12['Exp_DT'].dt.day\n",
    "    temp_12 = temp_12[temp_12['Exp_Day']==temp_12['DateDate']]\n",
    "    temp_12 = temp_12.drop(['DateDate','Exp_Day'],axis=1)\n",
    "\n",
    "    temp_df = temp_10.append(temp_12,ignore_index=True)\n",
    "    temp_df['exp_month_number'] = temp_df.apply(lambda row : add(row[\"Exp_month\"]), axis = 1)\n",
    "    temp_df['New_date'] = temp_df['date']\n",
    "    temp_df[\"New_date\"] = pd.to_datetime(temp_df[\"New_date\"])\n",
    "    \n",
    "    temp_df[\"current_month_number\"] = temp_df['New_date'].dt.month\n",
    "    temp_df[\"difference\"] = temp_df['exp_month_number'].astype(int) - temp_df[\"current_month_number\"].astype(int)\n",
    "\n",
    "    temp_df1 = pd.merge(temp_df, \n",
    "                     exp_df, \n",
    "                     on ='New_date', \n",
    "                     how ='left')\n",
    "    temp_df1.drop(temp_df1.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "    temp_df1[\"current_exp_month_number\"] = temp_df1['curr_exp_date'].dt.month\n",
    "    temp_df1[\"Diff_months\"] = temp_df1[\"current_exp_month_number\"] - temp_df1[\"current_month_number\"]\n",
    "    temp_df1[\"Diff_months\"] = temp_df1[\"Diff_months\"].astype(int) \n",
    "    temp_df1['Current_Year'] = temp_df1['New_date'].dt.year.astype(str).str[-2:]\n",
    "\n",
    "    bdf = temp_df1[temp_df1[\"Diff_months\"] == 0]\n",
    "    adf = temp_df1[(temp_df1[\"Diff_months\"] == 1) | (temp_df1[\"Diff_months\"] == -11)]\n",
    "    agb = adf.groupby([\"difference\"])\n",
    "    unique_val_list_a = list(adf[\"difference\"].unique())\n",
    "\n",
    "    bgb = bdf.groupby([\"difference\"])\n",
    "    unique_val_list_b = list(bdf[\"difference\"].unique())\n",
    "\n",
    "    ## TO AVOID OVERWRITING, REMOVING FILE\n",
    "    for i in range(3):\n",
    "        if(i==0):\n",
    "            file='-I'\n",
    "        if(i==1):\n",
    "            file='-II'\n",
    "        if(i==2):\n",
    "            file='-III'\n",
    "        if(os.path.exists(folpath+sym+file+\".csv\")):\n",
    "            os.remove(folpath+sym+file+\".csv\")\n",
    "\n",
    "    for i in unique_val_list_b:\n",
    "        temp_df_new = bgb.get_group(i)\n",
    "        temp_df_new = temp_df_new.drop(temp_df_new.columns[9:],axis=1)\n",
    "        if i == 0:\n",
    "            temp_df_new.to_csv(folpath + sym + '-I.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "\n",
    "        if i == 1 or i == -11:\n",
    "            temp_df_new.to_csv(folpath + sym + '-II.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "\n",
    "        if i == 2 or i == -10:\n",
    "            temp_df_new.to_csv(folpath + sym + '-III.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "\n",
    "    for i in unique_val_list_a:\n",
    "        temp_df_new = agb.get_group(i)\n",
    "        temp_df_new = temp_df_new.drop(temp_df_new.columns[9:],axis=1)\n",
    "        if i == 1 or i == -11:\n",
    "            temp_df_new.to_csv(folpath + sym + '-I.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-I.csv'), index=False)\n",
    "\n",
    "        if i == 2 or i == -10:\n",
    "            temp_df_new.to_csv(folpath + sym + '-II.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-II.csv'), index=False)\n",
    "\n",
    "        if i == 3 or i == -9:\n",
    "            temp_df_new.to_csv(folpath + sym + '-III.csv', mode = 'a', header = not os.path.exists(folpath + sym + '-III.csv'), index=False)\n",
    "\n",
    "    for i in range(3):\n",
    "        if(i==0):\n",
    "            file='-I'\n",
    "        if(i==1):\n",
    "            file='-II'\n",
    "        if(i==2):\n",
    "            file='-III'\n",
    "\n",
    "        if os.path.exists(finalpath+sym+file+\".csv\"):\n",
    "            os.remove(finalpath+sym+file+\".csv\")\n",
    "        if os.path.exists(folpath+sym+file+\".csv\"):\n",
    "            df = pd.read_csv(folpath+sym+file+\".csv\")\n",
    "            df['Option_Type'] = df['ticker'].str[-2:]\n",
    "            df['Strike'] = np.where((df['ticker'].str.len()==19) | (df['ticker'].str.len()==21) , df['ticker'].str[-6:-2] , df['ticker'].str[-7:-2])\n",
    "            df['Symbol'] = 'FINNIFTYMONTHLY' + file + df['Strike'].astype(int).astype(str) + df['Option_Type']\n",
    "            df['ticker'] = df['Symbol']\n",
    "            df = df.drop(df.columns[9:],axis=1)\n",
    "            df = df.sort_values(by='date')\n",
    "            print(file,df.shape[0])\n",
    "            df = df.drop_duplicates()\n",
    "            print(file,df.shape[0])\n",
    "            df.to_csv(finalpath+sym+file+\".csv\",index=False)\n",
    "    print(\"FINNIFTY MONTHLY CONTRACTS GENERATED\")\n",
    "    \n",
    "def finnifty_weekly():\n",
    "    exp_df1 = pd.read_excel(r\"C:\\Users\\admin\\Desktop\\Expiry_Dates\\Finnifty.xlsx\",sheet_name='Weekly',parse_dates=['date'],usecols= ['date','Week_number'])\n",
    "    exp_df2 = pd.read_excel(r\"C:\\Users\\admin\\Desktop\\Expiry_Dates\\Finnifty.xlsx\",sheet_name='Weekly',parse_dates=['Weekly_Expiry_Date'],usecols= ['Weekly_Expiry_Date', 'Expiry_Week_number'])\n",
    "    exp_date = pd.read_excel(r\"C:\\Users\\admin\\Desktop\\Expiry_Dates\\Finnifty_Monthly_Expiry.xlsx\")\n",
    "\n",
    "    folpath = r\"C:\\Users\\admin\\Desktop\\Pyspark_Contracts\\FinNifty\\Weekly_Data\\\\\"\n",
    "    finalpath = r\"C:\\Users\\admin\\Desktop\\Pyspark\\FinNifty\\Weekly\\\\\"\n",
    "    s = 'FINNIFTY'\n",
    "    def add(stri):\n",
    "        obj = datetime.strptime(stri, \"%b\")\n",
    "        month_number = obj.month\n",
    "        return month_number\n",
    "    sym = 'FINNIFTY'\n",
    "    fndata = finnifty_data()\n",
    "    dff = fndata.copy()\n",
    "    dff = dff[dff['ticker'].str.contains('FINNIFTY')]\n",
    "    dff = dff[(dff['ticker'].str.endswith('E')) | (dff['ticker'].str.endswith('E.NFO'))]\n",
    "    dff = dff.loc[:, ~dff.columns.str.contains('^Unnamed')]\n",
    "    dff['time'] = pd.to_datetime(dff['time']).dt.time\n",
    "    dff['date'] = pd.to_datetime(dff['date'],dayfirst=True)\n",
    "    dff['ticker'] = dff['ticker'].str.replace('30MAR23','29MAR23',regex=True)\n",
    "\n",
    "    dff['Option_Type'] = dff['ticker'].str[-2:]\n",
    "    dff['Temp'] = dff[\"ticker\"].str.replace(s,\"\")\n",
    "    dff['Temp'] = dff['Temp'].str[:-2]\n",
    "    dff['Length_of_Temp'] = dff['Temp'].str.len()\n",
    "    dff['Strike'] = np.where((dff['Temp'].str.len()==9) | (dff['Temp'].str.len()==11) , \n",
    "                              dff['Temp'].str[-4:] , \n",
    "                              dff['Temp'].str[-5:])\n",
    "    dff['Exp_Year'] = np.where((dff['Temp'].str.len()==9) | (dff['Temp'].str.len()==10) ,\n",
    "                               dff['Temp'].str[:2] ,\n",
    "                               dff['Temp'].str[5:7])\n",
    "    dff['Exp_month'] = dff['Temp'].str[2:5]\n",
    "    dff['EXPIRY_DT'] = dff['Temp'].str[:7]\n",
    "    dff['EXPIRY_DT'] = pd.to_datetime(dff['EXPIRY_DT'],dayfirst=True)\n",
    "\n",
    "    dff['Exp_Year'] = dff['Exp_Year'].astype('str')\n",
    "    dff['MonthYear'] = dff['Exp_month']+dff['Exp_Year']\n",
    "    dff = pd.merge(dff,exp_date,on='MonthYear')\n",
    "    dff = dff.drop(['MonthYear','Month','Year'],axis=1)\n",
    "    dff = dff.rename(columns={'Exp_DT':'Monthly_Expiry'})\n",
    "\n",
    "    ## GETTING EXPIRY DATES FOR MONTHLY CONTRACTS\n",
    "    dff['expiry_date'] = np.where(dff['Length_of_Temp']>=11,dff['EXPIRY_DT'],dff['Monthly_Expiry'])\n",
    "    dff = dff.drop(['EXPIRY_DT',\"Monthly_Expiry\"],axis=1)\n",
    "    ## GETTING WEEK NUMBER OF CURRENT DATE\n",
    "    dff = dff.rename(columns={'Date':'date'})\n",
    "    dff = pd.merge(dff,exp_df1,on='date',how='left')\n",
    "\n",
    "    ## GETTING WEEK NUMBER OF EXPIRY DATES\n",
    "    exp_df2['Weekly_Expiry_Date'] = pd.to_datetime(exp_df2['Weekly_Expiry_Date'],dayfirst=True)\n",
    "    exp_df2 = exp_df2.dropna()\n",
    "    exp_df2 = exp_df2.rename(columns = {'Weekly_Expiry_Date':'expiry_date'})\n",
    "    temp_df = pd.merge(dff, exp_df2, on = 'expiry_date', how = 'left')\n",
    "    temp_df = temp_df.drop_duplicates()\n",
    "    temp_df['week_diff'] = temp_df['Expiry_Week_number'] - temp_df['Week_number']\n",
    "    final_df = temp_df.copy()\n",
    "    final_df[\"week_diff\"] = final_df['week_diff'].replace(np.nan,10000)\n",
    "    \n",
    "    agb = final_df.groupby([\"week_diff\"])\n",
    "    unique_val_list_a = list(final_df[\"week_diff\"].unique())\n",
    "    unique_val_list_a = sorted([a for a in unique_val_list_a if a>=0])[0:14]\n",
    "    print(unique_val_list_a)\n",
    "    for i in range(12):\n",
    "        if(i==0):\n",
    "            file='-I'\n",
    "        if(i==1):\n",
    "            file='-II'\n",
    "        if(i==2):\n",
    "            file='-III'\n",
    "        if(i==3):\n",
    "            file='-IV'\n",
    "        if(i==4):\n",
    "            file='-V'\n",
    "        if(i==5):\n",
    "            file='-VI'\n",
    "        if(i==6):\n",
    "            file='-VII'\n",
    "        if(i==7):\n",
    "            file='-VIII'\n",
    "        if(i==8):\n",
    "            file='-IX'\n",
    "        if(i==9):\n",
    "            file='-X'\n",
    "        if(i==10):\n",
    "            file='-XI'\n",
    "        if(i==11):\n",
    "            file='-XII'\n",
    "            \n",
    "        if(os.path.exists(folpath+sym+file+\".csv\")):\n",
    "            os.remove(folpath+sym+file+\".csv\")\n",
    "\n",
    "    for i in sorted(unique_val_list_a):\n",
    "        temp_df = agb.get_group(i)\n",
    "        temp_df = temp_df.drop(temp_df.columns[9:],axis=1)\n",
    "        if i == 0:\n",
    "            temp_df.to_csv(folpath + s + '-I.csv', mode = 'a', header = not os.path.exists(folpath + s + '-I.csv'), index=False)\n",
    "\n",
    "        if i == 1:\n",
    "            temp_df.to_csv(folpath + s + '-II.csv', mode = 'a', header = not os.path.exists(folpath + s + '-II.csv'), index=False)\n",
    "\n",
    "        if i == 2:\n",
    "            temp_df.to_csv(folpath + s + '-III.csv', mode = 'a', header = not os.path.exists(folpath + s + '-III.csv'), index=False)\n",
    "\n",
    "        if i == 3:\n",
    "            temp_df.to_csv(folpath + s + '-IV.csv', mode = 'a', header = not os.path.exists(folpath + s + '-IV.csv'), index=False)\n",
    "\n",
    "        if i == 4:\n",
    "            temp_df.to_csv(folpath + s + '-V.csv', mode = 'a', header = not os.path.exists(folpath + s + '-V.csv'), index=False)\n",
    "\n",
    "        if i == 5:\n",
    "            temp_df.to_csv(folpath + s + '-VI.csv', mode = 'a', header = not os.path.exists(folpath + s + '-VI.csv'), index=False)\n",
    "\n",
    "        if i == 6:\n",
    "            temp_df.to_csv(folpath + s + '-VII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-VII.csv'), index=False)\n",
    "\n",
    "        if i == 7:\n",
    "            temp_df.to_csv(folpath + s + '-VIII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-VIII.csv'), index=False)\n",
    "\n",
    "        if i == 8:\n",
    "            temp_df.to_csv(folpath + s + '-IX.csv', mode = 'a', header = not os.path.exists(folpath + s + '-IX.csv'), index=False)\n",
    "\n",
    "        if i == 9:\n",
    "            temp_df.to_csv(folpath + s + '-X.csv', mode = 'a', header = not os.path.exists(folpath + s + '-X.csv'), index=False)\n",
    "\n",
    "        if i == 10:\n",
    "            temp_df.to_csv(folpath + s + '-XI.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XI.csv'), index=False)\n",
    "\n",
    "        if i == 11:\n",
    "            temp_df.to_csv(folpath + s + '-XII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XII.csv'), index=False)\n",
    "\n",
    "        if i == 12:\n",
    "            temp_df.to_csv(folpath + s + '-XIII.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XIII.csv'), index=False)\n",
    "\n",
    "        if i == 13:\n",
    "            temp_df.to_csv(folpath + s + '-XIV.csv', mode = 'a', header = not os.path.exists(folpath + s + '-XIV.csv'), index=False)\n",
    "\n",
    "    for i in range(12):\n",
    "        if(i==0):\n",
    "            file='-I'\n",
    "        if(i==1):\n",
    "            file='-II'\n",
    "        if(i==2):\n",
    "            file='-III'\n",
    "        if(i==3):\n",
    "            file='-IV'\n",
    "        if(i==4):\n",
    "            file='-V'\n",
    "        if(i==5):\n",
    "            file='-VI'\n",
    "        if(i==6):\n",
    "            file='-VII'\n",
    "        if(i==7):\n",
    "            file='-VIII'\n",
    "        if(i==8):\n",
    "            file='-IX'\n",
    "        if(i==9):\n",
    "            file='-X'\n",
    "        if(i==10):\n",
    "            file='-XI'\n",
    "        if(i==11):\n",
    "            file='-XII'\n",
    "        if(i==12):\n",
    "            file='-XIII'\n",
    "        if(i==13):\n",
    "            file='-XIV'\n",
    "        if os.path.exists(finalpath+sym+file+\".csv\"):\n",
    "            os.remove(finalpath+sym+file+\".csv\")\n",
    "        if(os.path.exists(folpath+sym+file+\".csv\")):\n",
    "            print(file)\n",
    "            df = pd.read_csv(folpath+sym+str(file)+\".csv\")\n",
    "            df['Option_Type'] = df['ticker'].str[-2:]\n",
    "            df['Strike'] = np.where((df['ticker'].str.len()==19) | (df['ticker'].str.len()==21) , df['ticker'].str[-6:-2] , df['ticker'].str[-7:-2])\n",
    "            df['Symbol'] = 'FINNIFTY' + file + df['Strike'].astype(int).astype(str) + df['Option_Type']\n",
    "            df['ticker'] = df['Symbol']\n",
    "            df = df.drop(df.columns[9:],axis=1)\n",
    "            df = df.sort_values(by='date')\n",
    "            print(df.shape[0])\n",
    "            df = df.drop_duplicates()\n",
    "            print(df.shape[0])\n",
    "            df.to_csv(finalpath+sym+str(file)+\".csv\",index=False)\n",
    "        else:\n",
    "            print(file,\"not exists\")\n",
    "    print(\"FINNIFTY WEEKLY CONTRACTS CREATED\")\n",
    "    \n",
    "print(\"FINNIFTY CONTRACTS BEING CREATED\")\n",
    "finnifty_monthly()\n",
    "finnifty_weekly()\n",
    "et = time.time()\n",
    "\n",
    "print(\"Elapsed Time\",et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706efaef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
